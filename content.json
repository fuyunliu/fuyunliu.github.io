{"meta":{"title":"听听那冷雨","subtitle":"No one write here","description":"记录一点东西","author":"听听那冷雨","url":"https://fuyunliu.github.io","root":"/"},"pages":[{"title":"标签","date":"2018-03-10T09:46:27.000Z","updated":"2020-12-03T07:33:48.333Z","comments":true,"path":"tags/index.html","permalink":"https://fuyunliu.github.io/tags/index.html","excerpt":"","text":""},{"title":"分类","date":"2018-03-10T09:46:57.000Z","updated":"2020-12-03T07:34:04.041Z","comments":true,"path":"categories/index.html","permalink":"https://fuyunliu.github.io/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"理解 Python 的元类","slug":"understand-python-metaclass","date":"2021-07-09T07:50:51.000Z","updated":"2021-07-09T08:01:00.279Z","comments":true,"path":"2021/07/09/understand-python-metaclass/","link":"","permalink":"https://fuyunliu.github.io/2021/07/09/understand-python-metaclass/","excerpt":"元类是一个深奥的OOP概念，几乎隐藏在所有Python代码之后。无论您是否知道，都在使用它们。在大多数情况下，您无需意识到这一点。大多数Python程序员很少（即使有的话）也不必考虑元类。","text":"元类是一个深奥的OOP概念，几乎隐藏在所有Python代码之后。无论您是否知道，都在使用它们。在大多数情况下，您无需意识到这一点。大多数Python程序员很少（即使有的话）也不必考虑元类。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228print_line = lambda x: print(&#x27;*&#x27; * x)# python中类的概念借鉴于Smalltalk，在大多数语言中类就是一段用于生成一个对象的代码。class ObjectCreator(object): passmyobj = ObjectCreator()print(myobj)print_line(50)# 但是类在python中也是对象，每当你用class关键字申明一个类时，python就会执行它并创建一个对象。比如上面的代码，python在内存中创建了一个名为ObjectCreator的对象。# 类对象本身也有创建对象（实例）的能力，这就是为什么它叫做类。# 但是同时，类本身也是个对象，因此你可以把它赋给一个变量，拷贝，添加属性或者作为函数的参数。print(ObjectCreator) # 你可以打印它，因为它是一个对象def echo(obj): print(obj)echo(ObjectCreator) # 你可以把类作为参数传递print(hasattr(ObjectCreator, &#x27;new_attribute&#x27;))ObjectCreator.new_attribute = &#x27;foo&#x27; # 你可以给它添加属性print(hasattr(ObjectCreator, &#x27;new_attribute&#x27;))print(ObjectCreator.new_attribute)ObjectCreatorMirror = ObjectCreator # 你可以把它赋给一个变量print(ObjectCreatorMirror.new_attribute)print(ObjectCreatorMirror())print_line(50)# 因为类也是一个对象，你可以像任何其他对象一样动态地创建它。def choose_class(name): if name == &#x27;foo&#x27;: class Foo(object): pass return Foo # 注意这里返回类，而不是实例 else: class Bar(object): pass return BarMyClass = choose_class(&#x27;foo&#x27;)print(MyClass) # 函数返回的是一个类，而不是实例print(MyClass()) # 你可以用这个类创建一个实例对象print_line(50)# 但这还不够动态，因为你还得自己手动编写整个类的代码。既然类是对象，那么肯定有什么东西来生成它，每当你使用class关键字时，python就自动创建这个对象，但是python也给你自己动手的机会，还记得type这个古老的函数吗？它返回这个对象的类型。print(type(1))print(type(&#x27;1&#x27;))print(type(ObjectCreator))print(type(ObjectCreator()))print_line(50)# type还有另一种完全不同的能力，它也能够动态地创建类，type接受一个类地描述作为参数然后返回一个类。# 比如下面这个类可以这样手动创建&quot;&quot;&quot;class MyShinyClass(object): passtype(name of the class, tuple of the parent class (for inheritance, can be empty), dictionary containing attributes names and values)&quot;&quot;&quot;MyShinyClass = type(&#x27;MyShinyClass&#x27;, (), &#123;&#125;) # 返回类对象print(MyShinyClass)print(MyShinyClass())print_line(50)# 再来个例子&quot;&quot;&quot;class Foo(object): bar = True&quot;&quot;&quot;# 可以写成Foo = type(&#x27;Foo&#x27;, (), &#123;&#x27;bar&#x27;: True&#125;)# 然后我们像正常的类一样来使用它print(Foo)print(Foo.bar)f = Foo()print(f)print(f.bar)# 我们还可以继承它FooChild = type(&#x27;FooChild&#x27;, (Foo,), &#123;&#125;)print(FooChild)print(FooChild.bar) # bar属性从Foo继承# 在类中添加方法def echo_bar(self): print(self.bar)FooChild = type(&#x27;FooChild&#x27;, (Foo,), &#123;&#x27;echo_bar&#x27;: echo_bar&#125;)print(hasattr(Foo, &#x27;echo_bar&#x27;))print(hasattr(FooChild, &#x27;echo_bar&#x27;))my_foo = FooChild()my_foo.echo_bar()print_line(50)# 综上，type就是元类，用于创建所有类的元类，是python内建的元类，你也可以创建自己的元类# 不信你看age = 35name = &#x27;fuyun&#x27;def foo(): passclass Bar(object): passprint(age.__class__)print(age.__class__.__class__)print(name.__class__)print(name.__class__.__class__)print(foo.__class__)print(foo.__class__.__class__)print(Bar().__class__)print(Bar().__class__.__class__)print_line(50)# 当你创建一个类的时候，你可以添加__metaclass__属性，python将会在类定义中寻找__metaclass__，如果找到了就用它来创建类，如果没有就用type来创建类。&quot;&quot;&quot;class Foo(Bar): pass&quot;&quot;&quot;# 上面的代码python将会这样做，首先python会在Foo中找__metaclass__，找到就用它来创建类对象，如果没有就会从父类Bar中找__metaclass__，如果在任何父类中都找不到__metaclass__，就会在模块层次中找__metaclass__，都找不到那就用内置的type来创建类对象。# 因此我们可以在__metaclass__中写一些用于创建类的代码，什么可以创建类？那就是type，或者任何使用到type或子类化type的东西。# 元类的主要目的就是在创建类的时候能够自动改变类。# 举个例子，编写一个元类，让类的属性都改成大写形式。# 元类会自动将你通常传给&#x27;type&#x27;的参数作为自己的参数传入def upper_attr(future_class_name, future_class_parents, future_class_attr): &quot;&quot;&quot; 返回一个将属性列表变为大写字母的类对象 &quot;&quot;&quot; # 选取所有不以&#x27;__&#x27;开头的属性，并把它们变成大写 uppercase_attr = &#123;&#125; for name, val in future_class_attr.items(): if not name.startswith(&#x27;__&#x27;): uppercase_attr[name.upper()] = val else: uppercase_attr[name] = val # 用type创建类 return type(future_class_name, future_class_parents, uppercase_attr)class Foo(metaclass=upper_attr): # __metaclass__ = upper_attr 这是python2的写法 bar = &#x27;foo&#x27;print(hasattr(Foo, &#x27;bar&#x27;))print(hasattr(Foo, &#x27;BAR&#x27;))print(Foo().BAR)print_line(50)# type实际上是一个类，就像str和int一样，所以，你可以从type继承class UpperAttrMetaclass(type): # __new__ 是在__init__之前被调用的特殊方法 # __new__是用来创建对象并返回它的方法 # 而__init__只是用来将传入的参数初始化给对象 # 你很少用到__new__，除非你希望能够控制对象的创建 # 这里，创建的对象是类，我们希望能够自定义它，所以我们这里改写__new__ # 如果你希望的话，你也可以在__init__中做些事情 # 还有一些高级的用法会涉及到改写__call__特殊方法，但是我们这里不用 def __new__(upperattr_metaclass, future_class_name, future_class_parents, future_class_attr): uppercase_attr = &#123;&#125; for name, val in future_class_attr.items(): if not name.startswith(&#x27;__&#x27;): uppercase_attr[name.upper()] = val else: uppercase_attr[name] = val return type(future_class_name, future_class_parents, uppercase_attr)# 但是这不是真正的面向对象(OOP)。我们直接调用了type，而且我们没有改写父类的new方法。class UpperAttrMetaclass(type): def __new__(upperattr_metaclass, future_class_name, future_class_parents, future_class_attr): uppercase_attr = &#123;&#125; for name, val in future_class_attr.items(): if not name.startswith(&#x27;__&#x27;): uppercase_attr[name.upper()] = val else: uppercase_attr[name] = val # 重用 type.__new__ 方法 # 这就是基本的OOP编程，没什么魔法 return type.__new__(upperattr_metaclass, future_class_name, future_class_parents, uppercase_attr) # 这里有个额外的参数upperattr_metaclass，类似于self，类方法的第一个参数总是代表当前实例。# 为了便于理解上面的代码名字编的太长，实际产品中的代码应该是这样的class UpperAttrMetaclass(type): def __new__(cls, clsname, bases, dct): uppercase_attr = &#123;&#125; for name, val in dct.items(): if not name.startswith(&#x27;__&#x27;): uppercase_attr[name.upper()] = val else: uppercase_attr[name] = val return type.__new__(cls, clsname, bases, uppercase_attr)# 我们还可以使用super方法使代码变得更清晰一点class UpperAttrMetaclass(type): def __new__(cls, clsname, bases, dct): uppercase_attr = &#123;&#125; for name, val in dct.items(): if not name.startswith(&#x27;__&#x27;): uppercase_attr[name.upper()] = val else: uppercase_attr[name] = val # return super(UpperAttrMetaclass, cls).__new__(cls, clsname, bases, uppercase_attr) 这是python2的写法 return super().__new__(cls, clsname, bases, uppercase_attr)# 元类要做的事就是拦截类的创建，修改一个类，返回修改之后的类。# 当你需要动态修改类的时候，最好使用“monkey patching”或“装饰器”。","categories":[{"name":"笔记","slug":"笔记","permalink":"https://fuyunliu.github.io/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Python3","slug":"Python3","permalink":"https://fuyunliu.github.io/tags/Python3/"}]},{"title":"理解 Python 的装饰器","slug":"understand-python-decorator","date":"2021-07-09T07:46:04.000Z","updated":"2021-07-09T07:57:11.923Z","comments":true,"path":"2021/07/09/understand-python-decorator/","link":"","permalink":"https://fuyunliu.github.io/2021/07/09/understand-python-decorator/","excerpt":"装饰器本质上是一个Python函数，它可以让其他函数在不需要做任何代码变动的前提下增加额外功能，装饰器的返回值也是一个函数对象。它经常用于有切面需求的场景，比如：插入日志、性能测试、事务处理、缓存、权限校验等场景。装饰器是解决这类问题的绝佳设计，有了装饰器，我们就可以抽离出大量与函数功能本身无关的雷同代码并继续重用。概括的讲，装饰器的作用就是为已经存在的对象添加额外的功能。","text":"装饰器本质上是一个Python函数，它可以让其他函数在不需要做任何代码变动的前提下增加额外功能，装饰器的返回值也是一个函数对象。它经常用于有切面需求的场景，比如：插入日志、性能测试、事务处理、缓存、权限校验等场景。装饰器是解决这类问题的绝佳设计，有了装饰器，我们就可以抽离出大量与函数功能本身无关的雷同代码并继续重用。概括的讲，装饰器的作用就是为已经存在的对象添加额外的功能。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629print_line = lambda x: print(&#x27;*&#x27; * x)# 在python中函数也是对象，举个例子def shout(word=&#x27;yes&#x27;): return word.capitalize() + &#x27;!&#x27;print(shout())# 你还可以把函数赋给一个变量scream = shoutprint(scream())# 你可以删除旧的函数名，而scream依然可以用del shouttry: print(shout())except NameError as e: print(e)print(scream())print_line(50)# python的另一个有趣的特性就是你可以在一个函数里定义另一个函数def talk(): # 定义另一个函数 def whisper(word=&#x27;yes&#x27;): return word.lower() + &#x27;...&#x27; # 现在调用它 print(whisper())# 每次调用talk时都会定义一次whisper，然后talk会调用whispertalk()# 但是在talk之外whisper是不存在的try: print(whisper())except NameError as e: print(e)# 总结：函数是对象，可以赋给一个变量，可以在函数里面定义，因此函数可以返回另一个函数print_line(50)def get_talk(kind=&#x27;shout&#x27;): # 先定义两个函数 def shout(word=&#x27;yes&#x27;): return word.capitalize() + &#x27;!&#x27; def whisper(word=&#x27;yes&#x27;): return word.lower() + &#x27;...&#x27; # 根据传入的参数返回不同的函数对象 if kind == &#x27;shout&#x27;: return shout else: return whisper# 把函数值赋给变量talk = get_talk()# 可以看出函数值是一个函数对象print(talk)# 再看看函数对象返回的对象print(talk())# 你还可以这么用print(get_talk(&#x27;whisper&#x27;)())print_line(50)# 既然可以return一个函数，那么把函数作为参数传递好了def do_something_before(func): print(&quot;I do something before then I call the function you gave me&quot;) print(func())do_something_before(scream)print_line(50)# 装饰器就是在函数执行之前或之后执行另一些代码而不用修改函数# 装饰器就是把其他函数作为参数的函数，然后返回一个函数的函数def my_shiny_new_decorator(a_function_to_decorate): # 在函数里面，装饰器在运行中定义函数: 包装器 # 这个函数将被包装在原始函数的外面，所以可以在原始函数之前和之后执行其他代码 def the_wrapper_around_the_original_function(): # 把要在原始函数被调用前执行的代码放在这里 print(&quot;Before the function runs&quot;) # 调用原始函数 a_function_to_decorate() # 把要在原始函数调用后执行的代码放在这里 print(&quot;After the function runs&quot;) # 在这里a_function_to_decorate函数还没有被执行 # 在这里返回刚刚包装过的函数 # 在包装函数里包含要在原始函数前后执行的代码 return the_wrapper_around_the_original_function# 现在假想一下你创建了一个永远也不想去修改的函数def a_stand_alone_function(): print(&quot;I am a stand alone function, don&#x27;t you dare modify me!&quot;)# 先尝试运行一下这个永不修改的函数a_stand_alone_function()print()# 现在你可以装饰器来增加它的功能，把它作为参数传递给装饰器，装饰器会返回一个被包装过的函数，a_stand_alone_function_decorated = my_shiny_new_decorator( a_stand_alone_function)a_stand_alone_function_decorated()print()# 现在你想要每次都是用a_stand_alone_function_decorated来代替a_stand_alone_functiona_stand_alone_function = my_shiny_new_decorator(a_stand_alone_function)a_stand_alone_function()# 函数名字改变了，变成了装饰器返回的那个函数的名字print(a_stand_alone_function.__name__)print_line(50)# 接下来看看装饰器的语法@my_shiny_new_decoratordef another_stand_alone_function(): print(&quot;Leave me alone!&quot;)# @my_shiny_new_decorator就是another_stand_alone_function = my_shiny_new_decorator(another_stand_alone_function)的缩写another_stand_alone_function()# 但是这个函数的名字也改变了print(another_stand_alone_function.__name__)print_line(50)# 当然你也可以自己写一个装饰器def bread(func): def wrapper(): print(&quot;&lt;/&#x27;&#x27;&#x27;&#x27;&#x27;&#x27;\\&gt;&quot;) func() print(&quot;&lt;\\______/&gt;&quot;) return wrapperdef ingredients(func): def wrapper(): print(&quot;#tomatoes#&quot;) func() print(&quot;~salad~&quot;) return wrapperdef sandwich(food=&quot;--ham--&quot;): print(food)# 现在来做两个不同的三明治one_sandwich = bread(ingredients(sandwich))one_sandwich()print()two_sandwich = ingredients(bread(sandwich))two_sandwich()print()# 或者用装饰器语法糖做三明治@bread@ingredientsdef sandwich_a(food=&quot;--ham--&quot;): print(food)# 改变一下顺序看看如何@ingredients@breaddef sandwich_b(food=&quot;--ham--&quot;): print(food)sandwich_a()print()sandwich_b()print_line(50)# 粗体装饰器def makebold(fn): # 装饰器将返回新的函数 def wrapper(): # 在之前或者之后插入新的代码 return &quot;&lt;b&gt;&quot; + fn() + &quot;&lt;/b&gt;&quot; return wrapper# 斜体装饰器def makeitalic(fn): # 装饰器将返回新的函数 def wrapper(): # 在之前或者之后插入新的代码 return &quot;&lt;i&gt;&quot; + fn() + &quot;&lt;/i&gt;&quot; return wrapper@makebold@makeitalicdef say(): return &quot;hello&quot;print(say())# 这相当于def say(): return &quot;hello&quot;say = makebold(makeitalic(say))print(say())print_line(50)# 在装饰器函数里传入参数def a_decorator_passing_arguments(function_to_decorate): def a_wrapper_accepting_arguments(arg1, arg2): print(&quot;I got args! Look:&quot;, arg1, arg2) function_to_decorate(arg1, arg2) return a_wrapper_accepting_arguments# 当你调用装饰器返回的函数时，也就调用了包装器，把参数传入包装器里，包装器再把参数传递给被装饰的函数@a_decorator_passing_argumentsdef print_full_name(first_name, last_name): print(&quot;My name is&quot;, first_name, last_name)print_full_name(&quot;fuyun&quot;, &quot;Liu&quot;)print_line(50)# 用装饰器装饰类方法也是一样的，唯一的区别就是类方法的第一个参数是self，代表实例对象def method_friendly_decorator(method_to_decorate): def wrapper(self, lie): lie = lie - 3 return method_to_decorate(self, lie) return wrapperclass Lucy(object): def __init__(self): self.age = 32 @method_friendly_decorator def say_your_age(self, lie): print(&quot;I am %s, what did you think?&quot; % (self.age + lie))l = Lucy()l.say_your_age(-3)print_line(50)# 如果你想造一个更通用的可以同时满足方法和函数的装饰器，用*args，**kwargs就可以了def a_decorator_passing_arbitrary_arguments(function_to_decorate): # 包装器接受所有参数 def a_wrapper_accepting_arbitrary_arguments(*args, **kwargs): print(&quot;Do I have args?:&quot;) print(args) print(kwargs) # args是个列表，kwargs是个字典 # 这里可以把args和kwargs解包并对其处理 function_to_decorate(*args, **kwargs) return a_wrapper_accepting_arbitrary_arguments@a_decorator_passing_arbitrary_argumentsdef function_with_no_argument(): print(&quot;Python is cool, no argument here.&quot;)function_with_no_argument()print()@a_decorator_passing_arbitrary_argumentsdef function_with_arguments(a, b, c): print(a, b, c)function_with_arguments(1, 2, 3)print()@a_decorator_passing_arbitrary_argumentsdef function_with_named_arguments(a, b, c, platypus=&quot;Why not ?&quot;): print(&quot;Do %s, %s and %s like platypus? %s&quot; % (a, b, c, platypus))function_with_named_arguments(&quot;Bill&quot;, &quot;Linus&quot;, &quot;Steve&quot;, platypus=&quot;Indeed!&quot;)print()class Mary(object): def __init__(self): self.age = 31 @a_decorator_passing_arbitrary_arguments def say_your_age(self, lie=-3): # 可以加入一个默认值 print(&quot;I am %s, what did you think?&quot; % (self.age + lie))m = Mary()m.say_your_age(lie=-5) # 这里又覆盖了默认值，可以变换着看一下print_line(50)# 像上面的把参数传给被装饰器返回的函数，实际上就是被定义在装饰器内部的包装器接收了。# 那如何给装饰器传参数呢？再来回顾一下装饰器的用法def my_decorator(func): print(&quot;I am an ordinary function&quot;) def wrapper(): print(&quot;I am function returned by the decorator&quot;) func() return wrapperdef lazy_function(): print(&quot;zzzzzzzz&quot;)# 装饰函数的过程其实调用了装饰器函数，下面这句有打印信息。decorated_function = my_decorator(lazy_function)# 这样也是，输出&quot;I am an ordinary function&quot;@my_decoratordef lazy_function(): print(&quot;zzzzzzzz&quot;)print_line(50)# 再用一层函数包装装饰器，我们就可以传参数给装饰器了，类似闭包，动态返回装饰器。def decorator_maker(): print(&quot;I make decorators! I am executed only once: &quot; + &quot;when you make me create a decorator.&quot;) def my_decorator(func): print(&quot;I am a decorator! I am executed only when you decorate a function.&quot;) def wrapped(): print(&quot;I am the wrapper around the decorated function. &quot; &quot;I am called when you call the decorated function. &quot; &quot;As the wrapper, I return the RESULT of the decorated function.&quot;) return func() print(&quot;As the decorator, I return the wrapped function.&quot;) return wrapped print(&quot;As a decorator maker, I return a decorator&quot;) return my_decorator# 用函数创建一个装饰器new_decorator = decorator_maker()print()def decorated_function(): print(&quot;I am the decorated function.&quot;)# 用刚刚创建的装饰器装饰函数decorated_function = new_decorator(decorated_function)print()# 执行被装饰过的函数decorated_function()print_line(50)# 用一行代码概括上面的decorator_maker()(decorated_function)()print_line(50)# 用@语法糖简化@decorator_maker()def decorated_function(): print(&quot;I am the decorated function.&quot;)# 执行一下decorated_function()print_line(50)# 现在来写一个带参数的装饰器生成函数def decorator_maker_with_arguments(decorator_arg1, decorator_arg2): print(&quot;I make decorators! And I accept arguments:&quot;, decorator_arg1, decorator_arg2) def my_decorator(func): # 这里传参的能力借鉴了闭包 # 参考 http://stackoverflow.com/questions/13857/can-you-explain-closures-as-they-relate-to-python print(&quot;I am the decorator. Somehow you passed me arguments:&quot;, decorator_arg1, decorator_arg2) # 不要忘了装饰器参数和函数参数 def wrapped(function_arg1, function_arg2): print(&quot;I am the wrapper around the decorated function.\\n&quot; &quot;I can access all the variables\\n&quot; &quot;\\t- from the decorator: &#123;0&#125; &#123;1&#125;\\n&quot; &quot;\\t- from the function call: &#123;2&#125; &#123;3&#125;\\n&quot; &quot;Then I can pass them to the decorated function&quot; .format(decorator_arg1, decorator_arg2, function_arg1, function_arg2)) return func(function_arg1, function_arg2) return wrapped return my_decorator@decorator_maker_with_arguments(&quot;Leonard&quot;, &quot;Sheldon&quot;)def decorated_function_with_arguments(function_arg1, function_arg2): print(&quot;I am the decorated function and only knows about my arguments: &#123;0&#125;&quot; &quot; &#123;1&#125;&quot;.format(function_arg1, function_arg2))decorated_function_with_arguments(&quot;Rajesh&quot;, &quot;Howard&quot;)print_line(50)# 参数还可以设置成变量c1 = &quot;Penny&quot;c2 = &quot;Leslie&quot;@decorator_maker_with_arguments(&quot;Leonard&quot;, c1)def decorated_function_with_arguments(function_arg1, function_arg2): print(&quot;I am the decorated function and only knows about my arguments:&quot; &quot; &#123;0&#125; &#123;1&#125;&quot;.format(function_arg1, function_arg2))decorated_function_with_arguments(c2, &quot;Howard&quot;)print_line(50)# 最后神奇的一招，如何装饰一个装饰器，动态地返回一个可以带任意参数的装饰器。def decorator_with_args(decorator_to_enhance): &quot;&quot;&quot; 这个函数接收一个装饰器作为参数，返回一个被装饰的装饰器 这没什么高深，只不过是为了给装饰器传参而已 &quot;&quot;&quot; def decorator_maker(*args, **kwargs): # 我们动态地建立一个只接收一个函数的装饰器 # 但是他能接收来自maker的参数 def decorator_wrapper(func): # 最后我们返回原始的装饰器，毕竟它只是普通的函数 # 唯一的陷阱：装饰器必须有这个特殊的，否则将不会奏效 return decorator_to_enhance(func, *args, **kwargs) return decorator_wrapper return decorator_maker# 把装饰器语法糖加到装饰器上面，注意这个装饰器是用来装饰函数的@decorator_with_argsdef decorated_decorator(func, *args, **kwargs): def wrapper(function_arg1, function_arg2): print(&quot;Decorated with&quot;, args, kwargs) return func(function_arg1, function_arg2) return wrapper# 现在用被装饰过的装饰器装饰你的函数@decorated_decorator(1, 2, 3, a=1, b=2, c=3)def decorated_function(function_arg1, function_arg2): print(&quot;Hello&quot;, function_arg1, function_arg2)# 调用被装饰器装饰过的函数decorated_function(&quot;world,&quot;, &quot;Awesome!&quot;)print_line(50)# 是不是被绕晕了，来看看终极调用过程# 首先这是一个普通的装饰器def normal_decorator(func, *args, **kwargs): def wrapper(function_arg1, function_arg2): print(&quot;Normal decorator decorated with&quot;, args, kwargs) return func(function_arg1, function_arg2) return wrapper# 这是一个普通的函数def normal_function(function_arg1, function_arg2): print(&quot;Hello&quot;, function_arg1, function_arg2)# 终极变态调用过程如下decorator_with_args(normal_decorator)(1, 2, 3, a=1, b=2, c=3)(normal_function)(&#x27;world,&#x27;, &#x27;Awesome!&#x27;)print_line(50)# 现在来关注一个小问题，被装饰器装饰的函数的名字__name__改变了。# 幸好我们有functools.wraps()函数，它可以复制函数的名字，模块和文档给它的包装器。def foo(): print(&quot;foo&quot;)print(foo.__name__)def bar(func): def wrapper(): print(&quot;bar&quot;) return func() return wrapper@bardef foo(): print(&quot;foo&quot;)print(foo.__name__)# 下面用functools.wraps()来修复import functoolsdef bar(func): @functools.wraps(func) def wrapper(): print(&quot;bar&quot;) return func() return wrapper@bardef foo(): print(&quot;foo&quot;)print(foo.__name__)print_line(50)# 如何使用装饰器def benchmark(func): &quot;&quot;&quot; A decorator that prints the time a function takes to execute. &quot;&quot;&quot; import time def wrapper(*args, **kwargs): t = time.clock() res = func(*args, **kwargs) print(func.__name__, time.clock() - t) return res return wrapperdef logging(func): &quot;&quot;&quot; A decorator that logs the activity of the script. (it actually just prints it, but it could be logging!) &quot;&quot;&quot; def wrapper(*args, **kwargs): res = func(*args, **kwargs) print(func.__name__, args, kwargs) return res return wrapperdef counter(func): &quot;&quot;&quot; A decorator that counts and prints the number of times a function has been executed &quot;&quot;&quot; def wrapper(*args, **kwargs): wrapper.count = wrapper.count + 1 res = func(*args, **kwargs) print(&quot;&#123;0&#125; has been used: &#123;1&#125;x&quot;.format(func.__name__, wrapper.count)) return res wrapper.count = 0 return wrapper@counter@benchmark@loggingdef reverse_string(string): return str(reversed(string))print(reverse_string(&quot;Able was I ere I saw Elba&quot;))print(reverse_string(&quot;A man, a plan, a canoe, pasta, heros, rajahs, a coloratura, maps, snipe, percale, macaroni, a gag, a banana bag, a tan, a tag, a banana bag again (or a camel), a crepe, pins, Spam, a rut, a Rolo, cash, a jar, sore hats, a peon, a canal: Panama!&quot;))print_line(50)# 不用重写装饰器而可以用他们来做任何事@counter@benchmark@loggingdef get_html_text(): import requests import pprint try: r = requests.get(&quot;http://httpbin.org/html&quot;) pprint.pprint(r.text) except: return &quot;I got nothing!&quot;get_html_text()get_html_text()","categories":[{"name":"笔记","slug":"笔记","permalink":"https://fuyunliu.github.io/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Python3","slug":"Python3","permalink":"https://fuyunliu.github.io/tags/Python3/"}]},{"title":"关于 Python 的一些面试题","slug":"interview-python","date":"2021-06-18T02:42:23.000Z","updated":"2021-06-18T02:45:32.437Z","comments":true,"path":"2021/06/18/interview-python/","link":"","permalink":"https://fuyunliu.github.io/2021/06/18/interview-python/","excerpt":"","text":"Python 语言特性1 Python的函数参数传递看两个例子: 12345a = 1def fun(a): a = 2fun(a)print a # 1 12345a = []def fun(a): a.append(1)fun(a)print a # [1] 所有的变量都可以理解是内存中一个对象的“引用”，或者，也可以看似c中void*的感觉。 通过id来看引用a的内存地址可以比较理解： 12345678a = 1def fun(a): print &quot;func_in&quot;,id(a) # func_in 41322472 a = 2 print &quot;re-point&quot;,id(a), id(2) # re-point 41322448 41322448print &quot;func_out&quot;,id(a), id(1) # func_out 41322472 41322472fun(a)print a # 1 注：具体的值在不同电脑上运行时可能不同。 可以看到，在执行完a = 2之后，a引用中保存的值，即内存地址发生变化，由原来1对象的所在的地址变成了2这个实体对象的内存地址。 而第2个例子a引用保存的内存值就不会发生变化： 1234567a = []def fun(a): print &quot;func_in&quot;,id(a) # func_in 53629256 a.append(1)print &quot;func_out&quot;,id(a) # func_out 53629256fun(a)print a # [1] 这里记住的是类型是属于对象的，而不是变量。而对象有两种,“可更改”（mutable）与“不可更改”（immutable）对象。在python中，strings, tuples, 和numbers是不可更改的对象，而 list, dict, set 等则是可以修改的对象。(这就是这个问题的重点) 当一个引用传递给函数的时候,函数自动复制一份引用,这个函数里的引用和外边的引用没有半毛关系了.所以第一个例子里函数把引用指向了一个不可变对象,当函数返回的时候,外面的引用没半毛感觉.而第二个例子就不一样了,函数内的引用指向的是可变对象,对它的操作就和定位了指针地址一样,在内存里进行修改. 如果还不明白的话,这里有更好的解释: http://stackoverflow.com/questions/986006/how-do-i-pass-a-variable-by-reference 2 Python中的元类(metaclass)这个非常的不常用,但是像ORM这种复杂的结构还是会需要的,详情请看:http://stackoverflow.com/questions/100003/what-is-a-metaclass-in-python 3 @staticmethod和@classmethodPython其实有3个方法,即静态方法(staticmethod),类方法(classmethod)和实例方法,如下: 1234567891011121314151617def foo(x): print &quot;executing foo(%s)&quot;%(x)class A(object): def foo(self,x): print &quot;executing foo(%s,%s)&quot;%(self,x) @classmethod def class_foo(cls,x): print &quot;executing class_foo(%s,%s)&quot;%(cls,x) @staticmethod def static_foo(x): print &quot;executing static_foo(%s)&quot;%xa=A() 这里先理解下函数参数里面的self和cls.这个self和cls是对类或者实例的绑定,对于一般的函数来说我们可以这么调用foo(x),这个函数就是最常用的,它的工作跟任何东西(类,实例)无关.对于实例方法,我们知道在类里每次定义方法的时候都需要绑定这个实例,就是foo(self, x),为什么要这么做呢?因为实例方法的调用离不开实例,我们需要把实例自己传给函数,调用的时候是这样的a.foo(x)(其实是foo(a, x)).类方法一样,只不过它传递的是类而不是实例,A.class_foo(x).注意这里的self和cls可以替换别的参数,但是python的约定是这俩,还是不要改的好. 对于静态方法其实和普通的方法一样,不需要对谁进行绑定,唯一的区别是调用的时候需要使用a.static_foo(x)或者A.static_foo(x)来调用. \\ 实例方法 类方法 静态方法 a = A() a.foo(x) a.class_foo(x) a.static_foo(x) A 不可用 A.class_foo(x) A.static_foo(x) 更多关于这个问题: http://stackoverflow.com/questions/136097/what-is-the-difference-between-staticmethod-and-classmethod-in-python https://realpython.com/blog/python/instance-class-and-static-methods-demystified/4 类变量和实例变量 类变量： ​ 是可在类的所有实例之间共享的值（也就是说，它们不是单独分配给每个实例的）。例如下例中，num_of_instance 就是类变量，用于跟踪存在着多少个Test 的实例。 实例变量： 实例化之后，每个实例单独拥有的变量。 12345678910111213class Test(object): num_of_instance = 0 def __init__(self, name): self.name = name Test.num_of_instance += 1if __name__ == &#x27;__main__&#x27;: print Test.num_of_instance # 0 t1 = Test(&#x27;jack&#x27;) print Test.num_of_instance # 1 t2 = Test(&#x27;lucy&#x27;) print t1.name , t1.num_of_instance # jack 2 print t2.name , t2.num_of_instance # lucy 2 补充的例子 123456789class Person: name=&quot;aaa&quot;p1=Person()p2=Person()p1.name=&quot;bbb&quot;print p1.name # bbbprint p2.name # aaaprint Person.name # aaa 这里p1.name=&quot;bbb&quot;是实例调用了类变量,这其实和上面第一个问题一样,就是函数传参的问题,p1.name一开始是指向的类变量name=&quot;aaa&quot;,但是在实例的作用域里把类变量的引用改变了,就变成了一个实例变量,self.name不再引用Person的类变量name了. 可以看看下面的例子: 123456789class Person: name=[]p1=Person()p2=Person()p1.name.append(1)print p1.name # [1]print p2.name # [1]print Person.name # [1] 参考:http://stackoverflow.com/questions/6470428/catch-multiple-exceptions-in-one-line-except-block 5 Python自省这个也是python彪悍的特性. 自省就是面向对象的语言所写的程序在运行时,所能知道对象的类型.简单一句就是运行时能够获得对象的类型.比如type(),dir(),getattr(),hasattr(),isinstance(). 12345a = [1,2,3]b = &#123;&#x27;a&#x27;:1,&#x27;b&#x27;:2,&#x27;c&#x27;:3&#125;c = Trueprint type(a),type(b),type(c) # &lt;type &#x27;list&#x27;&gt; &lt;type &#x27;dict&#x27;&gt; &lt;type &#x27;bool&#x27;&gt;print isinstance(a,list) # True 6 字典推导式可能你见过列表推导时,却没有见过字典推导式,在2.7中才加入的: 1d = &#123;key: value for (key, value) in iterable&#125; 7 Python中单下划线和双下划线1234567891011121314&gt;&gt;&gt; class MyClass():... def __init__(self):... self.__superprivate = &quot;Hello&quot;... self._semiprivate = &quot;, world!&quot;...&gt;&gt;&gt; mc = MyClass()&gt;&gt;&gt; print mc.__superprivateTraceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;AttributeError: myClass instance has no attribute &#x27;__superprivate&#x27;&gt;&gt;&gt; print mc._semiprivate, world!&gt;&gt;&gt; print mc.__dict__&#123;&#x27;_MyClass__superprivate&#x27;: &#x27;Hello&#x27;, &#x27;_semiprivate&#x27;: &#x27;, world!&#x27;&#125; __foo__:一种约定,Python内部的名字,用来区别其他用户自定义的命名,以防冲突，就是例如__init__(),__del__(),__call__()这些特殊方法 _foo:一种约定,用来指定变量私有.程序员用来指定私有变量的一种方式.不能用from module import * 导入，其他方面和公有一样访问； __foo:这个有真正的意义:解析器用_classname__foo来代替这个名字,以区别和其他类相同的命名,它无法直接像公有成员一样随便访问,通过对象名._类名__xxx这样的方式可以访问. 详情见:http://stackoverflow.com/questions/1301346/the-meaning-of-a-single-and-a-double-underscore-before-an-object-name-in-python 或者: http://www.zhihu.com/question/19754941 8 字符串格式化:%和.format.format在许多方面看起来更便利.对于%最烦人的是它无法同时传递一个变量和元组.你可能会想下面的代码不会有什么问题: 1&quot;hi there %s&quot; % name 但是,如果name恰好是(1,2,3),它将会抛出一个TypeError异常.为了保证它总是正确的,你必须这样做: 1&quot;hi there %s&quot; % (name,) # 提供一个单元素的数组而不是一个参数 但是有点丑..format就没有这些问题.你给的第二个问题也是这样,.format好看多了. 你为什么不用它? 不知道它(在读这个之前) 为了和Python2.5兼容(譬如logging库建议使用%(issue #4)) http://stackoverflow.com/questions/5082452/python-string-formatting-vs-format 9 迭代器和生成器这个是stackoverflow里python排名第一的问题,值得一看: http://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do-in-python 这是中文版: http://taizilongxu.gitbooks.io/stackoverflow-about-python/content/1/README.html 这里有个关于生成器的创建问题面试官有考：问： 将列表生成式中[]改成() 之后数据结构是否改变？答案：是，从列表变为生成器 123456&gt;&gt;&gt; L = [x*x for x in range(10)]&gt;&gt;&gt; L[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]&gt;&gt;&gt; g = (x*x for x in range(10))&gt;&gt;&gt; g&lt;generator object &lt;genexpr&gt; at 0x0000028F8B774200&gt; 通过列表生成式，可以直接创建一个列表。但是，受到内存限制，列表容量肯定是有限的。而且，创建一个包含百万元素的列表，不仅是占用很大的内存空间，如：我们只需要访问前面的几个元素，后面大部分元素所占的空间都是浪费的。因此，没有必要创建完整的列表（节省大量内存空间）。在Python中，我们可以采用生成器：边循环，边计算的机制—&gt;generator 10 *args and **kwargs用*args和**kwargs只是为了方便并没有强制使用它们. 当你不确定你的函数里将要传递多少参数时你可以用*args.例如,它可以传递任意数量的参数: 12345678&gt;&gt;&gt; def print_everything(*args): for count, thing in enumerate(args):... print &#x27;&#123;0&#125;. &#123;1&#125;&#x27;.format(count, thing)...&gt;&gt;&gt; print_everything(&#x27;apple&#x27;, &#x27;banana&#x27;, &#x27;cabbage&#x27;)0. apple1. banana2. cabbage 相似的,**kwargs允许你使用没有事先定义的参数名: 1234567&gt;&gt;&gt; def table_things(**kwargs):... for name, value in kwargs.items():... print &#x27;&#123;0&#125; = &#123;1&#125;&#x27;.format(name, value)...&gt;&gt;&gt; table_things(apple = &#x27;fruit&#x27;, cabbage = &#x27;vegetable&#x27;)cabbage = vegetableapple = fruit 你也可以混着用.命名参数首先获得参数值然后所有的其他参数都传递给*args和**kwargs.命名参数在列表的最前端.例如: 1def table_things(titlestring, **kwargs) *args和**kwargs可以同时在函数的定义中,但是*args必须在**kwargs前面. 当调用函数时你也可以用*和**语法.例如: 1234567&gt;&gt;&gt; def print_three_things(a, b, c):... print &#x27;a = &#123;0&#125;, b = &#123;1&#125;, c = &#123;2&#125;&#x27;.format(a,b,c)...&gt;&gt;&gt; mylist = [&#x27;aardvark&#x27;, &#x27;baboon&#x27;, &#x27;cat&#x27;]&gt;&gt;&gt; print_three_things(*mylist)a = aardvark, b = baboon, c = cat 就像你看到的一样,它可以传递列表(或者元组)的每一项并把它们解包.注意必须与它们在函数里的参数相吻合.当然,你也可以在函数定义或者函数调用时用*. http://stackoverflow.com/questions/3394835/args-and-kwargs 11 面向切面编程AOP和装饰器这个AOP一听起来有点懵,同学面阿里的时候就被问懵了… 装饰器是一个很著名的设计模式，经常被用于有切面需求的场景，较为经典的有插入日志、性能测试、事务处理等。装饰器是解决这类问题的绝佳设计，有了装饰器，我们就可以抽离出大量函数中与函数功能本身无关的雷同代码并继续重用。概括的讲，装饰器的作用就是为已经存在的对象添加额外的功能。 这个问题比较大,推荐: http://stackoverflow.com/questions/739654/how-can-i-make-a-chain-of-function-decorators-in-python 中文: http://taizilongxu.gitbooks.io/stackoverflow-about-python/content/3/README.html 12 鸭子类型“当看到一只鸟走起来像鸭子、游泳起来像鸭子、叫起来也像鸭子，那么这只鸟就可以被称为鸭子。” 我们并不关心对象是什么类型，到底是不是鸭子，只关心行为。 比如在python中，有很多file-like的东西，比如StringIO,GzipFile,socket。它们有很多相同的方法，我们把它们当作文件使用。 又比如list.extend()方法中,我们并不关心它的参数是不是list,只要它是可迭代的,所以它的参数可以是list/tuple/dict/字符串/生成器等. 鸭子类型在动态语言中经常使用，非常灵活，使得python不像java那样专门去弄一大堆的设计模式。 13 Python中重载引自知乎:http://www.zhihu.com/question/20053359 函数重载主要是为了解决两个问题。 可变参数类型。 可变参数个数。 另外，一个基本的设计原则是，仅仅当两个函数除了参数类型和参数个数不同以外，其功能是完全相同的，此时才使用函数重载，如果两个函数的功能其实不同，那么不应当使用重载，而应当使用一个名字不同的函数。 好吧，那么对于情况 1 ，函数功能相同，但是参数类型不同，python 如何处理？答案是根本不需要处理，因为 python 可以接受任何类型的参数，如果函数的功能相同，那么不同的参数类型在 python 中很可能是相同的代码，没有必要做成两个不同函数。 那么对于情况 2 ，函数功能相同，但参数个数不同，python 如何处理？大家知道，答案就是缺省参数。对那些缺少的参数设定为缺省参数即可解决问题。因为你假设函数功能相同，那么那些缺少的参数终归是需要用的。 好了，鉴于情况 1 跟 情况 2 都有了解决方案，python 自然就不需要函数重载了。 14 新式类和旧式类这个面试官问了,我说了老半天,不知道他问的真正意图是什么. stackoverflow 这篇文章很好的介绍了新式类的特性: http://www.cnblogs.com/btchenguang/archive/2012/09/17/2689146.html 新式类很早在2.2就出现了,所以旧式类完全是兼容的问题,Python3里的类全部都是新式类.这里有一个MRO问题可以了解下(新式类继承是根据C3算法,旧式类是深度优先),&lt;Python核心编程&gt;里讲的也很多. 一个旧式类的深度优先的例子 12345678910111213141516class A(): def foo1(self): print &quot;A&quot;class B(A): def foo2(self): passclass C(A): def foo1(self): print &quot;C&quot;class D(B, C): passd = D()d.foo1()# A 按照经典类的查找顺序从左到右深度优先的规则，在访问d.foo1()的时候,D这个类是没有的..那么往上查找,先找到B,里面没有,深度优先,访问A,找到了foo1(),所以这时候调用的是A的foo1()，从而导致C重写的foo1()被绕过 15 __new__和__init__的区别这个__new__确实很少见到,先做了解吧. __new__是一个静态方法,而__init__是一个实例方法. __new__方法会返回一个创建的实例,而__init__什么都不返回. 只有在__new__返回一个cls的实例时后面的__init__才能被调用. 当创建一个新实例时调用__new__,初始化一个实例时用__init__. stackoverflow ps: __metaclass__是创建类时起作用.所以我们可以分别使用__metaclass__,__new__和__init__来分别在类创建,实例创建和实例初始化的时候做一些小手脚. 16 单例模式 ​ 单例模式是一种常用的软件设计模式。在它的核心结构中只包含一个被称为单例类的特殊类。通过单例模式可以保证系统中一个类只有一个实例而且该实例易于外界访问，从而方便对实例个数的控制并节约系统资源。如果希望在系统中某个类的对象只能存在一个，单例模式是最好的解决方案。 __new__()在__init__()之前被调用，用于生成实例对象。利用这个方法和类的属性的特点可以实现设计模式的单例模式。单例模式是指创建唯一对象，单例模式设计的类只能实例这个绝对常考啊.绝对要记住1~2个方法,当时面试官是让手写的. 1 使用__new__方法123456789class Singleton(object): def __new__(cls, *args, **kw): if not hasattr(cls, &#x27;_instance&#x27;): orig = super(Singleton, cls) cls._instance = orig.__new__(cls, *args, **kw) return cls._instanceclass MyClass(Singleton): a = 1 2 共享属性创建实例时把所有实例的__dict__指向同一个字典,这样它们具有相同的属性和方法. 12345678910class Borg(object): _state = &#123;&#125; def __new__(cls, *args, **kw): ob = super(Borg, cls).__new__(cls, *args, **kw) ob.__dict__ = cls._state return obclass MyClass2(Borg): a = 1 3 装饰器版本1234567891011def singleton(cls): instances = &#123;&#125; def getinstance(*args, **kw): if cls not in instances: instances[cls] = cls(*args, **kw) return instances[cls] return getinstance@singletonclass MyClass: ... 4 import方法作为python的模块是天然的单例模式 123456789101112# mysingleton.pyclass My_Singleton(object): def foo(self): passmy_singleton = My_Singleton()# to usefrom mysingleton import my_singletonmy_singleton.foo() 单例模式伯乐在线详细解释 17 Python中的作用域Python 中，一个变量的作用域总是由在代码中被赋值的地方所决定的。 当 Python 遇到一个变量的话他会按照这样的顺序进行搜索： 本地作用域（Local）→当前作用域被嵌入的本地作用域（Enclosing locals）→全局/模块作用域（Global）→内置作用域（Built-in） 18 GIL线程全局锁线程全局锁(Global Interpreter Lock),即Python为了保证线程安全而采取的独立线程运行的限制,说白了就是一个核只能在同一时间运行一个线程.对于io密集型任务，python的多线程起到作用，但对于cpu密集型任务，python的多线程几乎占不到任何优势，还有可能因为争夺资源而变慢。 见Python 最难的问题 解决办法就是多进程和下面的协程(协程也只是单CPU,但是能减小切换代价提升性能). 19 协程知乎被问到了,呵呵哒,跪了 简单点说协程是进程和线程的升级版,进程和线程都面临着内核态和用户态的切换问题而耗费许多切换时间,而协程就是用户自己控制切换的时机,不再需要陷入系统的内核态. Python里最常见的yield就是协程的思想!可以查看第九个问题. 20 闭包闭包(closure)是函数式编程的重要的语法结构。闭包也是一种组织代码的结构，它同样提高了代码的可重复使用性。 当一个内嵌函数引用其外部作作用域的变量,我们就会得到一个闭包. 总结一下,创建一个闭包必须满足以下几点: 必须有一个内嵌函数 内嵌函数必须引用外部函数中的变量 外部函数的返回值必须是内嵌函数 感觉闭包还是有难度的,几句话是说不明白的,还是查查相关资料. 重点是函数运行后并不会被撤销,就像16题的instance字典一样,当函数运行完后,instance并不被销毁,而是继续留在内存空间里.这个功能类似类里的类变量,只不过迁移到了函数上. 闭包就像个空心球一样,你知道外面和里面,但你不知道中间是什么样. 21 lambda函数其实就是一个匿名函数,为什么叫lambda?因为和后面的函数式编程有关. 推荐: 知乎 22 Python函数式编程这个需要适当的了解一下吧,毕竟函数式编程在Python中也做了引用. 推荐: 酷壳 python中函数式编程支持: filter 函数的功能相当于过滤器。调用一个布尔函数bool_func来迭代遍历每个seq中的元素；返回一个使bool_seq返回值为true的元素的序列。 1234&gt;&gt;&gt;a = [1,2,3,4,5,6,7]&gt;&gt;&gt;b = filter(lambda x: x &gt; 5, a)&gt;&gt;&gt;print b&gt;&gt;&gt;[6,7] map函数是对一个序列的每个项依次执行函数，下面是对一个序列每个项都乘以2： 123&gt;&gt;&gt; a = map(lambda x:x*2,[1,2,3])&gt;&gt;&gt; list(a)[2, 4, 6] reduce函数是对一个序列的每个项迭代调用函数，下面是求3的阶乘： 12&gt;&gt;&gt; reduce(lambda x,y:x*y,range(1,4))6 23 Python里的拷贝引用和copy(),deepcopy()的区别 1234567891011121314151617181920import copya = [1, 2, 3, 4, [&#x27;a&#x27;, &#x27;b&#x27;]] #原始对象b = a #赋值，传对象的引用c = copy.copy(a) #对象拷贝，浅拷贝d = copy.deepcopy(a) #对象拷贝，深拷贝a.append(5) #修改对象aa[4].append(&#x27;c&#x27;) #修改对象a中的[&#x27;a&#x27;, &#x27;b&#x27;]数组对象print &#x27;a = &#x27;, aprint &#x27;b = &#x27;, bprint &#x27;c = &#x27;, cprint &#x27;d = &#x27;, d输出结果：a = [1, 2, 3, 4, [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;], 5]b = [1, 2, 3, 4, [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;], 5]c = [1, 2, 3, 4, [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;]]d = [1, 2, 3, 4, [&#x27;a&#x27;, &#x27;b&#x27;]] 24 Python垃圾回收机制Python GC主要使用引用计数（reference counting）来跟踪和回收垃圾。在引用计数的基础上，通过“标记-清除”（mark and sweep）解决容器对象可能产生的循环引用问题，通过“分代回收”（generation collection）以空间换时间的方法提高垃圾回收效率。 1 引用计数PyObject是每个对象必有的内容，其中ob_refcnt就是做为引用计数。当一个对象有新的引用时，它的ob_refcnt就会增加，当引用它的对象被删除，它的ob_refcnt就会减少.引用计数为0时，该对象生命就结束了。 优点: 简单 实时性 缺点: 维护引用计数消耗资源 循环引用 2 标记-清除机制基本思路是先按需分配，等到没有空闲内存的时候从寄存器和程序栈上的引用出发，遍历以对象为节点、以引用为边构成的图，把所有可以访问到的对象打上标记，然后清扫一遍内存空间，把所有没标记的对象释放。 3 分代技术分代回收的整体思想是：将系统中的所有内存块根据其存活时间划分为不同的集合，每个集合就成为一个“代”，垃圾收集频率随着“代”的存活时间的增大而减小，存活时间通常利用经过几次垃圾回收来度量。 Python默认定义了三代对象集合，索引数越大，对象存活时间越长。 举例：当某些内存块M经过了3次垃圾收集的清洗之后还存活时，我们就将内存块M划到一个集合A中去，而新分配的内存都划分到集合B中去。当垃圾收集开始工作时，大多数情况都只对集合B进行垃圾回收，而对集合A进行垃圾回收要隔相当长一段时间后才进行，这就使得垃圾收集机制需要处理的内存少了，效率自然就提高了。在这个过程中，集合B中的某些内存块由于存活时间长而会被转移到集合A中，当然，集合A中实际上也存在一些垃圾，这些垃圾的回收会因为这种分代的机制而被延迟。 25 Python的List推荐: http://www.jianshu.com/p/J4U6rR 26 Python的isis是对比地址,==是对比值 27 read,readline和readlines read 读取整个文件 readline 读取下一行,使用生成器方法 readlines 读取整个文件到一个迭代器以供我们遍历 28 Python2和3的区别推荐：Python 2.7.x 与 Python 3.x 的主要差异 29 super initsuper() lets you avoid referring to the base class explicitly, which can be nice. But the main advantage comes with multiple inheritance, where all sorts of fun stuff can happen. See the standard docs on super if you haven’t already. Note that the syntax changed in Python 3.0: you can just say super().__init__() instead of super(ChildB, self).__init__() which IMO is quite a bit nicer. http://stackoverflow.com/questions/576169/understanding-python-super-with-init-methods Python2.7中的super方法浅见 30 range and xrange都在循环时使用，xrange内存性能更好。for i in range(0, 20):for i in xrange(0, 20):What is the difference between range and xrange functions in Python 2.X? range creates a list, so if you do range(1, 10000000) it creates a list in memory with 9999999 elements. xrange is a sequence object that evaluates lazily. http://stackoverflow.com/questions/94935/what-is-the-difference-between-range-and-xrange-functions-in-python-2-x 操作系统1 select,poll和epoll其实所有的I/O都是轮询的方法,只不过实现的层面不同罢了. 这个问题可能有点深入了,但相信能回答出这个问题是对I/O多路复用有很好的了解了.其中tornado使用的就是epoll的. selec,poll和epoll区别总结 基本上select有3个缺点: 连接数受限 查找配对速度慢 数据由内核拷贝到用户态 poll改善了第一个缺点 epoll改了三个缺点. 关于epoll的: http://www.cnblogs.com/my_life/articles/3968782.html 2 调度算法 先来先服务(FCFS, First Come First Serve) 短作业优先(SJF, Shortest Job First) 最高优先权调度(Priority Scheduling) 时间片轮转(RR, Round Robin) 多级反馈队列调度(multilevel feedback queue scheduling) 常见的调度算法总结:http://www.jianshu.com/p/6edf8174c1eb 实时调度算法: 最早截至时间优先 EDF 最低松弛度优先 LLF 3 死锁原因: 竞争资源 程序推进顺序不当 必要条件: 互斥条件 请求和保持条件 不剥夺条件 环路等待条件 处理死锁基本方法: 预防死锁(摒弃除1以外的条件) 避免死锁(银行家算法) 检测死锁(资源分配图) 解除死锁 剥夺资源 撤销进程 死锁概念处理策略详细介绍:https://wizardforcel.gitbooks.io/wangdaokaoyan-os/content/10.html 4 程序编译与链接推荐: http://www.ruanyifeng.com/blog/2014/11/compiler.html Bulid过程可以分解为4个步骤:预处理(Prepressing), 编译(Compilation)、汇编(Assembly)、链接(Linking) 以c语言为例: 1 预处理预编译过程主要处理那些源文件中的以“#”开始的预编译指令，主要处理规则有： 将所有的“#define”删除，并展开所用的宏定义 处理所有条件预编译指令，比如“#if”、“#ifdef”、 “#elif”、“#endif” 处理“#include”预编译指令，将被包含的文件插入到该编译指令的位置，注：此过程是递归进行的 删除所有注释 添加行号和文件名标识，以便于编译时编译器产生调试用的行号信息以及用于编译时产生编译错误或警告时可显示行号 保留所有的#pragma编译器指令。 2 编译编译过程就是把预处理完的文件进行一系列的词法分析、语法分析、语义分析及优化后生成相应的汇编代码文件。这个过程是整个程序构建的核心部分。 3 汇编汇编器是将汇编代码转化成机器可以执行的指令，每一条汇编语句几乎都是一条机器指令。经过编译、链接、汇编输出的文件成为目标文件(Object File) 4 链接链接的主要内容就是把各个模块之间相互引用的部分处理好，使各个模块可以正确的拼接。链接的主要过程包块 地址和空间的分配（Address and Storage Allocation）、符号决议(Symbol Resolution)和重定位(Relocation)等步骤。 5 静态链接和动态链接静态链接方法：静态链接的时候，载入代码就会把程序会用到的动态代码或动态代码的地址确定下来静态库的链接可以使用静态链接，动态链接库也可以使用这种方法链接导入库 动态链接方法：使用这种方式的程序并不在一开始就完成动态链接，而是直到真正调用动态库代码时，载入程序才计算(被调用的那部分)动态代码的逻辑地址，然后等到某个时候，程序又需要调用另外某块动态代码时，载入程序又去计算这部分代码的逻辑地址，所以，这种方式使程序初始化时间较短，但运行期间的性能比不上静态链接的程序 6 虚拟内存技术虚拟存储器是指具有请求调入功能和置换功能,能从逻辑上对内存容量加以扩充的一种存储系统. 7 分页和分段分页: 用户程序的地址空间被划分成若干固定大小的区域，称为“页”，相应地，内存空间分成若干个物理块，页和块的大小相等。可将用户程序的任一页放在内存的任一块中，实现了离散分配。 分段: 将用户程序地址空间分成若干个大小不等的段，每段可以定义一组相对完整的逻辑信息。存储分配时，以段为单位，段与段在内存中可以不相邻接，也实现了离散分配。 分页与分段的主要区别 页是信息的物理单位,分页是为了实现非连续分配,以便解决内存碎片问题,或者说分页是由于系统管理的需要.段是信息的逻辑单位,它含有一组意义相对完整的信息,分段的目的是为了更好地实现共享,满足用户的需要. 页的大小固定,由系统确定,将逻辑地址划分为页号和页内地址是由机器硬件实现的.而段的长度却不固定,决定于用户所编写的程序,通常由编译程序在对源程序进行编译时根据信息的性质来划分. 分页的作业地址空间是一维的.分段的地址空间是二维的. 8 页面置换算法 最佳置换算法OPT:不可能实现 先进先出FIFO 最近最久未使用算法LRU:最近一段时间里最久没有使用过的页面予以置换. clock算法 9 边沿触发和水平触发边缘触发是指每当状态变化时发生一个 io 事件，条件触发是只要满足条件就发生一个 io 事件 数据库1 事务数据库事务(Database Transaction) ，是指作为单个逻辑工作单元执行的一系列操作，要么完全地执行，要么完全地不执行。彻底理解数据库事务: http://www.hollischuang.com/archives/898 2 数据库索引推荐: http://tech.meituan.com/mysql-index.html MySQL索引背后的数据结构及算法原理 聚集索引,非聚集索引,B-Tree,B+Tree,最左前缀原理 3 Redis原理Redis是什么？ 是一个完全开源免费的key-value内存数据库 通常被认为是一个数据结构服务器，主要是因为其有着丰富的数据结构 strings、map、 list、sets、 sorted sets Redis数据库 ​ 通常局限点来说，Redis也以消息队列的形式存在，作为内嵌的List存在，满足实时的高并发需求。在使用缓存的时候，redis比memcached具有更多的优势，并且支持更多的数据类型，把redis当作一个中间存储系统，用来处理高并发的数据库操作 速度快：使用标准C写，所有数据都在内存中完成，读写速度分别达到10万/20万 持久化：对数据的更新采用Copy-on-write技术，可以异步地保存到磁盘上，主要有两种策略，一是根据时间，更新次数的快照（save 300 10 ）二是基于语句追加方式(Append-only file，aof) 自动操作：对不同数据类型的操作都是自动的，很安全 快速的主–从复制，官方提供了一个数据，Slave在21秒即完成了对Amazon网站10G key set的复制。 Sharding技术： 很容易将数据分布到多个Redis实例中，数据库的扩展是个永恒的话题，在关系型数据库中，主要是以添加硬件、以分区为主要技术形式的纵向扩展解决了很多的应用场景，但随着web2.0、移动互联网、云计算等应用的兴起，这种扩展模式已经不太适合了，所以近年来，像采用主从配置、数据库复制形式的，Sharding这种技术把负载分布到多个特理节点上去的横向扩展方式用处越来越多。 Redis缺点 是数据库容量受到物理内存的限制,不能用作海量数据的高性能读写,因此Redis适合的场景主要局限在较小数据量的高性能操作和运算上。 Redis较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。为避免这一问题，运维人员在系统上线时必须确保有足够的空间，这对资源造成了很大的浪费。 4 乐观锁和悲观锁悲观锁：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作 乐观锁：假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。 乐观锁与悲观锁的具体区别: http://www.cnblogs.com/Bob-FD/p/3352216.html 5 MVCC ​ 全称是Multi-Version Concurrent Control，即多版本并发控制，在MVCC协议下，每个读操作会看到一个一致性的snapshot，并且可以实现非阻塞的读。MVCC允许数据具有多个版本，这个版本可以是时间戳或者是全局递增的事务ID，在同一个时间点，不同的事务看到的数据是不同的。 MySQL的innodb引擎是如何实现MVCC的innodb会为每一行添加两个字段，分别表示该行创建的版本和删除的版本，填入的是事务的版本号，这个版本号随着事务的创建不断递增。在repeated read的隔离级别（事务的隔离级别请看这篇文章）下，具体各种数据库操作的实现： select：满足以下两个条件innodb会返回该行数据： 该行的创建版本号小于等于当前版本号，用于保证在select操作之前所有的操作已经执行落地。 该行的删除版本号大于当前版本或者为空。删除版本号大于当前版本意味着有一个并发事务将该行删除了。 insert：将新插入的行的创建版本号设置为当前系统的版本号。 delete：将要删除的行的删除版本号设置为当前系统的版本号。 update：不执行原地update，而是转换成insert + delete。将旧行的删除版本号设置为当前版本号，并将新行insert同时设置创建版本号为当前版本号。 其中，写操作（insert、delete和update）执行时，需要将系统版本号递增。 ​ 由于旧数据并不真正的删除，所以必须对这些数据进行清理，innodb会开启一个后台线程执行清理工作，具体的规则是将删除版本号小于当前系统版本的行删除，这个过程叫做purge。 通过MVCC很好的实现了事务的隔离性，可以达到repeated read级别，要实现serializable还必须加锁。 参考：MVCC浅析 6 MyISAM和InnoDBMyISAM 适合于一些需要大量查询的应用，但其对于有大量写操作并不是很好。甚至你只是需要update一个字段，整个表都会被锁起来，而别的进程，就算是读进程都无法操作直到读操作完成。另外，MyISAM 对于 SELECT COUNT(*) 这类的计算是超快无比的。 InnoDB 的趋势会是一个非常复杂的存储引擎，对于一些小的应用，它会比 MyISAM 还慢。他是它支持“行锁” ，于是在写操作比较多的时候，会更优秀。并且，他还支持更多的高级应用，比如：事务。 mysql 数据库引擎: http://www.cnblogs.com/0201zcr/p/5296843.htmlMySQL存储引擎－－MyISAM与InnoDB区别: https://segmentfault.com/a/1190000008227211 网络1 三次握手 客户端通过向服务器端发送一个SYN来创建一个主动打开，作为三次握手的一部分。客户端把这段连接的序号设定为随机数 A。 服务器端应当为一个合法的SYN回送一个SYN/ACK。ACK 的确认码应为 A+1，SYN/ACK 包本身又有一个随机序号 B。 最后，客户端再发送一个ACK。当服务端受到这个ACK的时候，就完成了三路握手，并进入了连接创建状态。此时包序号被设定为收到的确认号 A+1，而响应则为 B+1。 2 四次挥手注意: 中断连接端可以是客户端，也可以是服务器端. 下面仅以客户端断开连接举例, 反之亦然. 客户端发送一个数据分段, 其中的 FIN 标记设置为1. 客户端进入 FIN-WAIT 状态. 该状态下客户端只接收数据, 不再发送数据. 服务器接收到带有 FIN = 1 的数据分段, 发送带有 ACK = 1 的剩余数据分段, 确认收到客户端发来的 FIN 信息. 服务器等到所有数据传输结束, 向客户端发送一个带有 FIN = 1 的数据分段, 并进入 CLOSE-WAIT 状态, 等待客户端发来带有 ACK = 1 的确认报文. 客户端收到服务器发来带有 FIN = 1 的报文, 返回 ACK = 1 的报文确认, 为了防止服务器端未收到需要重发, 进入 TIME-WAIT 状态. 服务器接收到报文后关闭连接. 客户端等待 2MSL 后未收到回复, 则认为服务器成功关闭, 客户端关闭连接. 图解: http://blog.csdn.net/whuslei/article/details/6667471 3 ARP协议地址解析协议(Address Resolution Protocol)，其基本功能为透过目标设备的IP地址，查询目标的MAC地址，以保证通信的顺利进行。它是IPv4网络层必不可少的协议，不过在IPv6中已不再适用，并被邻居发现协议（NDP）所替代。 4 urllib和urllib2的区别这个面试官确实问过,当时答的urllib2可以Post而urllib不可以. urllib提供urlencode方法用来GET查询字符串的产生，而urllib2没有。这是为何urllib常和urllib2一起使用的原因。 urllib2可以接受一个Request类的实例来设置URL请求的headers，urllib仅可以接受URL。这意味着，你不可以伪装你的User Agent字符串等。 5 Post和GetGET和POST有什么区别？及为什么网上的多数答案都是错的知乎回答 get: RFC 2616 - Hypertext Transfer Protocol – HTTP/1.1post: RFC 2616 - Hypertext Transfer Protocol – HTTP/1.1 6 Cookie和Session Cookie Session 储存位置 客户端 服务器端 目的 跟踪会话，也可以保存用户偏好设置或者保存用户名密码等 跟踪会话 安全性 不安全 安全 session技术是要使用到cookie的，之所以出现session技术，主要是为了安全。 7 apache和nginx的区别nginx 相对 apache 的优点： 轻量级，同样起web 服务，比apache 占用更少的内存及资源 抗并发，nginx 处理请求是异步非阻塞的，支持更多的并发连接，而apache 则是阻塞型的，在高并发下nginx 能保持低资源低消耗高性能 配置简洁 高度模块化的设计，编写模块相对简单 社区活跃 apache 相对nginx 的优点： rewrite ，比nginx 的rewrite 强大 模块超多，基本想到的都可以找到 少bug ，nginx 的bug 相对较多 超稳定 8 网站用户密码保存 明文保存 明文hash后保存,如md5 MD5+Salt方式,这个salt可以随机 知乎使用了Bcrypy(好像)加密 9 HTTP和HTTPS 状态码 定义 1xx 报告 接收到请求，继续进程 2xx 成功 步骤成功接收，被理解，并被接受 3xx 重定向 为了完成请求,必须采取进一步措施 4xx 客户端出错 请求包括错的顺序或不能完成 5xx 服务器出错 服务器无法完成显然有效的请求 403: Forbidden404: Not Found HTTPS握手,对称加密,非对称加密,TLS/SSL,RSA 10 XSRF和XSS CSRF(Cross-site request forgery)跨站请求伪造 XSS(Cross Site Scripting)跨站脚本攻击 CSRF重点在请求,XSS重点在脚本 11 幂等 IdempotenceHTTP方法的幂等性是指一次和多次请求某一个资源应该具有同样的副作用。(注意是副作用) GET http://www.bank.com/account/123456，不会改变资源的状态，不论调用一次还是N次都没有副作用。请注意，这里强调的是一次和N次具有相同的副作用，而不是每次GET的结果相同。GET http://www.news.com/latest-news这个HTTP请求可能会每次得到不同的结果，但它本身并没有产生任何副作用，因而是满足幂等性的。 DELETE方法用于删除资源，有副作用，但它应该满足幂等性。比如：DELETE http://www.forum.com/article/4231，调用一次和N次对系统产生的副作用是相同的，即删掉id为4231的帖子；因此，调用者可以多次调用或刷新页面而不必担心引起错误。 POST所对应的URI并非创建的资源本身，而是资源的接收者。比如：POST http://www.forum.com/articles的语义是在http://www.forum.com/articles下创建一篇帖子，HTTP响应中应包含帖子的创建状态以及帖子的URI。两次相同的POST请求会在服务器端创建两份资源，它们具有不同的URI；所以，POST方法不具备幂等性。 PUT所对应的URI是要创建或更新的资源本身。比如：PUT http://www.forum/articles/4231的语义是创建或更新ID为4231的帖子。对同一URI进行多次PUT的副作用和一次PUT是相同的；因此，PUT方法具有幂等性。 12 RESTful架构(SOAP,RPC)推荐: http://www.ruanyifeng.com/blog/2011/09/restful.html 13 SOAPSOAP（原为Simple Object Access Protocol的首字母缩写，即简单对象访问协议）是交换数据的一种协议规范，使用在计算机网络Web服务（web service）中，交换带结构信息。SOAP为了简化网页服务器（Web Server）从XML数据库中提取数据时，节省去格式化页面时间，以及不同应用程序之间按照HTTP通信协议，遵从XML格式执行资料互换，使其抽象于语言实现、平台和硬件。 14 RPCRPC（Remote Procedure Call Protocol）——远程过程调用协议，它是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议。RPC协议假定某些传输协议的存在，如TCP或UDP，为通信程序之间携带信息数据。在OSI网络通信模型中，RPC跨越了传输层和应用层。RPC使得开发包括网络分布式多程序在内的应用程序更加容易。 总结:服务提供的两大流派.传统意义以方法调用为导向通称RPC。为了企业SOA,若干厂商联合推出webservice,制定了wsdl接口定义,传输soap.当互联网时代,臃肿SOA被简化为http+xml/json.但是简化出现各种混乱。以资源为导向,任何操作无非是对资源的增删改查，于是统一的REST出现了. 进化的顺序: RPC -&gt; SOAP -&gt; RESTful 15 CGI和WSGICGI是通用网关接口，是连接web服务器和应用程序的接口，用户通过CGI来获取动态数据或文件等。CGI程序是一个独立的程序，它可以用几乎所有语言来写，包括perl，c，lua，python等等。 WSGI, Web Server Gateway Interface，是Python应用程序或框架和Web服务器之间的一种接口，WSGI的其中一个目的就是让用户可以用统一的语言(Python)编写前后端。 官方说明：PEP-3333 16 中间人攻击在GFW里屡见不鲜的,呵呵. 中间人攻击（Man-in-the-middle attack，通常缩写为MITM）是指攻击者与通讯的两端分别创建独立的联系，并交换其所收到的数据，使通讯的两端认为他们正在通过一个私密的连接与对方直接对话，但事实上整个会话都被攻击者完全控制。 17 c10k问题所谓c10k问题，指的是服务器同时支持成千上万个客户端的问题，也就是concurrent 10 000 connection（这也是c10k这个名字的由来）。推荐: https://my.oschina.net/xianggao/blog/664275 18 socket推荐: http://www.360doc.com/content/11/0609/15/5482098_122692444.shtml Socket=Ip address+ TCP/UDP + port 19 浏览器缓存推荐: http://www.cnblogs.com/skynet/archive/2012/11/28/2792503.html 304 Not Modified 20 HTTP1.0和HTTP1.1推荐: http://blog.csdn.net/elifefly/article/details/3964766 请求头Host字段,一个服务器多个网站 长链接 文件断点续传 身份认证,状态管理,Cache缓存 HTTP请求8种方法介绍HTTP/1.1协议中共定义了8种HTTP请求方法，HTTP请求方法也被叫做“请求动作”，不同的方法规定了不同的操作指定的资源方式。服务端也会根据不同的请求方法做不同的响应。 GET GET请求会显示请求指定的资源。一般来说GET方法应该只用于数据的读取，而不应当用于会产生副作用的非幂等的操作中。 GET会方法请求指定的页面信息，并返回响应主体，GET被认为是不安全的方法，因为GET方法会被网络蜘蛛等任意的访问。 HEAD HEAD方法与GET方法一样，都是向服务器发出指定资源的请求。但是，服务器在响应HEAD请求时不会回传资源的内容部分，即：响应主体。这样，我们可以不传输全部内容的情况下，就可以获取服务器的响应头信息。HEAD方法常被用于客户端查看服务器的性能。 POST POST请求会 向指定资源提交数据，请求服务器进行处理，如：表单数据提交、文件上传等，请求数据会被包含在请求体中。POST方法是非幂等的方法，因为这个请求可能会创建新的资源或/和修改现有资源。 PUT PUT请求会身向指定资源位置上传其最新内容，PUT方法是幂等的方法。通过该方法客户端可以将指定资源的最新数据传送给服务器取代指定的资源的内容。 DELETE DELETE请求用于请求服务器删除所请求URI（统一资源标识符，Uniform Resource Identifier）所标识的资源。DELETE请求后指定资源会被删除，DELETE方法也是幂等的。 CONNECT CONNECT方法是HTTP/1.1协议预留的，能够将连接改为管道方式的代理服务器。通常用于SSL加密服务器的链接与非加密的HTTP代理服务器的通信。 OPTIONS OPTIONS请求与HEAD类似，一般也是用于客户端查看服务器的性能。 这个方法会请求服务器返回该资源所支持的所有HTTP请求方法，该方法会用’*’来代替资源名称，向服务器发送OPTIONS请求，可以测试服务器功能是否正常。JavaScript的XMLHttpRequest对象进行CORS跨域资源共享时，就是使用OPTIONS方法发送嗅探请求，以判断是否有对指定资源的访问权限。 允许 TRACE TRACE请求服务器回显其收到的请求信息，该方法主要用于HTTP请求的测试或诊断。 HTTP/1.1之后增加的方法 在HTTP/1.1标准制定之后，又陆续扩展了一些方法。其中使用中较多的是 PATCH 方法： PATCH PATCH方法出现的较晚，它在2010年的RFC 5789标准中被定义。PATCH请求与PUT请求类似，同样用于资源的更新。二者有以下两点不同： 但PATCH一般用于资源的部分更新，而PUT一般用于资源的整体更新。当资源不存在时，PATCH会创建一个新的资源，而PUT只会对已在资源进行更新。 21 AjaxAJAX,Asynchronous JavaScript and XML（异步的 JavaScript 和 XML）, 是与在不重新加载整个页面的情况下，与服务器交换数据并更新部分网页的技术。 *NIXunix进程间通信方式(IPC) 管道（Pipe）：管道可用于具有亲缘关系进程间的通信，允许一个进程和另一个与它有共同祖先的进程之间进行通信。 命名管道（named pipe）：命名管道克服了管道没有名字的限制，因此，除具有管道所具有的功能外，它还允许无亲缘关系进程间的通信。命名管道在文件系统中有对应的文件名。命名管道通过命令mkfifo或系统调用mkfifo来创建。 信号（Signal）：信号是比较复杂的通信方式，用于通知接受进程有某种事件发生，除了用于进程间通信外，进程还可以发送信号给进程本身；linux除了支持Unix早期信号语义函数sigal外，还支持语义符合Posix.1标准的信号函数sigaction（实际上，该函数是基于BSD的，BSD为了实现可靠信号机制，又能够统一对外接口，用sigaction函数重新实现了signal函数）。 消息（Message）队列：消息队列是消息的链接表，包括Posix消息队列system V消息队列。有足够权限的进程可以向队列中添加消息，被赋予读权限的进程则可以读走队列中的消息。消息队列克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺 共享内存：使得多个进程可以访问同一块内存空间，是最快的可用IPC形式。是针对其他通信机制运行效率较低而设计的。往往与其它通信机制，如信号量结合使用，来达到进程间的同步及互斥。 内存映射（mapped memory）：内存映射允许任何多个进程间通信，每一个使用该机制的进程通过把一个共享的文件映射到自己的进程地址空间来实现它。 信号量（semaphore）：主要作为进程间以及同一进程不同线程之间的同步手段。 套接口（Socket）：更为一般的进程间通信机制，可用于不同机器之间的进程间通信。起初是由Unix系统的BSD分支开发出来的，但现在一般可以移植到其它类Unix系统上：Linux和System V的变种都支持套接字。 数据结构1 红黑树红黑树与AVL的比较： AVL是严格平衡树，因此在增加或者删除节点的时候，根据不同情况，旋转的次数比红黑树要多； 红黑是用非严格的平衡来换取增删节点时候旋转次数的降低； 所以简单说，如果你的应用中，搜索的次数远远大于插入和删除，那么选择AVL，如果搜索，插入删除次数几乎差不多，应该选择RB。 红黑树详解: https://xieguanglei.github.io/blog/post/red-black-tree.html 教你透彻了解红黑树: https://github.com/julycoding/The-Art-Of-Programming-By-July/blob/master/ebook/zh/03.01.md 编程题1 台阶问题/斐波那契一只青蛙一次可以跳上1级台阶，也可以跳上2级。求该青蛙跳上一个n级的台阶总共有多少种跳法。 1fib = lambda n: n if n &lt;= 2 else fib(n - 1) + fib(n - 2) 第二种记忆方法 1234567891011121314def memo(func): cache = &#123;&#125; def wrap(*args): if args not in cache: cache[args] = func(*args) return cache[args] return wrap@memodef fib(i): if i &lt; 2: return 1 return fib(i-1) + fib(i-2) 第三种方法 12345def fib(n): a, b = 0, 1 for _ in xrange(n): a, b = b, a + b return b 2 变态台阶问题一只青蛙一次可以跳上1级台阶，也可以跳上2级……它也可以跳上n级。求该青蛙跳上一个n级的台阶总共有多少种跳法。 1fib = lambda n: n if n &lt; 2 else 2 * fib(n - 1) 3 矩形覆盖我们可以用2*1的小矩形横着或者竖着去覆盖更大的矩形。请问用n个2*1的小矩形无重叠地覆盖一个2*n的大矩形，总共有多少种方法？ 第2*n个矩形的覆盖方法等于第2*(n-1)加上第2*(n-2)的方法。 1f = lambda n: 1 if n &lt; 2 else f(n - 1) + f(n - 2) 4 杨氏矩阵查找在一个m行n列二维数组中，每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。 使用Step-wise线性搜索。 1234567891011121314151617def get_value(l, r, c): return l[r][c]def find(l, x): m = len(l) - 1 n = len(l[0]) - 1 r = 0 c = n while c &gt;= 0 and r &lt;= m: value = get_value(l, r, c) if value == x: return True elif value &gt; x: c = c - 1 elif value &lt; x: r = r + 1 return False 5 去除列表中的重复元素用集合 1list(set(l)) 用字典 123l1 = [&#x27;b&#x27;,&#x27;c&#x27;,&#x27;d&#x27;,&#x27;b&#x27;,&#x27;c&#x27;,&#x27;a&#x27;,&#x27;a&#x27;]l2 = &#123;&#125;.fromkeys(l1).keys()print l2 用字典并保持顺序 1234l1 = [&#x27;b&#x27;,&#x27;c&#x27;,&#x27;d&#x27;,&#x27;b&#x27;,&#x27;c&#x27;,&#x27;a&#x27;,&#x27;a&#x27;]l2 = list(set(l1))l2.sort(key=l1.index)print l2 列表推导式 123l1 = [&#x27;b&#x27;,&#x27;c&#x27;,&#x27;d&#x27;,&#x27;b&#x27;,&#x27;c&#x27;,&#x27;a&#x27;,&#x27;a&#x27;]l2 = [][l2.append(i) for i in l1 if not i in l2] sorted排序并且用列表推导式. l = [‘b’,’c’,’d’,’b’,’c’,’a’,’a’][single.append(i) for i in sorted(l) if i not in single]print single 6 链表成对调换1-&gt;2-&gt;3-&gt;4转换成2-&gt;1-&gt;4-&gt;3. 123456789101112131415class ListNode: def __init__(self, x): self.val = x self.next = Noneclass Solution: # @param a ListNode # @return a ListNode def swapPairs(self, head): if head != None and head.next != None: next = head.next head.next = self.swapPairs(next.next) next.next = head return next return head 7 创建字典的方法1 直接创建1dict = &#123;&#x27;name&#x27;:&#x27;earth&#x27;, &#x27;port&#x27;:&#x27;80&#x27;&#125; 2 工厂方法123items=[(&#x27;name&#x27;,&#x27;earth&#x27;),(&#x27;port&#x27;,&#x27;80&#x27;)]dict2=dict(items)dict1=dict(([&#x27;name&#x27;,&#x27;earth&#x27;],[&#x27;port&#x27;,&#x27;80&#x27;])) 3 fromkeys()方法1234dict1=&#123;&#125;.fromkeys((&#x27;x&#x27;,&#x27;y&#x27;),-1)dict=&#123;&#x27;x&#x27;:-1,&#x27;y&#x27;:-1&#125;dict2=&#123;&#125;.fromkeys((&#x27;x&#x27;,&#x27;y&#x27;))dict2=&#123;&#x27;x&#x27;:None, &#x27;y&#x27;:None&#125; 8 合并两个有序列表知乎远程面试要求编程 尾递归 12345678910111213141516def _recursion_merge_sort2(l1, l2, tmp): if len(l1) == 0 or len(l2) == 0: tmp.extend(l1) tmp.extend(l2) return tmp else: if l1[0] &lt; l2[0]: tmp.append(l1[0]) del l1[0] else: tmp.append(l2[0]) del l2[0] return _recursion_merge_sort2(l1, l2, tmp)def recursion_merge_sort2(l1, l2): return _recursion_merge_sort2(l1, l2, []) 循环算法 思路： 定义一个新的空列表 比较两个列表的首个元素 小的就插入到新列表里 把已经插入新列表的元素从旧列表删除 直到两个旧列表有一个为空 再把旧列表加到新列表后面 123456789101112def loop_merge_sort(l1, l2): tmp &#x3D; [] while len(l1) &gt; 0 and len(l2) &gt; 0: if l1[0] &lt; l2[0]: tmp.append(l1[0]) del l1[0] else: tmp.append(l2[0]) del l2[0] tmp.extend(l1) tmp.extend(l2) return tmp pop弹出 1234567891011121314151617a = [1,2,3,7]b = [3,4,5]def merge_sortedlist(a,b): c = [] while a and b: if a[0] &gt;= b[0]: c.append(b.pop(0)) else: c.append(a.pop(0)) while a: c.append(a.pop(0)) while b: c.append(b.pop(0)) return cprint merge_sortedlist(a,b) 9 交叉链表求交点 其实思想可以按照从尾开始比较两个链表，如果相交，则从尾开始必然一致，只要从尾开始比较，直至不一致的地方即为交叉点，如图所示 1234567891011121314# 使用a,b两个list来模拟链表，可以看出交叉点是 7这个节点a = [1,2,3,7,9,1,5]b = [4,5,7,9,1,5]for i in range(1,min(len(a),len(b))): if i==1 and (a[-1] != b[-1]): print &quot;No&quot; break else: if a[-i] != b[-i]: print &quot;交叉节点：&quot;,a[-i+1] break else: pass 另外一种比较正规的方法，构造链表类 1234567891011121314151617181920212223242526class ListNode: def __init__(self, x): self.val = x self.next = Nonedef node(l1, l2): length1, lenth2 = 0, 0 # 求两个链表长度 while l1.next: l1 = l1.next length1 += 1 while l2.next: l2 = l2.next length2 += 1 # 长的链表先走 if length1 &gt; lenth2: for _ in range(length1 - length2): l1 = l1.next else: for _ in range(length2 - length1): l2 = l2.next while l1 and l2: if l1.next == l2.next: return l1.next else: l1 = l1.next l2 = l2.next 修改了一下: 123456789101112131415161718192021222324252627282930#coding:utf-8class ListNode: def __init__(self, x): self.val = x self.next = Nonedef node(l1, l2): length1, length2 = 0, 0 # 求两个链表长度 while l1.next: l1 = l1.next#尾节点 length1 += 1 while l2.next: l2 = l2.next#尾节点 length2 += 1 #如果相交 if l1.next == l2.next: # 长的链表先走 if length1 &gt; length2: for _ in range(length1 - length2): l1 = l1.next return l1#返回交点 else: for _ in range(length2 - length1): l2 = l2.next return l2#返回交点 # 如果不相交 else: return 思路: http://humaoli.blog.163.com/blog/static/13346651820141125102125995/ 10 二分查找123456789101112131415161718#coding:utf-8def binary_search(list, item): low = 0 high = len(list) - 1 while low &lt;= high: mid = (high - low) / 2 + low # 避免(high + low) / 2溢出 guess = list[mid] if guess &gt; item: high = mid - 1 elif guess &lt; item: low = mid + 1 else: return mid return Nonemylist = [1,3,5,7,9]print binary_search(mylist, 3) 参考: http://blog.csdn.net/u013205877/article/details/76411718 11 快排123456789101112#coding:utf-8def quicksort(list): if len(list)&lt;2: return list else: midpivot = list[0] lessbeforemidpivot = [i for i in list[1:] if i&lt;=midpivot] biggerafterpivot = [i for i in list[1:] if i &gt; midpivot] finallylist = quicksort(lessbeforemidpivot)+[midpivot]+quicksort(biggerafterpivot) return finallylistprint quicksort([2,4,6,7,1,2,5]) 更多排序问题可见：数据结构与算法-排序篇-Python描述 12 找零问题1234567891011121314151617181920#coding:utf-8#values是硬币的面值values = [ 25, 21, 10, 5, 1]#valuesCounts 钱币对应的种类数#money 找出来的总钱数#coinsUsed 对应于目前钱币总数i所使用的硬币数目def coinChange(values,valuesCounts,money,coinsUsed): #遍历出从1到money所有的钱数可能 for cents in range(1,money+1): minCoins = cents #把所有的硬币面值遍历出来和钱数做对比 for kind in range(0,valuesCounts): if (values[kind] &lt;= cents): temp = coinsUsed[cents - values[kind]] +1 if (temp &lt; minCoins): minCoins = temp coinsUsed[cents] = minCoins print (&#x27;面值:&#123;0&#125;的最少硬币使用数为:&#123;1&#125;&#x27;.format(cents, coinsUsed[cents])) 思路: http://blog.csdn.net/wdxin1322/article/details/9501163 方法: http://www.cnblogs.com/ChenxofHit/archive/2011/03/18/1988431.html 13 广度遍历和深度遍历二叉树给定一个数组，构建二叉树，并且按层次打印这个二叉树 14 二叉树节点123456789class Node(object): def __init__(self, data, left=None, right=None): self.data = data self.left = left self.right = righttree = Node(1, Node(3, Node(7, Node(0)), Node(6)), Node(2, Node(5), Node(4))) 15 层次遍历1234567def lookup(root): row = [root] while row: print(row) row = [kid for item in row for kid in (item.left, item.right) if kid] 16 深度遍历1234567891011def deep(root): if not root: return print root.data deep(root.left) deep(root.right)if __name__ == &#x27;__main__&#x27;: lookup(tree) deep(tree) 17 前中后序遍历深度遍历改变顺序就OK了 1234567891011121314151617181920212223242526272829303132333435363738#coding:utf-8#二叉树的遍历#简单的二叉树节点类class Node(object): def __init__(self,value,left,right): self.value = value self.left = left self.right = right#中序遍历:遍历左子树,访问当前节点,遍历右子树def mid_travelsal(root): if root.left is not None: mid_travelsal(root.left) #访问当前节点 print(root.value) if root.right is not None: mid_travelsal(root.right)#前序遍历:访问当前节点,遍历左子树,遍历右子树def pre_travelsal(root): print (root.value) if root.left is not None: pre_travelsal(root.left) if root.right is not None: pre_travelsal(root.right)#后续遍历:遍历左子树,遍历右子树,访问当前节点def post_trvelsal(root): if root.left is not None: post_trvelsal(root.left) if root.right is not None: post_trvelsal(root.right) print (root.value) 18 求最大树深1234def maxDepth(root): if not root: return 0 return max(maxDepth(root.left), maxDepth(root.right)) + 1 19 求两棵树是否相同1234567def isSameTree(p, q): if p == None and q == None: return True elif p and q : return p.val == q.val and isSameTree(p.left,q.left) and isSameTree(p.right,q.right) else : return False 20 前序中序求后序推荐: http://blog.csdn.net/hinyunsin/article/details/6315502 123456789101112131415def rebuild(pre, center): if not pre: return cur = Node(pre[0]) index = center.index(pre[0]) cur.left = rebuild(pre[1:index + 1], center[:index]) cur.right = rebuild(pre[index + 1:], center[index + 1:]) return curdef deep(root): if not root: return deep(root.left) deep(root.right) print root.data 21 单链表逆置12345678910111213141516171819202122class Node(object): def __init__(self, data=None, next=None): self.data = data self.next = nextlink = Node(1, Node(2, Node(3, Node(4, Node(5, Node(6, Node(7, Node(8, Node(9)))))))))def rev(link): pre = link cur = link.next pre.next = None while cur: tmp = cur.next cur.next = pre pre = cur cur = tmp return preroot = rev(link)while root: print root.data root = root.next 思路: http://blog.csdn.net/feliciafay/article/details/6841115 方法: http://www.xuebuyuan.com/2066385.html?mobile=1 22 两个字符串是否是变位词12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576class Anagram: &quot;&quot;&quot; @:param s1: The first string @:param s2: The second string @:return true or false &quot;&quot;&quot; def Solution1(s1,s2): alist = list(s2) pos1 = 0 stillOK = True while pos1 &lt; len(s1) and stillOK: pos2 = 0 found = False while pos2 &lt; len(alist) and not found: if s1[pos1] == alist[pos2]: found = True else: pos2 = pos2 + 1 if found: alist[pos2] = None else: stillOK = False pos1 = pos1 + 1 return stillOK print(Solution1(&#x27;abcd&#x27;,&#x27;dcba&#x27;)) def Solution2(s1,s2): alist1 = list(s1) alist2 = list(s2) alist1.sort() alist2.sort() pos = 0 matches = True while pos &lt; len(s1) and matches: if alist1[pos] == alist2[pos]: pos = pos + 1 else: matches = False return matches print(Solution2(&#x27;abcde&#x27;,&#x27;edcbg&#x27;)) def Solution3(s1,s2): c1 = [0]*26 c2 = [0]*26 for i in range(len(s1)): pos = ord(s1[i])-ord(&#x27;a&#x27;) c1[pos] = c1[pos] + 1 for i in range(len(s2)): pos = ord(s2[i])-ord(&#x27;a&#x27;) c2[pos] = c2[pos] + 1 j = 0 stillOK = True while j&lt;26 and stillOK: if c1[j] == c2[j]: j = j + 1 else: stillOK = False return stillOK print(Solution3(&#x27;apple&#x27;,&#x27;pleap&#x27;)) 23 动态规划问题 可参考：动态规划(DP)的整理-Python描述","categories":[{"name":"笔记","slug":"笔记","permalink":"https://fuyunliu.github.io/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Python3","slug":"Python3","permalink":"https://fuyunliu.github.io/tags/Python3/"}]},{"title":"数据科学中的各种相似性度量及其实现","slug":"similarity-measures-in-python","date":"2021-06-10T01:37:13.000Z","updated":"2021-06-10T06:33:27.963Z","comments":true,"path":"2021/06/10/similarity-measures-in-python/","link":"","permalink":"https://fuyunliu.github.io/2021/06/10/similarity-measures-in-python/","excerpt":"欧氏距离(Euclidean Distance)欧氏距离（也称欧几里得度量）指在 m 维空间中两个点之间的真实距离，或者向量的自然长度（即该点到原点的距离）。 123456789101112131415161718192021222324from math import *import numpy as npdef euclidean_distance(x, y): # 方法一 # d = sqrt(sum(pow(a - b, 2) for a, b in zip(x, y))) # 方法二 x, y = np.array(x), np.array(y) # d = np.linalg.norm(x - y, ord=2) d = np.sqrt(np.sum(np.square(x - y))) return dx = [1, 2, 3, 4, 5]y = [6, 7, 8, 9, 10]euclidean_distance(x, y) # 11.180339887498949from scipy.spatial.distance import euclideaneuclidean(x, y) # 11.180339887498949","text":"欧氏距离(Euclidean Distance)欧氏距离（也称欧几里得度量）指在 m 维空间中两个点之间的真实距离，或者向量的自然长度（即该点到原点的距离）。 123456789101112131415161718192021222324from math import *import numpy as npdef euclidean_distance(x, y): # 方法一 # d = sqrt(sum(pow(a - b, 2) for a, b in zip(x, y))) # 方法二 x, y = np.array(x), np.array(y) # d = np.linalg.norm(x - y, ord=2) d = np.sqrt(np.sum(np.square(x - y))) return dx = [1, 2, 3, 4, 5]y = [6, 7, 8, 9, 10]euclidean_distance(x, y) # 11.180339887498949from scipy.spatial.distance import euclideaneuclidean(x, y) # 11.180339887498949 标准化欧氏距离(Standardized Euclidean Distance)将各个分量都“标准化”到均值、方差相等所得出的距离。 12345from scipy.spatial.distance import seuclideanseuclidean([1, 0, 0], [0, 1, 0], [0.1, 0.1, 0.1]) # 4.4721359549995796seuclidean([1, 0, 0], [0, 1, 0], [1, 0.1, 0.1]) # 3.3166247903553998seuclidean([1, 0, 0], [0, 1, 0], [10, 0.1, 0.1]) # 3.1780497164141406 马氏距离(Mahalanobis Distance)马哈拉诺比斯距离是由印度统计学家马哈拉诺比斯提出的，表示数据的协方差距离。它是一种有效的计算两个未知样本集的相似度的方法。 123456from scipy.spatial.distance import mahalanobisiv = [[1, 0.5, 0.5], [0.5, 1, 0.5], [0.5, 0.5, 1]]mahalanobis([1, 0, 0], [0, 1, 0], iv) # 1.0mahalanobis([0, 2, 0], [0, 1, 0], iv) # 1.0mahalanobis([2, 0, 0], [0, 1, 0], iv) # 1.7320508075688772 编辑距离编辑距离是针对二个字符串的差异程度的量化量测，量测方式是看至少需要多少次的处理才能将一个字符串变成另一个字符串。 12345678import Levenshteins1 = &#x27;Hello, World!&#x27;s2 = &#x27;I am very happy!&#x27;Levenshtein.distance(s1, s2) # 14Levenshtein.ratio(s1, s2) # 0.20689655172413793 曼哈顿距离(Manhattan Distance)在欧几里得空间的固定直角坐标系上两点所形成的线段对轴产生的投影的距离总和。 123456789101112131415161718192021222324from math import *import numpy as npdef manhattan_distance(x, y): # 方法一 # d = sum(abs(a - b) for a, b in zip(x, y)) # 方法二 x, y = np.array(x), np.array(y) # d = np.linalg.norm(x - y, ord=1) d = np.sum(np.abs(x - y)) return dx = [1, 2, 3, 4, 5]y = [6, 7, 8, 9, 10]manhattan_distance(x, y) # 25from scipy.spatial.distance import cityblockcityblock(x, y) # 25 切比雪夫距离(Chebyshev Distance)数学上，切比雪夫距离或是L∞度量是向量空间中的一种度量，二个点之间的距离定义为其各座标数值差的最大值。 12345678910111213141516171819import numpy as npdef chebyshev_distance(x, y): x, y = np.array(x), np.array(y) # d = np.linalg.norm(x - y, ord=np.inf) d = np.abs(x - y).max() return dx = [1, 2, 3, 4, 5]y = [6, 7, 8, 9, 10]chebyshev_distance(x, y) # 5from scipy.spatial.distance import chebyshevchebyshev(x, y) # 5 闵可夫斯基距离(Minkowski Distance)明氏距离又叫做明可夫斯基距离，是欧氏空间中的一种测度，被看做是欧氏距离和曼哈顿距离的一种推广。 1234567891011121314151617181920212223242526272829303132333435from math import *from decimal import Decimaldef nth_root(value, n_root): root_value = 1 / float(n_root) return round(Decimal(value)**Decimal(root_value), 3)def minkowski_distance(x, y, p_value): d = nth_root(sum(pow(abs(a - b), p_value) for a, b in zip(x, y)), p_value) return dx = [1, 2, 3, 4, 5]y = [6, 7, 8, 9, 10]minkowski_distance(x, y, 1) # Decimal(&#x27;25.000&#x27;)minkowski_distance(x, y, 2) # Decimal(&#x27;11.180&#x27;)minkowski_distance(x, y, 3) # Decimal(&#x27;8.550&#x27;)import numpy as npdef minkowski_distance(x, y, ord=1): # ord = 1 一范数 # ord = 2 二范数 # ord = np.inf 无穷范数 d = np.linalg.norm(x - y, ord=ord) return dfrom scipy.spatial.distance import minkowskiminkowski(x, y, p=1) # 25.0minkowski(x, y, p=2) # 11.180339887498949minkowski(x, y, p=3) # 8.549879733383484 汉明距离(Hamming Distance)在信息论中，两个等长字符串之间的汉明距离是两个字符串对应位置的不同字符的个数。 123456789101112131415161718192021import numpy as npdef hamming_distance(x, y): x, y = np.array(x), np.array(y) # 方法一 # d = len(np.nonzero(x - y)[0]) # 方法二 d = np.shape(np.nonzero(x - y)[0])[0] return dx = [1, 2, 3, 4, 5]y = [6, 7, 8, 9, 10]hamming_distance(x, y) # 5from scipy.spatial.distance import hamminghamming(x, y) # 1.0 余弦相似度(Cosine Similarity)余弦相似性通过测量两个向量的夹角的余弦值来度量它们之间的相似性。 1234567891011121314151617def cosine_distance(x, y): x, y = np.array(x), np.array(y) d = np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y)) return dx = [1, 2, 3, 4, 5]y = [6, 7, 8, 9, 10]cosine_distance(x, y) # 0.9649505047327671from sklearn.metrics.pairwise import cosine_similarityx, y = np.array(x), np.array(y)cosine_similarity(x.reshape(1, -1), y.reshape(1, -1)) # array([[0.9649505]]) 皮尔森相关系数(Pearson Correlation Coefficient)用于度量两个变量X和Y之间的相关程度，其值介于-1与1之间。 12345from scipy.stats import pearsonrx = [1, 2, 3, 4, 5]y = [10, 9, 2.5, 6, 4]coe, pv = pearsonr(x, y) # coe = -0.7426106572325057, pv = 0.1505558088534455 杰卡德相似系数(Jaccard Similarity Coefficient)及杰卡德距离(Jaccard Distance)Jaccard 相似指数用来度量两个集合之间的相似性，它被定义为两个集合交集的元素个数除以并集的元素个数。 Jaccard 距离用来度量两个集合之间的差异性，它是 Jaccard 的相似系数的补集，被定义为 1 减去 Jaccard 相似系数。 123456from scipy.spatial.distance import jaccardx = np.array([1, 1, 0, 1, 0, 1, 0, 0, 1])y = np.array([0, 1, 1, 0, 0, 0, 1, 1, 1])jaccard(x, y) # 0.75","categories":[{"name":"笔记","slug":"笔记","permalink":"https://fuyunliu.github.io/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Python3","slug":"Python3","permalink":"https://fuyunliu.github.io/tags/Python3/"}]},{"title":"基于 LSTM 深度学习模型的日志异常检测","slug":"log-anomaly-detection","date":"2021-06-08T08:33:13.000Z","updated":"2021-06-11T06:09:44.356Z","comments":true,"path":"2021/06/08/log-anomaly-detection/","link":"","permalink":"https://fuyunliu.github.io/2021/06/08/log-anomaly-detection/","excerpt":"日志模式识别日志样例123456789102021-03-11 09:23:17,195 [OCKey:HlTOgWeM-LYFkTMn2wsXcEd] DEBUG com.dawninfotek.base.security.WebAppSafeGuard - BaseWebAppSafeGuard.class::key = beneAcctNo4 value = 12021-03-11 09:23:17,849 [OCKey:zQXeCzqsWdY9_GliHIoAIpI] DEBUG com.dawninfotek.base.action.BaseDispatchAction - com.dawninfotek.easybanking.web.pr.olbfinance.polbfinancemyfinancenew.POLBFinanceMyFinanceAction::Base BaseDispatchAction - link6::370037472021-03-11 09:23:18,635 [OCKey:cSrKSPklI9-juH5TB1VdT6N] DEBUG com.dawninfotek.base.dac.ConnectionFactory - java.lang.Class::Getting a connection from dataSource2021-03-11 09:23:18,635 [OCKey:cSrKSPklI9-juH5TB1VdT6N] DEBUG com.dawninfotek.base.dac.ConnectionFactory - java.lang.Class::got connection com.ibm.ws.rsadapter.jdbc.WSJdbcConnection@3bfa1e18 from dataSource: auto Commit = false2021-03-11 09:23:18,635 [OCKey:cSrKSPklI9-juH5TB1VdT6N] DEBUG java.sql.Connection - &#123;conn-12085845&#125; Connection2021-03-11 09:23:18,635 [OCKey:cSrKSPklI9-juH5TB1VdT6N] DEBUG java.sql.Connection - &#123;conn-12085845&#125; Preparing Statement: select count(T.CUSTNO) from PERCRMPRODUCTDUEDATE t where t.CUSTNO=? and t.READFLAG = &#x27;0&#x27;2021-03-11 09:23:18,635 [OCKey:cSrKSPklI9-juH5TB1VdT6N] DEBUG java.sql.PreparedStatement - &#123;pstm-12085846&#125; Executing Statement: select count(T.CUSTNO) from PERCRMPRODUCTDUEDATE t where t.CUSTNO=? and t.READFLAG = &#x27;0&#x27;2021-03-11 09:23:18,636 [OCKey:cSrKSPklI9-juH5TB1VdT6N] DEBUG java.sql.PreparedStatement - &#123;pstm-12085846&#125; Parameters: [42300205]2021-03-11 09:23:18,636 [OCKey:cSrKSPklI9-juH5TB1VdT6N] DEBUG java.sql.PreparedStatement - &#123;pstm-12085846&#125; Types: [java.lang.String]2021-03-11 09:23:18,636 [OCKey:cSrKSPklI9-juH5TB1VdT6N] DEBUG com.dawninfotek.easybanking.base.process.EasyBankingProcessManager - com.dawninfotek.easybanking.base.process.EasyBankingProcessManager::Start to commit transaction for DAC:EasyBankingSample","text":"日志模式识别日志样例123456789102021-03-11 09:23:17,195 [OCKey:HlTOgWeM-LYFkTMn2wsXcEd] DEBUG com.dawninfotek.base.security.WebAppSafeGuard - BaseWebAppSafeGuard.class::key = beneAcctNo4 value = 12021-03-11 09:23:17,849 [OCKey:zQXeCzqsWdY9_GliHIoAIpI] DEBUG com.dawninfotek.base.action.BaseDispatchAction - com.dawninfotek.easybanking.web.pr.olbfinance.polbfinancemyfinancenew.POLBFinanceMyFinanceAction::Base BaseDispatchAction - link6::370037472021-03-11 09:23:18,635 [OCKey:cSrKSPklI9-juH5TB1VdT6N] DEBUG com.dawninfotek.base.dac.ConnectionFactory - java.lang.Class::Getting a connection from dataSource2021-03-11 09:23:18,635 [OCKey:cSrKSPklI9-juH5TB1VdT6N] DEBUG com.dawninfotek.base.dac.ConnectionFactory - java.lang.Class::got connection com.ibm.ws.rsadapter.jdbc.WSJdbcConnection@3bfa1e18 from dataSource: auto Commit = false2021-03-11 09:23:18,635 [OCKey:cSrKSPklI9-juH5TB1VdT6N] DEBUG java.sql.Connection - &#123;conn-12085845&#125; Connection2021-03-11 09:23:18,635 [OCKey:cSrKSPklI9-juH5TB1VdT6N] DEBUG java.sql.Connection - &#123;conn-12085845&#125; Preparing Statement: select count(T.CUSTNO) from PERCRMPRODUCTDUEDATE t where t.CUSTNO=? and t.READFLAG = &#x27;0&#x27;2021-03-11 09:23:18,635 [OCKey:cSrKSPklI9-juH5TB1VdT6N] DEBUG java.sql.PreparedStatement - &#123;pstm-12085846&#125; Executing Statement: select count(T.CUSTNO) from PERCRMPRODUCTDUEDATE t where t.CUSTNO=? and t.READFLAG = &#x27;0&#x27;2021-03-11 09:23:18,636 [OCKey:cSrKSPklI9-juH5TB1VdT6N] DEBUG java.sql.PreparedStatement - &#123;pstm-12085846&#125; Parameters: [42300205]2021-03-11 09:23:18,636 [OCKey:cSrKSPklI9-juH5TB1VdT6N] DEBUG java.sql.PreparedStatement - &#123;pstm-12085846&#125; Types: [java.lang.String]2021-03-11 09:23:18,636 [OCKey:cSrKSPklI9-juH5TB1VdT6N] DEBUG com.dawninfotek.easybanking.base.process.EasyBankingProcessManager - com.dawninfotek.easybanking.base.process.EasyBankingProcessManager::Start to commit transaction for DAC:EasyBankingSample 日志模式使用 Drain3 算法对日志进行模式提取，共提取得到 190 条日志模式，只展示部分结果。 12345678910&#123;&quot;group_id&quot;: 1, &quot;cluster_id&quot;: 1, &quot;cluster_size&quot;: 62086, &quot;is_abnormal&quot;: false, &quot;template_mined&quot;: &quot;&lt;MODULE&gt; key &lt;*&gt; value&quot;, &quot;template_tokenize&quot;: &quot;modul key valu&quot;&#125;&#123;&quot;group_id&quot;: 2, &quot;cluster_id&quot;: 2, &quot;cluster_size&quot;: 22856, &quot;is_abnormal&quot;: false, &quot;template_mined&quot;: &quot;&lt;CLASS&gt; key &lt;KEY&gt; value &lt;VALUE&gt;&quot;, &quot;template_tokenize&quot;: &quot;class key key valu valu&quot;&#125;&#123;&quot;group_id&quot;: 3, &quot;cluster_id&quot;: 3, &quot;cluster_size&quot;: 2942, &quot;is_abnormal&quot;: false, &quot;template_mined&quot;: &quot;&lt;MODULE&gt; Base BaseDispatchAction &lt;*&gt; &lt;*&gt;&quot;, &quot;template_tokenize&quot;: &quot;modul base basedispatchact&quot;&#125;&#123;&quot;group_id&quot;: 3, &quot;cluster_id&quot;: 53, &quot;cluster_size&quot;: 147, &quot;is_abnormal&quot;: false, &quot;template_mined&quot;: &quot;&lt;MODULE&gt; Base BaseDispatchAction &lt;*&gt;&quot;, &quot;template_tokenize&quot;: &quot;modul base basedispatchact&quot;&#125;&#123;&quot;group_id&quot;: 4, &quot;cluster_id&quot;: 4, &quot;cluster_size&quot;: 16820, &quot;is_abnormal&quot;: false, &quot;template_mined&quot;: &quot;&lt;MODULE&gt; Getting a connection from dataSource&quot;, &quot;template_tokenize&quot;: &quot;modul connect datasourc&quot;&#125;&#123;&quot;group_id&quot;: 5, &quot;cluster_id&quot;: 5, &quot;cluster_size&quot;: 16820, &quot;is_abnormal&quot;: false, &quot;template_mined&quot;: &quot;&lt;MODULE&gt; got connection com.ibm.ws.rsadapter.jdbc.WSJdbcConnection &lt;*&gt; from dataSource auto Commit false&quot;, &quot;template_tokenize&quot;: &quot;modul connect ibm rsadapt jdbc wsjdbcconnect datasourc auto commit fals&quot;&#125;&#123;&quot;group_id&quot;: 6, &quot;cluster_id&quot;: 6, &quot;cluster_size&quot;: 23956, &quot;is_abnormal&quot;: false, &quot;template_mined&quot;: &quot;&lt;CONN&gt; Connection&quot;, &quot;template_tokenize&quot;: &quot;conn connect&quot;&#125;&#123;&quot;group_id&quot;: 7, &quot;cluster_id&quot;: 7, &quot;cluster_size&quot;: 22323, &quot;is_abnormal&quot;: false, &quot;template_mined&quot;: &quot;&lt;CONN&gt; Preparing Statement &lt;SQL&gt;&quot;, &quot;template_tokenize&quot;: &quot;conn prepar statement sql&quot;&#125;&#123;&quot;group_id&quot;: 8, &quot;cluster_id&quot;: 8, &quot;cluster_size&quot;: 22323, &quot;is_abnormal&quot;: false, &quot;template_mined&quot;: &quot;&lt;PSTM&gt; Executing Statement &lt;SQL&gt;&quot;, &quot;template_tokenize&quot;: &quot;pstm execut statement sql&quot;&#125;&#123;&quot;group_id&quot;: 9, &quot;cluster_id&quot;: 9, &quot;cluster_size&quot;: 22322, &quot;is_abnormal&quot;: false, &quot;template_mined&quot;: &quot;&lt;PSTM&gt; Parameters &lt;PARAMS&gt;&quot;, &quot;template_tokenize&quot;: &quot;pstm paramet param&quot;&#125; 字段解释 123456group_id: 模式分组 ID，使用 Levenshtein 计算相似度，阈值为 0.8，大于等于阈值的模式会被分配到相同 group_id 之下。cluster_id：模式 ID。cluster_size: 模式匹配到的日志数量。is_abnormal: 根据通用的异常关键字，预判模式的异常。template_mined: 学习到的日志模式字符串。template_tokenize: 日志模式字符串经过一系列处理得到的字符串，后续日志模式向量计算基于该字符串。 预置的通用异常关键字 1abnormal_chars = [&#x27;error&#x27;, &#x27;fail&#x27;, &#x27;failed&#x27;, &#x27;exception&#x27;, &#x27;invalid&#x27;, &#x27;missing&#x27;, &#x27;duplicate&#x27;, &#x27;unable&#x27;] 日志模式字符串处理过程 提取中英文单词12345678910111213141516171819202122232425262728293031323334def is_lower_alphabet(char): &quot;&quot;&quot;小写字母&quot;&quot;&quot; return &#x27;\\u0061&#x27; &lt;= char &lt;= &#x27;\\u007A&#x27;def is_upper_alphabet(char): &quot;&quot;&quot;大写字母&quot;&quot;&quot; return &#x27;\\u0041&#x27; &lt;= char &lt;= &#x27;\\u005A&#x27;def is_alphabet(char): &quot;&quot;&quot;英文字母&quot;&quot;&quot; return is_lower_alphabet(char) or is_upper_alphabet(char)def is_chinese(char): &quot;&quot;&quot;中文&quot;&quot;&quot; return &#x27;\\u4e00&#x27; &lt;= char &lt;= &#x27;\\u9fff&#x27;def segment(text): &quot;&quot;&quot;中英文分词&quot;&quot;&quot; chars = [] for char in text: if not is_alphabet(char) and not is_chinese(char):: if chars: word = &#x27;&#x27;.join(chars) yield word chars = [] else: chars.append(char) if chars: word = &#x27;&#x27;.join(chars) yield word 中文分词如果提取得到的单词是中文，进一步将中文进行分词。 1234import hanlpHanLP = hanlp.load(hanlp.pretrained.mtl.CLOSE_TOK_POS_NER_SRL_DEP_SDP_CON_ELECTRA_SMALL_ZH)tokens = HanLP(&#x27;读取限流控制参数值&#x27;, tasks=&#x27;tok/fine&#x27;)[&#x27;tok/fine&#x27;] # [&#x27;读取&#x27;, &#x27;限流&#x27;, &#x27;控制&#x27;, &#x27;参数值&#x27;] 统一转化为小写1word = str.lower(word) 词干提取词干提取（Stemming）是抽取词的词干或词根形式（不一定能够表达完整语义）。 1234from nltk.stem.snowball import SnowballStemmerstemmer= SnowballStemmer(&#x27;english&#x27;)word = stemmer.stem(&#x27;Connection&#x27;) # connect 词形还原词形还原（Lemmatization），是把一个任何形式的语言词汇还原为一般形式（能表达完整语义）。 12345from nltk.stem import WordNetLemmatizerlemmatizer = WordNetLemmatizer()word = lemmatizer.lemmatize(&#x27;rooms&#x27;) # room 去停用词去除分词结果中的中英文停用词，这些词没有意义或者出现的频率很低，比如中文的 “的”、“是”、“啊”，英文的 “the”, “an”, “their”。 12345678910111213# 英文停用词: https://github.com/stopwords-iso/stopwords-en# 中文停用词: https://github.com/goto456/stopwordsfrom pathlib import Pathdef load_stopwords(): english_path = Path(__file__).parent / &#x27;stopwords&#x27; / &#x27;english&#x27; chinese_path = Path(__file__).parent / &#x27;stopwords&#x27; / &#x27;chinese&#x27; with english_path.open(&#x27;rt&#x27;, encoding=&#x27;utf-8&#x27;) as en, chinese_path.open(&#x27;rt&#x27;, encoding=&#x27;utf-8&#x27;) as zh: stopwords = &#123;line.strip() for line in en&#125; | &#123;line.strip() for line in zh&#125; return stopwords 模式向量计算TF-IDF 计算1234567891011121314from sklearn.feature_extraction.text import TfidfVectorizer# 读取日志模版template = pd.read_csv(&#x27;easybanking.csv&#x27;)template.fillna(&#x27;&#x27;, inplace=True)# TF-IDF 计算corpus = template[&#x27;template_tokenize&#x27;].to_list()vectorizer = TfidfVectorizer()X = vectorizer.fit_transform(corpus)xarr = X.toarray()words = vectorizer.get_feature_names() # 这里得到的词汇结果可能会被去掉一些频率很低的词 词向量计算1234567891011121314151617181920212223242526import fasttextimport fasttext.utilfasttext.FastText.eprint = lambda x: None# 加载预训练模型ften = fasttext.load_model(&#x27;cc.en.300.bin&#x27;)ftzh = fasttext.load_model(&#x27;cc.zh.300.bin&#x27;)# 词向量默认维度是300，可以降维。ften.get_dimension() # 300fasttext.util.reduce_model(ften, 100)ften.get_dimension() # 100class WordVectorDict(dict): def __missing__(self, key): # 防止有些词汇不存在 if any(map(is_chinese, key)): return ftzh.get_word_vector(key) else: return ften.get_word_vector(key)word_vectors = WordVectorDict() 模式向量12345678910111213141516from collections import defaultdict# 模式向量计算template_vectors = &#123;&#125;for row, arr in zip(template.to_dict(orient=&#x27;records&#x27;), xarr): lookup = defaultdict(int, zip(words, arr)) # 防止有些词汇不存在 tokens = row[&#x27;template_tokenize&#x27;].split() tv = np.zeros(300) for token in tokens: w = lookup[token] # TF-IDF v = word_vectors[token] # 词向量 wv = w * v tv += wv tv = tv if len(tokens) == 0 else tv / len(tokens) template_vectors[row[&#x27;cluster_id&#x27;]] = tv 模式相似度12345from sklearn.metrics.pairwise import cosine_similarity# 余弦相似度cs = cosine_similarity(template_vector_1.reshape(1,-1), template_vector_2.reshape(1,-1)) \b评估指标 TP：True Positive，预测为正，实际为正。 TN：True Negative，预测为负，实际为负。 FP：False Positive，预测为正，实际为负。 FN：False Negative，预测为负，实际为正。 准确率（Accuracy）：ACC = (TP+TN) / (TP+TN+FP+FN) 错误率（Error Rate）：ER = (FP+FN) / (TP+TN+FP+FN) 灵敏度（sensitive）：sensitive = TP/P，表示的是所有正例中被分对的比例，衡量了分类器对正例的识别能力。。 特效度（specificity）：specificity = TN/N，表示的是所有负例中被分对的比例，衡量了分类器对负例的识别能力。 精确率、精度（Precision）：Precesion = TP / (TP+FP)。 召回率（Recall）：Recall = TP / (TP+FN)。 综合评价指标（F-Measure）：F1 = (2 * P * R) / (P + R)。 计算速度：分类器训练和预测需要的时间。 鲁棒性：处理缺失值和异常值的能力。 可扩展性：处理大数据集的能力。 可解释性：分类器的预测标准的可理解性，像决策树产生的规则就是很容易理解的，而神经网络的一堆参数就不好理解，我们只好把它看成一个黑盒子。 ROC曲线：ROC（Receiver Operating Characteristic）曲线是以假正率（FP_rate）和真正率（TP_rate）为轴的曲线。 PR曲线：PR（Precision-Recall）曲线。 基于模式概率分布的异常检测在没有得到日志模版向量表示之前，使用模版的索引对所有日志模版进行 One-Hot 编码，所以对于每一行日志都有一个其对应的模版编码，也可以叫模版概率分布。 对原始日志处理成模版的概率分布之后，我们可以训练一个多分类模型，预测下一个日志的模版概率分布，如果真实日志的模版不在预测的 topK 中，则认为日志是异常的。 构造数据集12345678910111213141516171819202122232425262728import numpy as npimport pandas as pdfrom sklearn.preprocessing import label_binarizefrom sklearn.model_selection import train_test_splitdef create_window_dataset(log_parsed_path, template_path, window_size, split_ratio=0.8): log_parsed = pd.read_csv(log_parsed_path) templates = pd.read_csv(template_path)[&#x27;cluster_id&#x27;].to_list() def fn(dataset, look_back, look_interval=0, look_forward=1): x, y = [], [] for i in range(len(dataset)-look_back-look_interval-look_forward): back = dataset[i:i+look_back,] forward = dataset[i+look_back+look_interval:i+look_back+look_interval+look_forward,] back_x = label_binarize(back, classes=templates) forward_y = label_binarize(forward, classes=templates)[0] x.append(back_x) y.append(forward_y) return np.array(x), np.array(y) dataset = log_parsed[[&#x27;cluster_id&#x27;]].values x, y = fn(dataset, window_size) x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=split_ratio, shuffle=False, stratify=None) return (x_train, y_train), (x_test, y_test) 模型定义123456789101112131415from tensorflow.keras import layers, models, optimizersdef build_model(input_shape, num_classes): inputs = layers.Input(shape=input_shape) x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(inputs) x = layers.Bidirectional(layers.LSTM(64))(x) outputs = layers.Dense(num_classes, activation=&#x27;softmax&#x27;)(x) model = models.Model(inputs=inputs, outputs=outputs) model.compile(loss=&#x27;categorical_crossentropy&#x27;, optimizer=optimizers.Adam(), metrics=[&#x27;accuracy&#x27;]) return model 模型训练12345678910111213141516171819202122232425262728293031# 构造数据集n_candidates = 10window_size = 10log_parsed_path = &#x27;easybanking_parsed_1w.csv&#x27;template_path = &#x27;easybanking_template.csv&#x27;(x_train, y_train), (x_test, y_test) = create_window_dataset(log_parsed_path, template_path, window_size)# 定义模型num_classes = y_train.shape[1]input_shape = (x_train.shape[1], x_train.shape[2])model = build_model(input_shape, num_classes)model.summary()# 模型训练call_backs = [ callbacks.ModelCheckpoint(&quot;best_model.h5&quot;, save_best_only=True, monitor=&quot;val_loss&quot;), callbacks.ReduceLROnPlateau(monitor=&quot;val_loss&quot;, factor=0.5, patience=20, min_lr=0.0001), callbacks.EarlyStopping(monitor=&quot;val_loss&quot;, patience=50, verbose=1),]history = model.fit(x_train, y_train, batch_size=32, epochs=20, callbacks=call_backs, validation_split=0.2, shuffle=True, verbose=1)# 评估模型best_model = models.load_model(&quot;best_model.h5&quot;)y_pred = best_model.predict(x_test)y_true = np.argmax(y_test, axis=1)y_pred = np.argmax(y_pred, axis=1)# 我们只知道日志模式预测的正确与否，但是不知道真实这条日志是否为异常，所以无法计算 TP、TN、FP 和 FN。# 简单起见计算全局准确率和召回率，这里只取 topK K = 1。真正需要提高准确率等需要在模型参数和日志数据及其处理等方面调节。precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=&#x27;micro&#x27;)# (0.7737737737737738, 0.7737737737737738, 0.7737737737737739, None) 缺点 该方案对日志模板进行编码时只使用模板索引，这可能导致丢失有价值的信息，因为模板索引不能揭示日志的语义关系。 真实系统不断升级和更新，日志的模式可能会相应地漂移，该方案难以应付不断变化的、有噪声的日志数据。 基于有监督二分类的异常检测我们得到了日志模版的向量表示，如果我们的数据集被人工标注了异常，我们很容易训练一个二分类模型，直接输出异常与否。 由于应用日志没有异常标注，所以此方案做不了，为了实验可以使用公开的 HDFS 日志，这份日志有异常标注。 这种输入是模式向量，输出是正常异常的概率，是一种粗粒度的异常检测方法，就是假设该模式是异常的，则所属该模式的日志均为异常。 这种方法感觉类似垃圾邮件分类，垃圾短信分类。 针对 HDFS 日志的异常检测，其实特征的构造是另一种做法，HDFS 的每一条日志都有一个 BlockID，根据 BlockID 可以提取出一个日志序列，而 BlockID 决定了这个日志序列的异常与否，换句话说，针对 HDFS 日志，单条日志没有正常异常的概念，只有根据 BlockID 提取的日志序列才有正常异常之分。就比如 “open file xxx” 和 “close file xxx”，单条来说都是正常的，但是结合到一起来看缺一不可，如果某个日志序列缺少了 open 或者 close 则认为文件打开异常了。所以 HDFS 日志的特征输入就是单个 BlockID 所属的日志序列，输出就是正常异常。 然而这种做法不具有普适性，换一个数据源日志则没法套用，只能说是该方法针对 HDFS 日志的异常检测具有比较好的效果。 构造数据集123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960def create_label_dataset(log_parsed_path, template_path, split_ratio=0.8): import fasttext fasttext.FastText.eprint = lambda x: None from sklearn.feature_extraction.text import TfidfVectorizer ften = fasttext.load_model(&#x27;cc.en.300.bin&#x27;) ftzh = fasttext.load_model(&#x27;cc.zh.300.bin&#x27;) class WordVectorDict(dict): def __missing__(self, key): if any(map(is_chinese, key)): return ftzh.get_word_vector(key) else: return ften.get_word_vector(key) # 读取日志模版 template = pd.read_csv(template_path) template.fillna(&#x27;&#x27;, inplace=True) # TF-IDF 计算 corpus = template[&#x27;template_tokenize&#x27;].to_list() vectorizer = TfidfVectorizer() X = vectorizer.fit_transform(corpus) xarr = X.toarray() # 词向量计算 words = vectorizer.get_feature_names() word_vectors = WordVectorDict() # 模版向量计算 template_vectors = &#123;&#125; for row, arr in zip(template.to_dict(orient=&#x27;records&#x27;), xarr): lookup = defaultdict(int, zip(words, arr)) tokens = row[&#x27;template_tokenize&#x27;].split() tv = np.zeros(300) for token in tokens: w = lookup[token] # TF-IDF v = word_vectors[token] # 词向量 wv = w * v tv += wv tv = tv if len(tokens) == 0 else tv / len(tokens) template_vectors[row[&#x27;cluster_id&#x27;]] = tv # 读取日志解析结果 log_vectors = [] log_parsed = pd.read_csv(log_parsed_path) for cluster_id in log_parsed[&#x27;cluster_id&#x27;].to_list(): tv = template_vectors[cluster_id] log_vectors.append(tv) log_labels = log_parsed[&#x27;label&#x27;].to_list() x = np.array(log_vectors) x = np.reshape(x, (x.shape[0], 1, x.shape[1])) y = np.array(log_labels) x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=split_ratio, shuffle=False, stratify=None) return (x_train, y_train), (x_test, y_test) 模型定义123456789101112131415from tensorflow.keras import layers, models, optimizersdef build_model(input_shape, num_classes): inputs = layers.Input(shape=input_shape) x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(inputs) x = layers.Bidirectional(layers.LSTM(64))(x) outputs = layers.Dense(num_classes, activation=&#x27;sigmoid&#x27;)(x) model = models.Model(inputs=inputs, outputs=outputs) model.compile(loss=&#x27;binary_crossentropy&#x27;, optimizer=optimizers.Adam(), metrics=[&#x27;accuracy&#x27;]) return model 模型训练123456789101112131415161718192021222324252627282930313233343536373839# 构造数据集log_parsed_path = &#x27;HDFS_parsed_10w.csv&#x27;template_path = &#x27;HDFS_template.csv&#x27;(x_train, y_train), (x_test, y_test) = create_label_dataset(log_parsed_path, template_path)# 定义模型num_classes = 1input_shape = (x_train.shape[1], x_train.shape[2])model = build_model(input_shape, num_classes)model.summary()# 模型训练call_backs = [ callbacks.ModelCheckpoint(&quot;best_model.h5&quot;, save_best_only=True, monitor=&quot;val_loss&quot;), callbacks.ReduceLROnPlateau(monitor=&quot;val_loss&quot;, factor=0.5, patience=20, min_lr=0.0001), callbacks.EarlyStopping(monitor=&quot;val_loss&quot;, patience=50, verbose=1),]history = model.fit(x_train, y_train, batch_size=32, epochs=20, callbacks=call_backs, validation_split=0.2, shuffle=True, verbose=1)# 评估模型best_model = models.load_model(&quot;best_model.h5&quot;)y_pred = best_model.predict(x_test)y_pred = y_pred[:,0].astype(int)precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=&#x27;binary&#x27;)# (0.9553976053045843, 1.0, 0.9771901149032715, None)# 这里虽然有监督的二分类模型取得了 95% 以上的准确度，但是数据集不合理，数据集应该包含 50% 的正常日志和 50% 的异常日志再加以乱序，这样训练出来的结果是比较合理的。# 画图metric = &quot;accuracy&quot;plt.figure()plt.plot(history.history[metric])plt.plot(history.history[&quot;val_&quot; + metric])plt.title(&quot;model &quot; + metric)plt.ylabel(metric, fontsize=&quot;large&quot;)plt.xlabel(&quot;epoch&quot;, fontsize=&quot;large&quot;)plt.legend([&quot;train&quot;, &quot;val&quot;], loc=&quot;best&quot;)plt.show()plt.close() 基于预测模式向量的异常检测由于没有异常标注数据，所以需要换一种思路进行异常检测，借鉴对时间序列的预测，我们可以认为日志是一种时间序列，此方案中我们训练的模型不是分类模型，而是回归模型，预测下一个日志的模版向量表示，与真实日志的模版向量进行相似度计算，计算出的相似度低于某个阈值则认为该日志是异常的，相似度采用余弦相似度。 构造数据集12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667def create_vector_dataset(log_parsed_path, template_path, window_size, split_ratio=0.8): import fasttext fasttext.FastText.eprint = lambda x: None from sklearn.feature_extraction.text import TfidfVectorizer ften = fasttext.load_model(&#x27;cc.en.300.bin&#x27;) ftzh = fasttext.load_model(&#x27;cc.zh.300.bin&#x27;) class WordVectorDict(dict): def __missing__(self, key): if any(map(is_chinese, key)): return ftzh.get_word_vector(key) else: return ften.get_word_vector(key) # 读取日志模版 template = pd.read_csv(template_path) template.fillna(&#x27;&#x27;, inplace=True) # TF-IDF 计算 corpus = template[&#x27;template_tokenize&#x27;].to_list() vectorizer = TfidfVectorizer() X = vectorizer.fit_transform(corpus) xarr = X.toarray() # 词向量计算 words = vectorizer.get_feature_names() word_vectors = WordVectorDict() # 模版向量计算 template_vectors = &#123;&#125; for row, arr in zip(template.to_dict(orient=&#x27;records&#x27;), xarr): lookup = defaultdict(int, zip(words, arr)) tokens = row[&#x27;template_tokenize&#x27;].split() tv = np.zeros(300) for token in tokens: w = lookup[token] # TF-IDF v = word_vectors[token] # 词向量 wv = w * v tv += wv tv = tv if len(tokens) == 0 else tv / len(tokens) template_vectors[row[&#x27;cluster_id&#x27;]] = tv # 读取日志解析结果 log_vectors = [] log_parsed = pd.read_csv(log_parsed_path) for cluster_id in log_parsed[&#x27;cluster_id&#x27;].to_list(): tv = template_vectors[cluster_id] log_vectors.append(tv) def fn(dataset, look_back, look_interval=0, look_forward=1): x, y = [], [] for i in range(len(dataset)-look_back-look_interval-look_forward): back = dataset[i:i+look_back,] forward = dataset[i+look_back+look_interval:i+look_back+look_interval+look_forward,] x.append(back) y.append(forward) return np.array(x), np.array(y) x, y = fn(np.array(log_vectors), window_size) y = y[:,0] x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=split_ratio, shuffle=False, stratify=None) return (x_train, y_train), (x_test, y_test) 模型定义12345678910from tensorflow.keras import layers, modelsdef build_model(n_steps_in, n_features, n_steps_out): model = models.Sequential() model.add(layers.Bidirectional(layers.LSTM(units=64, activation=&#x27;tanh&#x27;), input_shape=(n_steps_in, n_features))) model.add(layers.Dense(n_steps_out)) model.compile(loss=&#x27;mse&#x27;, optimizer=&#x27;adam&#x27;, metrics=[&#x27;accuracy&#x27;]) return model 模型训练1234567891011121314151617181920212223242526272829303132import matplotlib.pyplot as plt# 构造数据集window_size = 10log_parsed_path = &#x27;easybanking_parsed_1w.csv&#x27;template_path = &#x27;easybanking_template.csv&#x27;(x_train, y_train), (x_test, y_test) = create_vector_dataset(log_parsed_path, template_path, window_size)# 定义模型n_steps_in, n_features, n_steps_out = (x_train.shape[1], x_train.shape[2], y_train.shape[1])model = build_model(n_steps_in, n_features, n_features)model.summary()# 模型训练call_backs = [ callbacks.ModelCheckpoint(&quot;best_model.h5&quot;, save_best_only=True, monitor=&quot;val_loss&quot;), callbacks.ReduceLROnPlateau(monitor=&quot;val_loss&quot;, factor=0.5, patience=20, min_lr=0.0001), callbacks.EarlyStopping(monitor=&quot;val_loss&quot;, patience=50, verbose=1),]history = model.fit(x_train, y_train, batch_size=32, epochs=20, callbacks=call_backs, validation_split=0.2, shuffle=True, verbose=1)# 画图metric = &quot;accuracy&quot;plt.figure()plt.plot(history.history[metric])plt.plot(history.history[&quot;val_&quot; + metric])plt.title(&quot;model &quot; + metric)plt.ylabel(metric, fontsize=&quot;large&quot;)plt.xlabel(&quot;epoch&quot;, fontsize=&quot;large&quot;)plt.legend([&quot;train&quot;, &quot;val&quot;], loc=&quot;best&quot;)plt.show()plt.close()","categories":[{"name":"笔记","slug":"笔记","permalink":"https://fuyunliu.github.io/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"LSTM","slug":"LSTM","permalink":"https://fuyunliu.github.io/tags/LSTM/"},{"name":"Drain3","slug":"Drain3","permalink":"https://fuyunliu.github.io/tags/Drain3/"},{"name":"FastText","slug":"FastText","permalink":"https://fuyunliu.github.io/tags/FastText/"},{"name":"HanLP","slug":"HanLP","permalink":"https://fuyunliu.github.io/tags/HanLP/"}]},{"title":"Session 、Cookie 和 JWT 详解","slug":"session-cookie-jwt","date":"2021-04-17T06:26:02.000Z","updated":"2021-04-17T07:09:29.917Z","comments":true,"path":"2021/04/17/session-cookie-jwt/","link":"","permalink":"https://fuyunliu.github.io/2021/04/17/session-cookie-jwt/","excerpt":"什么是 CookieHTTP Cookie（也叫 Web Cookie 或浏览器 Cookie）是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器下次向同一服务器再发起请求时被携带并发送到服务器上。通常，它用于告知服务端两个请求是否来自同一浏览器，如保持用户的登录状态。Cookie 使基于无状态的HTTP协议记录稳定的状态信息成为了可能。 Cookie 主要用于以下三个方面： 会话状态管理（如用户登录状态、购物车、游戏分数或其它需要记录的信息） 个性化设置（如用户自定义设置、主题等） 浏览器行为跟踪（如跟踪分析用户行为等）","text":"什么是 CookieHTTP Cookie（也叫 Web Cookie 或浏览器 Cookie）是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器下次向同一服务器再发起请求时被携带并发送到服务器上。通常，它用于告知服务端两个请求是否来自同一浏览器，如保持用户的登录状态。Cookie 使基于无状态的HTTP协议记录稳定的状态信息成为了可能。 Cookie 主要用于以下三个方面： 会话状态管理（如用户登录状态、购物车、游戏分数或其它需要记录的信息） 个性化设置（如用户自定义设置、主题等） 浏览器行为跟踪（如跟踪分析用户行为等） 什么是 SessionSession 代表着服务器和客户端一次会话的过程。Session 对象存储特定用户会话所需的属性及配置信息。这样，当用户在应用程序的 Web 页之间跳转时，存储在 Session 对象中的变量将不会丢失，而是在整个用户会话中一直存在下去。当客户端关闭会话，或者 Session 超时失效时会话结束。 Session 和 Cookie 的区别 作用范围不同，Cookie 保存在客户端（浏览器），Session 保存在服务器端。 存取方式的不同，Cookie 只能保存 ASCII，Session 可以存任意数据类型，一般情况下我们可以在 Session 中保持一些常用变量信息，比如说 UserId 等。 有效期不同，Cookie 可设置为长时间保持，比如我们经常使用的默认登录功能，Session 一般失效时间较短，客户端关闭或者 Session 超时都会失效。 隐私策略不同，Cookie 存储在客户端，比较容易遭到不法获取，早期有人将用户的登录名和密码存储在 Cookie 中导致信息被窃取；Session 存储在服务端，安全性相对 Cookie 要好一些。 存储大小不同， 单个 Cookie 保存的数据不能超过 4K，Session 可存储数据远高于 Cookie。 Cookie 是客户端技术，Session 是服务端技术，Session 借助 Cookie 存储 sessionid。 如果浏览器禁用 Cookie，可以使用 POST 提交 sessionid 或者使用 JWT 技术。 分布式 Session在互联网公司为了可以支撑更大的流量，后端往往需要多台服务器共同来支撑前端用户请求，那如果用户在 A 服务器登录了，第二次请求跑到服务 B 就会出现登录失效问题。 分布式 Session 一般会有以下几种解决方案： Nginx ip_hash 策略，服务端使用 Nginx 代理，每个请求按访问 IP 的 hash 分配，这样来自同一 IP 固定访问一个后台服务器，避免了在服务器 A 创建 Session，第二次分发到服务器 B 的现象。 Session 复制，任何一个服务器上的 Session 发生改变（增删改），该节点会把这个 Session 的所有内容序列化，然后广播给所有其它节点。 共享 Session，服务端无状态话，将用户的 Session 等信息使用缓存中间件来统一管理，保障分发到每一个服务器的响应结果都一致。 跨域请求同源策略/SOP（Same origin policy）是一种约定，由 Netscape 公司 1995年引入浏览器，它是浏览器最核心也最基本的安全功能，如果缺少了同源策略，浏览器很容易受到 XSS、CSFR 等攻击。所谓同源是指”协议+域名+端口”三者相同，即便两个不同的域名指向同一个 ip 地址，也非同源。 解决方案： Nginx 代理 Jsonp 跨域 JWT 认证 JWT 数据结构Encoded1eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiaWF0IjoxNTE2MjM5MDIyfQ.SflKxwRJSMeKKF2QT4fwpMeJf36POk6yJV_adQssw5c DecodedHeader (头部)1234567&#123; &quot;alg&quot;: &quot;HS256&quot;, &quot;typ&quot;: &quot;JWT&quot;, &quot;kid&quot;: &quot;Key ID&quot;, &quot;cty&quot;: &quot;Content Type&quot;, &quot;enc&quot;: &quot;Encrypt Algorithm&quot;&#125; Payload (负载)123456789&#123; &quot;iss&quot;: &quot;issuer(签发人)&quot;, &quot;exp&quot;: &quot;expiration time(过期时间)&quot;, &quot;sub&quot;: &quot;subject(主题)&quot;, &quot;aud&quot;: &quot;audience(受众)&quot;, &quot;nbf&quot;: &quot;Not Before(生效时间)&quot;, &quot;iat&quot;: &quot;Issued At(签发时间)&quot;, &quot;jti&quot;: &quot;JWT ID(编号)&quot;&#125; Signature (签名)1234567HMACSHA256( base64UrlEncode(header) + &quot;.&quot; + base64UrlEncode(payload),your-256-bit-secret) secret base64 encoded JWT = Header.Payload.Signature","categories":[{"name":"笔记","slug":"笔记","permalink":"https://fuyunliu.github.io/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"JWT","slug":"JWT","permalink":"https://fuyunliu.github.io/tags/JWT/"},{"name":"Session","slug":"Session","permalink":"https://fuyunliu.github.io/tags/Session/"},{"name":"Cookie","slug":"Cookie","permalink":"https://fuyunliu.github.io/tags/Cookie/"}]},{"title":"Postgresql Tutorial","slug":"postgresql-tutorial","date":"2021-03-14T09:27:56.000Z","updated":"2021-03-14T09:29:50.578Z","comments":true,"path":"2021/03/14/postgresql-tutorial/","link":"","permalink":"https://fuyunliu.github.io/2021/03/14/postgresql-tutorial/","excerpt":"","text":"psql 数据库名 –连接数据库select rolname,rolpassword from pg_authid;–查看用户名密码select usename,passwd from pg_shadow;–查看用户名密码select version(); – 查看版本select current_database();–查看当前数据库\\l –查看所有数据库\\dt –查看表\\password username –修改密码\\password –设置密码。? –查看psql命令列表。\\c [database_name] –连接其他数据库，切换数据库。\\conninfo –列出当前数据库和连接的信息。\\d –列出当前数据库的所有表格。\\d [table_name] –列出某一张表格的结构。\\du –列出所有用户。\\e –打开文本编辑器。help –帮助\\h –查看SQL命令的解释，比如\\h select。\\q –退出","categories":[{"name":"笔记","slug":"笔记","permalink":"https://fuyunliu.github.io/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"PostgreSQL","slug":"PostgreSQL","permalink":"https://fuyunliu.github.io/tags/PostgreSQL/"}]},{"title":"LSTM 时间序列预测","slug":"lstm-models-for-time-series-forecasting","date":"2020-12-03T07:48:54.000Z","updated":"2020-12-17T01:18:30.188Z","comments":true,"path":"2020/12/03/lstm-models-for-time-series-forecasting/","link":"","permalink":"https://fuyunliu.github.io/2020/12/03/lstm-models-for-time-series-forecasting/","excerpt":"调节内容1.输出维度 units2.时间步长 timesteps3.激活函数 activation4.增加特征：增长率5.增加特征：日期属性6.预测增长率7.单层 stateful LSTM8.双层 stateful LSTM9.批数据大小 batch_size10.训练循环次数 epochs11.原序列对数12.原序列差分13.归一化值域 feature_range14.Bidirectional LSTM15.CNN LSTM16.ConvLSTM","text":"调节内容1.输出维度 units2.时间步长 timesteps3.激活函数 activation4.增加特征：增长率5.增加特征：日期属性6.预测增长率7.单层 stateful LSTM8.双层 stateful LSTM9.批数据大小 batch_size10.训练循环次数 epochs11.原序列对数12.原序列差分13.归一化值域 feature_range14.Bidirectional LSTM15.CNN LSTM16.ConvLSTM 原始数据集 原始序列超参数12345678# 定义超参数batch_size = 128 # 批数据大小epochs = 50 # 实验训练次数units = 64 # 状态的输出维度features = 1 # 最终输出维度timesteps = 3 # 时间步长feature_range = (0, 1) # 归一化值域ratio = 0.8 # 数据集分割比例 模型定义12345678910111213# 模型model = Sequential()model.add(LSTM(units=units, activation=&#x27;tanh&#x27;, input_shape=(timesteps,features)))model.add(Dense(1))model.compile(loss=&#x27;mse&#x27;, optimizer=&#x27;adam&#x27;)callbacks = [ keras.callbacks.EarlyStopping(monitor=&#x27;val_loss&#x27;, patience=2), keras.callbacks.ModelCheckpoint(filepath=&#x27;model.h5&#x27;, monitor=&#x27;val_loss&#x27;, save_best_only=True), keras.callbacks.ReduceLROnPlateau(monitor=&#x27;val_loss&#x27;, factor=0.01, patience=2)]# 训练history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_valid, y_valid), callbacks=callbacks, verbose=1) 验证损失12345validate cost: 0.00031516602518997155elapsed time: 2.2270960807800293 (s)Train Score: 2350.04 RMSEValid Score: 1975.81 RMSETest Score: 1143.96 RMSE Stateful LSTM使 RNN 具有状态意味着每批样品的状态将被重新用作下一批样品的初始状态。 stateful LSTM：能让模型学习到你输入的samples之间的时序特征，适合一些长序列的预测，哪个sample在前，那个sample在后对模型是有影响的。stateless LSTM：输入samples后，默认就会shuffle，可以说是每个sample独立，之间无前后关系，适合输入一些没有关系的样本。 超参数12345678# 定义超参数batch_size = 128 # 批数据大小epochs = 50 # 实验训练次数units = 64 # 状态的输出维度features = 1 # 最终输出维度timesteps = 3 # 时间步长feature_range = (0, 1) # 归一化值域ratio = 0.8 # 数据集分割比例 模型定义12345678910111213141516# 模型model = Sequential()model.add(LSTM(units=units, activation=&#x27;tanh&#x27;, stateful=True, batch_input_shape=(batch_size, timesteps, features)))model.add(Dense(1))model.summary()callbacks = [ keras.callbacks.EarlyStopping(monitor=&#x27;val_loss&#x27;, patience=2), keras.callbacks.ModelCheckpoint(filepath=&#x27;model.h5&#x27;, monitor=&#x27;val_loss&#x27;, save_best_only=True), keras.callbacks.ReduceLROnPlateau(monitor=&#x27;val_loss&#x27;, factor=0.01, patience=2)]model.compile(loss=&#x27;mse&#x27;, optimizer=&#x27;adam&#x27;)# 训练for i in range(epochs): history = model.fit(x_train, y_train, batch_size=batch_size, epochs=1, verbose=1, validation_data=(x_valid, y_valid), shuffle=False, callbacks=callbacks) model.reset_states() 验证损失123456789validate cost: 0.0003053233659405426elapsed time: 8.588087797164917 (s)Train Score: 2098.81 RMSEValid Score: 1768.38 RMSETest Score: 880.83 RMSE# stateful带来了一些改观，从理论上讲stateful会有些好处，因为我们的数据是具有自相关性的时序数据。# 但是stateful限制训练、验证和预测必须接受以batch为单位的数据，给后面预测带来很大变动和限制，故不使用stateful。 序列对数超参数12345678# 定义超参数batch_size = 128 # 批数据大小epochs = 50 # 实验训练次数units = 64 # 状态的输出维度features = 1 # 最终输出维度timesteps = 3 # 时间步长feature_range = (0, 1) # 归一化值域ratio = 0.8 # 数据集分割比例 模型定义123456789101112131415# 模型model = Sequential()model.add(LSTM(units=units, activation=&#x27;tanh&#x27;, input_shape=(timesteps, features)))model.add(Dense(1))model.summary()callbacks = [ keras.callbacks.EarlyStopping(monitor=&#x27;val_loss&#x27;, patience=2), keras.callbacks.ModelCheckpoint(filepath=&#x27;model.h5&#x27;, monitor=&#x27;val_loss&#x27;, save_best_only=True), keras.callbacks.ReduceLROnPlateau(monitor=&#x27;val_loss&#x27;, factor=0.01, patience=2)]model.compile(loss=&#x27;mse&#x27;, optimizer=&#x27;adam&#x27;)# 训练history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_valid, y_valid), shuffle=False, callbacks=callbacks) 验证损失1234567validate cost: 0.0003706229881521907elapsed time: 2.328054904937744 (s)Train Score: 2451.66 RMSEValid Score: 1843.60 RMSETest Score: 901.27 RMSE# 取对数在验证集和测试集上有所改观，在训练集上误差稍微增大 序列差分超参数12345678# 定义超参数batch_size = 128 # 批数据大小epochs = 50 # 实验训练次数units = 64 # 状态的输出维度features = 1 # 最终输出维度timesteps = 3 # 时间步长feature_range = (0, 1) # 归一化值域ratio = 0.8 # 数据集分割比例 模型定义1234567891011121314# 模型model = Sequential()model.add(LSTM(units=units, activation=&#x27;tanh&#x27;, input_shape=(timesteps, features)))model.add(Dense(1))model.summary()callbacks = [ keras.callbacks.EarlyStopping(monitor=&#x27;val_loss&#x27;, patience=2), keras.callbacks.ModelCheckpoint(filepath=&#x27;model.h5&#x27;, monitor=&#x27;val_loss&#x27;, save_best_only=True), keras.callbacks.ReduceLROnPlateau(monitor=&#x27;val_loss&#x27;, factor=0.01, patience=2)]model.compile(loss=&#x27;mse&#x27;, optimizer=&#x27;adam&#x27;)# 训练history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_valid, y_valid), shuffle=False, callbacks=callbacks) 一阶差分1234567891011validate cost: 9.300382513113658e-05elapsed time: 1.9793977737426758 (s)Train Score: 1868.55 RMSEValid Score: 1608.05 RMSETest Score: 884.86 RMSE# 一阶差分误差改善效果明显，相较于取对数更优。# 经过验证发现将归一化值域调整为 feature_range = (-1, 1) 之后# 验证集损失 val_loss 会增大，但是 Train, Valid, Test 的 RMSE 却减少 100-200左右# 经过差分之后的数据有正有负，似乎 (-1, 1) 是合理的，但是本文将保持 (0, 1) 不变# 研究其他变化带来的变化，最后选出最优的特征和超参数，归一化值域可随时更改 二阶差分1234567validate cost: 0.00017968161298761821elapsed time: 2.5699269771575928 (s)Train Score: 2607.74 RMSEValid Score: 2270.10 RMSETest Score: 1025.25 RMSE# 二阶差分反而更差了，故只取一阶差分 序列对数差分超参数12345678# 定义超参数batch_size = 128 # 批数据大小epochs = 50 # 实验训练次数units = 64 # 状态的输出维度features = 1 # 最终输出维度timesteps = 3 # 时间步长feature_range = (0, 1) # 归一化值域ratio = 0.8 # 数据集分割比例 模型定义123456789101112131415# 模型model = Sequential()model.add(LSTM(units=units, activation=&#x27;tanh&#x27;, input_shape=(timesteps, features)))model.add(Dense(1))model.summary()callbacks = [ keras.callbacks.EarlyStopping(monitor=&#x27;val_loss&#x27;, patience=2), keras.callbacks.ModelCheckpoint(filepath=&#x27;model.h5&#x27;, monitor=&#x27;val_loss&#x27;, save_best_only=True), keras.callbacks.ReduceLROnPlateau(monitor=&#x27;val_loss&#x27;, factor=0.01, patience=2)]model.compile(loss=&#x27;mse&#x27;, optimizer=&#x27;adam&#x27;)# 训练history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_valid, y_valid), shuffle=False, callbacks=callbacks) 验证损失12345678910validate cost: 8.005627370742416e-05elapsed time: 2.5233328342437744 (s)Train Score: 1883.97 RMSEValid Score: 1621.68 RMSETest Score: 879.93 RMSE# 可以发现对数差分的效果几乎和一阶差分的效果是一样的，取对数的效果微乎其微。# 差分之后的序列更接近平稳序列，可能更有利于LSTM建模预测。# 取对数只是缩小值域，再说还有归一化操作，似乎不是必要的。# 比如像LightGBM算法并没有归一化操作，所以取对数有比较好的调参效果。 增加日期属性 超参数12345678# 定义超参数batch_size = 128 # 批数据大小epochs = 50 # 实验训练次数units = 64 # 状态的输出维度features = 4 # 最终输出维度timesteps = 3 # 时间步长feature_range = (0, 1) # 归一化值域ratio = 0.8 # 数据集分割比例 模型定义123456789101112131415# 模型model = Sequential()model.add(LSTM(units=units, activation=&#x27;tanh&#x27;, input_shape=(timesteps, features)))model.add(Dense(1))model.summary()callbacks = [ keras.callbacks.EarlyStopping(monitor=&#x27;val_loss&#x27;, patience=2), keras.callbacks.ModelCheckpoint(filepath=&#x27;model.h5&#x27;, monitor=&#x27;val_loss&#x27;, save_best_only=True), keras.callbacks.ReduceLROnPlateau(monitor=&#x27;val_loss&#x27;, factor=0.01, patience=2)]model.compile(loss=&#x27;mse&#x27;, optimizer=&#x27;adam&#x27;)# 训练history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_valid, y_valid), shuffle=False, callbacks=callbacks) 验证损失1234567validate cost: 0.002384760812697476elapsed time: 1.893902063369751 (s)Train Score: 2104.13 RMSEValid Score: 5434.98 RMSETest Score: 5839.40 RMSE# 模型在训练集、验证集和测试集表现越来越差 增加增长率 超参数12345678# 定义超参数batch_size = 128 # 批数据大小epochs = 50 # 实验训练次数units = 64 # 状态的输出维度features = 2 # 最终输出维度timesteps = 3 # 时间步长feature_range = (0, 1) # 归一化值域ratio = 0.8 # 数据集分割比例 模型定义123456789101112131415# 模型model = Sequential()model.add(LSTM(units=units, activation=&#x27;tanh&#x27;, input_shape=(timesteps, features)))model.add(Dense(1))model.summary()callbacks = [ keras.callbacks.EarlyStopping(monitor=&#x27;val_loss&#x27;, patience=2), keras.callbacks.ModelCheckpoint(filepath=&#x27;model.h5&#x27;, monitor=&#x27;val_loss&#x27;, save_best_only=True), keras.callbacks.ReduceLROnPlateau(monitor=&#x27;val_loss&#x27;, factor=0.01, patience=2)]model.compile(loss=&#x27;mse&#x27;, optimizer=&#x27;adam&#x27;)# 训练history = model.fit(x_train, y_train, batch_size=batch_size, epochs=1, verbose=1, validation_data=(x_valid, y_valid), shuffle=False, callbacks=callbacks) 验证损失1234567891011validate cost: 0.00023447876570476951elapsed time: 2.060291051864624 (s)Train Score: 2084.47 RMSEValid Score: 1704.23 RMSETest Score: 1039.05 RMSE# 增长率也可以改善预测结果，原理和一阶差分相似，差分是做减法，增长率是做除法。# 误差减小了，但是增长率产生了负数的情况。# 之前的实验是增长率结合stateful LSTM，得到的结果是：增长率可以和一阶差分类似改善拟合结果，并无发现有负数的情况。# 做完实验考虑预测部分的时候发现stateful必须接受batch为单位的数据，使得预测变得麻烦，改动工作较大。 预测增长率变换目标值为增长率，预测增长率，和前一天的交易量进行计算，得到当前的交易预测值。 123456789validate cost: 0.007923171162502511elapsed time: 1.5544190406799316 (s)Train Score: 1575.60 RMSEValid Score: 1307.57 RMSETest Score: 761.17 RMSE# 结合图可以看出，相比增加增长率这个特征，直接预测增长率收到了比较好的效果。# 而且没有出现负数的情况，拟合误差减少很多，可以采用。 双层LSTM超参数12345678# 定义超参数batch_size = 128 # 批数据大小epochs = 50 # 实验训练次数units = 64 # 状态的输出维度features = 1 # 最终输出维度timesteps = 3 # 时间步长feature_range = (0, 1) # 归一化值域ratio = 0.8 # 数据集分割比例 单层LSTM有Dropout123456789101112131415# 模型model = Sequential()model.add(LSTM(units=units, activation=&#x27;tanh&#x27;, input_shape=(timesteps, features)))model.add(Dropout(0.2))model.add(Dense(1))model.summary()callbacks = [ keras.callbacks.EarlyStopping(monitor=&#x27;val_loss&#x27;, patience=2), keras.callbacks.ModelCheckpoint(filepath=&#x27;model.h5&#x27;, monitor=&#x27;val_loss&#x27;, save_best_only=True), keras.callbacks.ReduceLROnPlateau(monitor=&#x27;val_loss&#x27;, factor=0.01, patience=2)]model.compile(loss=&#x27;mse&#x27;, optimizer=&#x27;adam&#x27;)# 训练history = model.fit(x_train, y_train, batch_size=batch_size, epochs=1, verbose=1, validation_data=(x_valid, y_valid), shuffle=False, callbacks=callbacks) 123456validate cost: 0.00024637159007593934elapsed time: 2.1154732704162598 (s)Train Score: 2107.65 RMSEValid Score: 1746.91 RMSETest Score: 906.77 RMSE 双层LSTM有Dropout123456789101112131415161718# 模型model = Sequential()model.add(LSTM(units=units, activation=&#x27;tanh&#x27;, input_shape=(timesteps, features), return_sequences=True))model.add(Dropout(0.2))model.add(LSTM(units=units, activation=&#x27;tanh&#x27;, input_shape=(timesteps, features)))model.add(Dropout(0.2))model.add(Dense(1))model.summary()callbacks = [ keras.callbacks.EarlyStopping(monitor=&#x27;val_loss&#x27;, patience=2), keras.callbacks.ModelCheckpoint(filepath=&#x27;model.h5&#x27;, monitor=&#x27;val_loss&#x27;, save_best_only=True), keras.callbacks.ReduceLROnPlateau(monitor=&#x27;val_loss&#x27;, factor=0.01, patience=2)]model.compile(loss=&#x27;mse&#x27;, optimizer=&#x27;adam&#x27;)# 训练history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_valid, y_valid), shuffle=False, callbacks=callbacks) 123456validate cost: 0.00030157841621581707elapsed time: 3.7397210597991943 (s)Train Score: 2266.96 RMSEValid Score: 1932.75 RMSETest Score: 1101.70 RMSE 双层LSTM无Dropout12345678910111213141516# 模型model = Sequential()model.add(LSTM(units=units, activation=&#x27;tanh&#x27;, input_shape=(timesteps, features), return_sequences=True))model.add(LSTM(units=units, activation=&#x27;tanh&#x27;, input_shape=(timesteps, features)))model.add(Dense(1))model.summary()callbacks = [ keras.callbacks.EarlyStopping(monitor=&#x27;val_loss&#x27;, patience=2), keras.callbacks.ModelCheckpoint(filepath=&#x27;model.h5&#x27;, monitor=&#x27;val_loss&#x27;, save_best_only=True), keras.callbacks.ReduceLROnPlateau(monitor=&#x27;val_loss&#x27;, factor=0.01, patience=2)]model.compile(loss=&#x27;mse&#x27;, optimizer=&#x27;adam&#x27;)# 训练history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_valid, y_valid), shuffle=False, callbacks=callbacks) 123456789validate cost: 0.00028111153606354833elapsed time: 3.16672682762146 (s)Train Score: 2269.73 RMSEValid Score: 1866.01 RMSETest Score: 1003.38 RMSE# 单层LSTM加上Dropout正则化层，相较于单层LSTM似乎有所改善，但对于Dropout的作用还不太明白。# 双层LSTM加上Dropout正则化层，相较于双层LSTM又是略差些，但是相差不大。# 对于这些结果，可能需要多次实验取均值来确定哪些因素对拟合更优。 差分结合增长率在一阶差分的基础上增加增长率这个特征 超参数12345678# 定义超参数batch_size = 128 # 批数据大小epochs = 50 # 实验训练次数units = 64 # 状态的输出维度features = 2 # 最终输出维度timesteps = 3 # 时间步长feature_range = (0, 1) # 归一化值域ratio = 0.8 # 数据集分割比例 模型定义1234567891011121314# 模型model = Sequential()model.add(LSTM(units=units, activation=&#x27;tanh&#x27;, input_shape=(timesteps, features)))model.add(Dense(1))model.summary()callbacks = [ keras.callbacks.EarlyStopping(monitor=&#x27;val_loss&#x27;, patience=2), keras.callbacks.ModelCheckpoint(filepath=&#x27;model.h5&#x27;, monitor=&#x27;val_loss&#x27;, save_best_only=True), keras.callbacks.ReduceLROnPlateau(monitor=&#x27;val_loss&#x27;, factor=0.01, patience=2)]model.compile(loss=&#x27;mse&#x27;, optimizer=&#x27;adam&#x27;)# 训练history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_valid, y_valid), shuffle=False, callbacks=callbacks) 验证损失12345678910validate cost: 8.446127437506554e-05elapsed time: 2.3685760498046875 (s)Train Score: 1787.02 RMSEValid Score: 1532.42 RMSETest Score: 901.20 RMSE# 从误差结果可以看出，这个和一阶差分的结果相差无几# 但是从拟合图上看，拟合值出现了负数的情况，这是增长率带来的结果# 所以可以通过预测增长率，再结合一阶差分看看 预测增长率预测增长率，再结合一阶差分，这个和上面的不同之处在于使用增长率作为目标值。 12345678validate cost: 0.007926768652017368elapsed time: 1.7802140712738037 (s)Train Score: 1600.33 RMSEValid Score: 1325.91 RMSETest Score: 769.42 RMSE# 这个结果和单纯预测增长率的结果又是相差无几，差不差分都无所谓了。# 总结：一阶差分和预测增长率是二选一的结果，二者都能达到较好的优化，预测增长率更优一些。 Bidirectional LSTM On some sequence prediction problems, it can be beneficial to allow the LSTM model to learn the input sequence both forward and backwards and concatenate both interpretations.This is called a Bidirectional LSTM.We can implement a Bidirectional LSTM for univariate time series forecasting by wrapping the first hidden layer in a wrapper layer called Bidirectional. 超参数12345678# 定义超参数batch_size = 128 # 批数据大小epochs = 50 # 实验训练次数units = 64 # 状态的输出维度features = 1 # 最终输出维度timesteps = 3 # 时间步长feature_range = (0, 1) # 归一化值域ratio = 0.8 # 数据集分割比例 模型定义123456789101112131415# 模型model = Sequential()model.add(Bidirectional(LSTM(units=units, activation=&#x27;tanh&#x27;), input_shape=(timesteps, features)))model.add(Dense(1))model.summary()callbacks = [ keras.callbacks.EarlyStopping(monitor=&#x27;val_loss&#x27;, patience=2), keras.callbacks.ModelCheckpoint(filepath=&#x27;model.h5&#x27;, monitor=&#x27;val_loss&#x27;, save_best_only=True), keras.callbacks.ReduceLROnPlateau(monitor=&#x27;val_loss&#x27;, factor=0.01, patience=2)]model.compile(loss=&#x27;mse&#x27;, optimizer=&#x27;adam&#x27;)# 训练history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_valid, y_valid), shuffle=False, callbacks=callbacks) 验证损失1234567validate cost: 0.0002106719806980023elapsed time: 2.6818039417266846 (s)Train Score: 1946.72 RMSEValid Score: 1615.40 RMSETest Score: 823.85 RMSE# Bidirectional LSTM 具有明显改善效果，这个可以结合一阶差分或者预测增长率使用。 CNN LSTM A convolutional neural network, or CNN for short, is a type of neural network developed for working with two-dimensional image data.The CNN can be very effective at automatically extracting and learning features from one-dimensional sequence data such as univariate time series data.A CNN model can be used in a hybrid model with an LSTM backend where the CNN is used to interpret subsequences of input that together are provided as a sequence to an LSTM model to interpret. This hybrid model is called a CNN-LSTM. 超参数12345678# 定义超参数batch_size = 128 # 批数据大小epochs = 50 # 实验训练次数units = 64 # 状态的输出维度features = 1 # 最终输出维度timesteps = 4 # 时间步长feature_range = (0, 1) # 归一化值域ratio = 0.8 # 数据集分割比例 模型定义123456789101112131415161718# 模型model = Sequential()model.add(TimeDistributed(Conv1D(filters=units, kernel_size=1, activation=&#x27;tanh&#x27;), input_shape=(None, timesteps//2, features)))model.add(TimeDistributed(MaxPooling1D(pool_size=2)))model.add(TimeDistributed(Flatten()))model.add(LSTM(units=units, activation=&#x27;tanh&#x27;))model.add(Dense(1))model.summary()callbacks = [ keras.callbacks.EarlyStopping(monitor=&#x27;val_loss&#x27;, patience=2), keras.callbacks.ModelCheckpoint(filepath=&#x27;model.h5&#x27;, monitor=&#x27;val_loss&#x27;, save_best_only=True), keras.callbacks.ReduceLROnPlateau(monitor=&#x27;val_loss&#x27;, factor=0.01, patience=2)]model.compile(loss=&#x27;mse&#x27;, optimizer=&#x27;adam&#x27;)# 训练history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_valid, y_valid), shuffle=False, callbacks=callbacks) 验证损失123456validate cost: 0.00021777707989074557elapsed time: 2.1609442234039307 (s)Train Score: 2035.46 RMSEValid Score: 1642.41 RMSETest Score: 851.72 RMSE ConvLSTM A type of LSTM related to the CNN-LSTM is the ConvLSTM, where the convolutional reading of input is built directly into each LSTM unit.The ConvLSTM was developed for reading two-dimensional spatial-temporal data, but can be adapted for use with univariate time series forecasting. 超参数12345678# 定义超参数batch_size = 128 # 批数据大小epochs = 50 # 实验训练次数units = 64 # 状态的输出维度features = 1 # 最终输出维度timesteps = 4 # 时间步长feature_range = (0, 1) # 归一化值域ratio = 0.8 # 数据集分割比例 模型定义12345678910111213141516# 模型model = Sequential()model.add(ConvLSTM2D(filters=units, kernel_size=(1,2), activation=&#x27;tanh&#x27;, input_shape=(timesteps//2, 1, timesteps//2, features)))model.add(Flatten())model.add(Dense(1))model.summary()callbacks = [ keras.callbacks.EarlyStopping(monitor=&#x27;val_loss&#x27;, patience=2), keras.callbacks.ModelCheckpoint(filepath=&#x27;model.h5&#x27;, monitor=&#x27;val_loss&#x27;, save_best_only=True), keras.callbacks.ReduceLROnPlateau(monitor=&#x27;val_loss&#x27;, factor=0.01, patience=2)]model.compile(loss=&#x27;mse&#x27;, optimizer=&#x27;adam&#x27;)# 训练history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_valid, y_valid), shuffle=False, callbacks=callbacks) 验证损失12345678validate cost: 0.00022352560738618104elapsed time: 3.2140681743621826 (s)Train Score: 2092.71 RMSEValid Score: 1663.95 RMSETest Score: 844.92 RMSE# 三种模型相较于原始的单层 stateless LSTM 模型都具有改善效果# Bidirectional LSTM 略好一点 优化方案Stateless LSTM or Bidirectional LSTM or CNN LSTM or ConvLSTM 一阶差分 or 预测增长率 本次实验使用颜色标记的方案 超参数12345678# 定义超参数batch_size = 128 # 批数据大小epochs = 50 # 实验训练次数units = 64 # 状态的输出维度features = 1 # 最终输出维度timesteps = 3 # 时间步长feature_range = (0, 1) # 归一化值域ratio = 0.8 # 数据集分割比例 模型定义123456789101112131415# 模型model = Sequential()model.add(Bidirectional(LSTM(units=units, activation=&#x27;tanh&#x27;), input_shape=(timesteps, features)))model.add(Dense(1))model.summary()callbacks = [ keras.callbacks.EarlyStopping(monitor=&#x27;val_loss&#x27;, patience=2), keras.callbacks.ModelCheckpoint(filepath=&#x27;model.h5&#x27;, monitor=&#x27;val_loss&#x27;, save_best_only=True), keras.callbacks.ReduceLROnPlateau(monitor=&#x27;val_loss&#x27;, factor=0.01, patience=2)]model.compile(loss=&#x27;mse&#x27;, optimizer=&#x27;adam&#x27;)# 训练history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_valid, y_valid), shuffle=False, callbacks=callbacks) 验证损失123456789validate cost: 0.00794555525360681elapsed time: 2.404299020767212 (s)Train Score: 1576.97 RMSEValid Score: 1307.11 RMSETest Score: 758.50 RMSE# 可以看出这个方案和预测增长率的方案的结果是一样的，改变为Bidirectional LSTM 结构有略微的好处# 这种双向循环神经网络的隐藏层保存了两个值，A 参与正向计算， A&#x27; 参与反向计算，最终的输出值 y 取决于 A 和 A&#x27; 看看细节 成功率123456validate cost: 6.0617386995090114e-09elapsed time: 3.4173359870910645 (s)Train Score: 0.05 RMSEValid Score: 0.01 RMSETest Score: 0.13 RMSE 响应时间123456validate cost: 0.009244604190229511elapsed time: 3.7244749069213867 (s)Train Score: 56.79 RMSEValid Score: 14.35 RMSETest Score: 77.87 RMSE 新的问题Why is my forecasted time series one step behind the actual time series?Github上有人给出的一种解释是：这是由于序列存在自相关性 做过时间序列的朋友可能常常会有这样的感受，用了某种算法做出来的测试集的平均绝对误差率或者r2系数都很好，但是把测试集的真实值及预测值画出来对比一下，就会发现t时刻的预测值往往是t-1时刻的真实值，也就是模型倾向于把上一时刻的真实值作为下一时刻的预测值，导致两条曲线存在滞后性，也就是真实值曲线滞后于预测值曲线，就像下图右边所显示的那样。之所以会这样，是因为序列存在自相关性，如一阶自相关指的是当前时刻的值与其自身前一时刻值之间的相关性。因此，如果一个序列存在一阶自相关，模型学到的就是一阶相关性。而消除自相关性的办法就是进行差分运算，也就是我们可以将当前时刻与前一时刻的差值作为我们的回归目标 简单的说就是特征值X包含了目标值Y，试试改为一阶差分结果作为Y，上面已经试过增长率作为Y了，结果就是误差还好，但是有负数的情况出现。 如何解决存在预测滞后的现象是因为时间序列本身存在自相关性，因为损失函数是mse，模型倾向于把上一个时刻的值当作下一个时刻的预测值，导致图形画出来看似很好，mse也很小。解决办法是消除时间序列的自相关性，可以进行差分或者分解，分解方法有EMD分解和小波分解法，上面试过差分似乎还是存在预测值滞后的问题，试过使用EMD分解一周的响应时间，性能不好，效率不高，耗时很久，效果还挺好，分解出了27个IMF分量。另外我需要证明LSTM在预测非平稳时间序列，也就是不存在自相关性的时间序列上，不存在预测值滞后的问题，我想最简单的就是构造一个一正一负的时间序列，如果LSTM模型总是拿上一个时刻的值当作下一个时刻的预测值，那么这个模型预测可以说总是错的，如果结果还好，不存在滞后问题，那么就可以使用EMD分解法来逐个预测，最后综合各个的预测结果，还有一个问题是EMD分解性能的问题，可能需要再找一个效率更高的包，可能存在也可能不存在。如果顺利的话，最后预测也是个问题，既然分解了，那么预测的时候怎么预测？ 基于EMD分解与LSTM的空气质量预测 我构造了一正一负的时间序列 正：100～150 负：-150～-100 拟合结果 再拉清楚点看看 完全重合，没有错位，没有滞后。是不是说明在平稳的非自相关性的时间序列上就不会有预测值滞后的问题，而并非特征构造的问题，因为LSTM本身就是利用过去的值来预测未来的值，要不然有个timesteps参数作何说明。","categories":[],"tags":[{"name":"LSTM","slug":"LSTM","permalink":"https://fuyunliu.github.io/tags/LSTM/"}]},{"title":"Instagram 的分片与 ID 设计","slug":"sharding-ids-at-instagram","date":"2020-06-03T02:50:07.000Z","updated":"2020-06-12T08:41:34.656Z","comments":true,"path":"2020/06/03/sharding-ids-at-instagram/","link":"","permalink":"https://fuyunliu.github.io/2020/06/03/sharding-ids-at-instagram/","excerpt":"Instagram上有大量的数据，每分钟就有超过25张的图片和90个点赞。为了确保所有重要的数据都能被合理存储并且及时得被提取应用，我们对数据进行了分片（sharding）——也就是说，我们把数据放到多个桶（bucket）中，每个桶里都有一部分数据。 我们的应用服务器上运行的是Django， 后端数据库是PostgreSQL。对数据分片首先要决定是否要保留PostgreSQL作为主要的数据存储库，是否要采用其他的数据库。经过评估一些不同的数据库解决方案，我们最终确定最适合的方案是在PostgreSQL数据库集群上实现数据分片。 然而在把数据写到数据库之前，我们还要解决如何给数据（例如Instagram上发布的没一张图片）加上唯一标识符的问题。在单一数据库上的典型解法——使用数据库自带的自增主键功能——在当数据需要被同时插入到多个数据库时就不适用了。文章的下面就来讲讲我们是如何解决这个问题的","text":"Instagram上有大量的数据，每分钟就有超过25张的图片和90个点赞。为了确保所有重要的数据都能被合理存储并且及时得被提取应用，我们对数据进行了分片（sharding）——也就是说，我们把数据放到多个桶（bucket）中，每个桶里都有一部分数据。 我们的应用服务器上运行的是Django， 后端数据库是PostgreSQL。对数据分片首先要决定是否要保留PostgreSQL作为主要的数据存储库，是否要采用其他的数据库。经过评估一些不同的数据库解决方案，我们最终确定最适合的方案是在PostgreSQL数据库集群上实现数据分片。 然而在把数据写到数据库之前，我们还要解决如何给数据（例如Instagram上发布的没一张图片）加上唯一标识符的问题。在单一数据库上的典型解法——使用数据库自带的自增主键功能——在当数据需要被同时插入到多个数据库时就不适用了。文章的下面就来讲讲我们是如何解决这个问题的 开始前，我们先列出系统所需要的所有重要的功能。 产生的数据ID需是可以按时间排序的。（比如对一列图片数据的ID进行排序，可以不需要提取太多图片本身的信息） 理想的ID是64位的。（这样索引更小，存储也更优，像Redis） 系统要尽量少的引用“可变动因素”——在很少工程师的情况下还可以扩张Instagram的很大一部分原因就是，我们相信简单易懂的方案。 现有的解决方案由Web应用层生成ID这种方案将ID的生成完全交到应用层，而不是数据库。例如，MongoDB的ObjectId，就是12字节长并且在最前面加上时间戳进行编码。另一个流行的方案是使用UUIDs。 优点： 每个应用线程独立生成ID，最小的降低ID生成的失败和竞争。 如果用时间戳作为ID的起始部分，那么ID可以按时间排序。 缺点： 通常需要更多的存储空间（96位或者更多）来确保ID的合理唯一性。 一些UUID类型完全是随机的，无法排序。 通过单独的服务产生ID例如：Twitter的Snowflake，是一个Thrift服务，使用了Apache Zookeeper来协调各个结点并且产生64为的唯一ID。 优点： Snowflake的ID只有64位，是UUID的一半。 可以放时间戳到ID头，从而可以按时间排序。 分布式系统保证了系统结点不会挂掉。 缺点： 增加了复杂性，而且引入了更多的“可变动因素”（如ZooKeeper, Snowflake服务器）到系统构架中。 数据库票据（DB Ticket）服务器利用数据库自带的自增特性来确保唯一性。Flicker采用这一方法，不过还用了两台ticket数据库（一个生成偶数，一个生成奇数）来避免单点失败。 优点： 数据库好理解，带有易预测的可扩张功能。 缺点： 最终会出现数据写入的瓶颈（尽管Flicker称在高扩展下没有问题）。 需要管理多的两台服务器（或者EC2实例）。 如果单独使用数据库，会出现单点失效。如果使用多个数据库，则不能保证ID可以按时间排序。 在所有这些方案中，Twitter的snowflake是最接近的，但是生成ID所需的添加复杂性又和我们的目标冲突。我们的替换方案是采用概念上相近的方法，但是带到PostgreSQL内部实现。 Instagram 的方案我们的分片系统是由上千个“逻辑”分片组成的，由代码映射到少量的物理分片。 通过这个方法，我们一开始用少数数据库实现，慢慢扩展到更多个数据库，只需要把部分逻辑分片从一台数据库转移到另一台数据库里，不需要重新把数据重新聚合。我们用到的PostgreSQL的schema的特性可以轻松的实现计划和管理。 Schema（不要和SQL单个表的schema搞混了）是PostgreSQL里的一个逻辑分组功能。每一个PostgreSQL数据库都有好几个schema，每一个schema都有一到多个表。表名在没个schema中都是唯一的，而不是每个数据库，默认情况下，PostgreSQL会把所有数据都放在一个叫“public”的schema中。 在我们的系统中每个“逻辑”分片都是一个PostgreSQL schema， 每个分片的表（比如照片的“点赞”功能）都存在每个schema中。 我们通过使用PL/PGSQL, PostgreSQL内部的编程语言，和PostgreSQL现有的自增功能来生成ID。 每个ID都由下面几个部分组成： 12341位的毫秒级时间（用于产生41年的ID）13位用来表示逻辑分片的ID10位的自增序列，模上1024， 意味着每个分片每毫秒可以产生1024个ID 下面通过一个例子说明：比如说现在是2011年的九月九日，我们的纪元是从2011年的一月一号开始。从新纪元开始到此有1387263000毫秒，那么我们把这个数字左移41位来填满ID的头。 id = 1387263000 &lt;&lt;(64 – 41) 接下来， 我们拿来我们准备把这个数据插入的分片ID；如果我们用户ID是31341， 这个分片的ID是 31341%2000 → 1341。 我们接下来把下面13为填满： id |= 1341 &lt;&lt; (64-41-13) 最后， 我们用所剩的自增序列（每个schema中每个表中这个序列都是唯一的）来填满的后面的位数。 假设这张表中已经有了5000个ID； 我们下一个数据就是5001，我们把它模上1024得到： id |= （5001%1024） 我们就得到了我们的ID， 我们把这个id作为insert中的RETURNING返回给应用层。 下面是是实现以上过程的PL/PGSQL代码（这里用的schema是insta5） 1234567891011121314CREATE OR REPLACE FUNCTION insta5.next_id(OUT result bigint) AS $$DECLARE our_epoch bigint := 1314220021721; seq_id bigint; now_millis bigint; shard_id int := 5;BEGIN SELECT nextval(&#x27;insta5.table_id_seq&#x27;) %% 1024 INTO seq_id; SELECT FLOOR(EXTRACT(EPOCH FROM clock_timestamp()) * 1000) INTO now_millis; result := (now_millis - our_epoch) &lt;&lt; 23; result := result | (shard_id &lt;&lt; 10); result := result | (seq_id);END;$$ LANGUAGE PLPGSQL; 要生成表示执行下面的部分： 1234CREATE TABLE insta5.our_table( &quot;id&quot; bigint NOT NULL DEFAULT insta5.next_id(), ... rest of table schema ...) 成了！我们得到了应用中唯一的主键（还有一个好处是，ID中包含了分片ID可以用来轻松映射）。我们已经把这个方法用在产品中，并且对结果感到非常满意。 本文来自：Instagram 的分片与 ID 设计","categories":[{"name":"笔记","slug":"笔记","permalink":"https://fuyunliu.github.io/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Algorithm","slug":"Algorithm","permalink":"https://fuyunliu.github.io/tags/Algorithm/"}]},{"title":"Tmux 使用教程","slug":"tmux-tutorial","date":"2020-05-29T07:03:16.000Z","updated":"2020-05-29T09:05:06.646Z","comments":true,"path":"2020/05/29/tmux-tutorial/","link":"","permalink":"https://fuyunliu.github.io/2020/05/29/tmux-tutorial/","excerpt":"Tmux 是一个终端复用工具，和 screen 一样，screen 相对简单好使，tmux 更高级。 安装12345# CentOSyum install -y tmux# MacOSbrew install tmux","text":"Tmux 是一个终端复用工具，和 screen 一样，screen 相对简单好使，tmux 更高级。 安装12345# CentOSyum install -y tmux# MacOSbrew install tmux 基本操作1234567891011121314151617181920212223242526272829303132# 新建无名称会话tmux# 新建会话tmux new -s demo# 挂起会话tmux detach# 默认进入第一个会话tmux a# 进入名为demo的会话tmux a -t demo# 关闭demo会话tmux kill-session -t demo# 关闭服务器tmux kill-server# 查看会话tmux list-sessiontmux ls# 切换会话tmux switch -t 0 # 使用会话编号tmux switch -t demo # 使用会话名称# 重命名会话tmux rename-session -t demo new-demo 系统指令 前缀 指令 描述 prefix ? 显示快捷键帮助文档 prefix d 断开当前会话 prefix D 选择要断开的会话 prefix Ctrl+z 挂起当前会话 prefix r 强制重载当前会话 prefix s 显示会话列表用于选择并切换 prefix : 进入命令行模式 prefix [ 进入复制模式，按q退出 prefix ] 粘贴复制模式中复制的文本 prefix ~ 列出提示信息缓存 窗口指令 前缀 指令 描述 prefix c 新建窗口 prefix &amp; 关闭当前窗口（关闭前需输入y or n确认） prefix 0-9 切换到指定窗口 prefix p 切换到上一窗口 prefix n 切换到下一窗口 prefix w 打开窗口列表，用于且切换窗口 prefix , 重命名当前窗口 prefix . 修改当前窗口编号（适用于窗口重新排序） prefix f 快速定位到窗口（输入关键字匹配窗口名称） 面板指令 前缀 指令 描述 prefix “ 当前面板上下一分为二，下侧新建面板 prefix % 当前面板左右一分为二，右侧新建面板 prefix x 关闭当前面板（关闭前需输入y or n确认） prefix z 最大化当前面板，再重复一次按键后恢复正常（v1.8版本新增） prefix ! 将当前面板移动到新的窗口打开（原窗口中存在两个及以上面板有效） prefix ; 切换到最后一次使用的面板 prefix q 显示面板编号，在编号消失前输入对应的数字可切换到相应的面板 prefix { 向前置换当前面板 prefix } 向后置换当前面板 prefix Ctrl+o 顺时针旋转当前窗口中的所有面板 prefix 方向键 移动光标切换面板 prefix o 选择下一面板 prefix 空格键 在自带的面板布局中循环切换 prefix Alt+方向键 以5个单元格为单位调整当前面板边缘 prefix Ctrl+方向键 以1个单元格为单位调整当前面板边缘（Mac下被系统快捷键覆盖） prefix t 显示时钟 自定义配置编辑 ~/.tmux.conf 添加如下内容 12345678910111213141516171819202122232425262728# prefix configurationset -g prefix C-aunbind C-bbind C-a send-prefix# split windowunbind &#x27;&quot;&#x27;bind - split-window -v -c &#x27;#&#123;pane_current_path&#125;&#x27;unbind %bind = split-window -h -c &#x27;#&#123;pane_current_path&#125;&#x27;# mouse onset-option -g mouse on# pane navigationbind -r k select-pane -Ubind -r j select-pane -Dbind -r h select-pane -Lbind -r l select-pane -R# pane resizingbind -r ^k resize-pane -U 2bind -r ^j resize-pane -D 2bind -r ^h resize-pane -L 2bind -r ^l resize-pane -R 2# reload configurationbind r source-file ~/.tmux.conf \\; display &#x27;~/.tmux.conf sourced&#x27;","categories":[{"name":"笔记","slug":"笔记","permalink":"https://fuyunliu.github.io/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"CentOS","slug":"CentOS","permalink":"https://fuyunliu.github.io/tags/CentOS/"}]},{"title":"Sqlalchemy 基本用法","slug":"sqlalchemy-usage","date":"2019-05-12T07:18:31.000Z","updated":"2020-05-29T09:11:11.524Z","comments":true,"path":"2019/05/12/sqlalchemy-usage/","link":"","permalink":"https://fuyunliu.github.io/2019/05/12/sqlalchemy-usage/","excerpt":"Sqlalchemy 基本用法","text":"Sqlalchemy 基本用法 通用导入12345678910from sqlalchemy import create_enginefrom sqlalchemy.orm import scoped_session, sessionmakerfrom sqlalchemy import Column, Integer, String, ForeignKey, Booleanfrom sqlalchemy.orm import relationshipfrom sqlalchemy.ext.declarative import declarative_baseengine = create_engine(&#x27;sqlite:///test.db&#x27;, echo=True)Base = declarative_base()db_session = scoped_session(sessionmaker(bind=engine))Base.query = db_session.query_property() 一对一1234567891011121314class Parent(Base): __tablename__ = &#x27;parent&#x27; id = Column(Integer, primary_key=True) name = Column(String) child_id = Column(Integer, ForeignKey(&#x27;child.id&#x27;))class Child(Base): __tablename__ = &#x27;child&#x27; id = Column(Integer, primary_key=True) name = Column(String) parent = relationship(&#x27;Parent&#x27;, backref=&#x27;child&#x27;, uselist=False) 一对多12345678910111213141516171819# the one sideclass Parent(Base): __tablename__ = &#x27;parent&#x27; id = Column(Integer, primary_key=True) name = Column(String) # children = relationship(&quot;Child&quot;, back_populates=&quot;parent&quot;) children = relationship(&quot;Child&quot;, backref=&quot;parent&quot;, lazy=&quot;dynamic&quot;)# the many sideclass Child(Base): __tablename__ = &#x27;child&#x27; id = Column(Integer, primary_key=True) name = Column(String) parent_id = Column(Integer, ForeignKey(&#x27;parent.id&#x27;)) # parent = relationship(&quot;Parent&quot;, back_populates=&quot;children&quot;) # parent = relationship(&quot;Parent&quot;, backref=&quot;children&quot;) 多对一12345678910111213141516# the many sideclass Parent(Base): __tablename__ = &#x27;parent&#x27; id = Column(Integer, primary_key=True) name = Column(String) child_id = Column(Integer, ForeignKey(&#x27;child.id&#x27;))# the one sideclass Child(Base): __tablename__ = &#x27;child&#x27; id = Column(Integer, primary_key=True) name = Column(String) parents = relationship(&#x27;Parent&#x27;, backref=&#x27;child&#x27;, lazy=&#x27;dynamic&#x27;) 多对多123456789101112131415161718192021222324252627282930class Department(Base): __tablename__ = &#x27;department&#x27; id = Column(Integer, primary_key=True) name = Column(String) employees = relationship( &#x27;Employee&#x27;, secondary=&#x27;department_employee_link&#x27; )class Employee(Base): __tablename__ = &#x27;employee&#x27; id = Column(Integer, primary_key=True) name = Column(String) hired_on = Column( DateTime, default=func.now()) departments = relationship( &#x27;Department&#x27;, secondary=&#x27;department_employee_link&#x27; )class DepartmentEmployeeLink(Base): __tablename__ = &#x27;department_employee_link&#x27; department_id = Column(Integer, ForeignKey(&#x27;department.id&#x27;), primary_key=True) department = relationship(&#x27;Department&#x27;) employee_id = Column(Integer, ForeignKey(&#x27;employee.id&#x27;), primary_key=True) employee = relationship(&#x27;Employee&#x27;) 自身多对多1234567891011121314151617181920212223class Follow(Base): __tablename__ = &#x27;me_follow_you&#x27; me_id = Column(Integer, ForeignKey(&#x27;users.id&#x27;), primary_key=True) me = relationship(&#x27;User&#x27;, foreign_keys=[me_id]) you_id = Column(Integer, ForeignKey(&#x27;users.id&#x27;), primary_key=True) you = relationship(&#x27;User&#x27;, foreign_keys=[you_id]) created = Column(DateTime(timezone=True), default=datetime.utcnow)class User(Base): __tablename__ = &#x27;users&#x27; id = Column(Integer, primary_key=True) name = Column(String(64)) # stars=我关注的人 fans=我的粉丝 stars = relationship(&#x27;User&#x27;, secondary=&#x27;me_follow_you&#x27;, primaryjoin=&#x27;User.id==Follow.me_id&#x27;, secondaryjoin=&#x27;User.id==Follow.you_id&#x27;, backref=backref(&#x27;fans&#x27;, lazy=&#x27;dynamic&#x27;), lazy=&#x27;dynamic&#x27;) 自身一对一123456class Node(Base): __tablename__ = &#x27;node&#x27; id = Column(Integer, primary_key=True) parent_id = Column(Integer, ForeignKey(&#x27;node.id&#x27;)) data = Column(String(50)) parent = relationship(&quot;Node&quot;, remote_side=[id]) 创建表1234def init_db(): from sqlalchemy import create_engine engine = create_engine(&#x27;sqlite:///test.db&#x27;, echo=True) Base.metadata.create_all(engine) backref 和 back_populates1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253Parent 下添加 `children = relationship(&quot;Child&quot;, back_populates=&quot;parent&quot;)`创建p1 = Parent()和c1 = Child()失败，原因是One or more mappers failed to initialize，即back_populates必须在关系两端同时指定Parent下添加 `children = relationship(&quot;Child&quot;, back_populates=&quot;parent&quot;)`Child下添加 `parent = relationship(&quot;Parent&quot;, back_populates=&quot;children&quot;)`Parent Attribute:Parent.children Parent.id Parent.metadata Parent.name Parent.queryChild Attribute:Child.id Child.metadata Child.name Child.parent Child.parent_id Child.queryp1 = Parent()c1 = Child()c1.parent = p1 or p1.children.append(c1)Parent下添加 `children = relationship(&quot;Child&quot;, backref=&quot;parent&quot;)`Parent Attribute:Parent.children Parent.id Parent.metadata Parent.name Parent.queryChild Attribute:Child.id Child.metadata Child.name Child.parent_id Child.queryp1 = Parent()c1 = Child()c1.parent = p1 or p1.children.append(c1)可以看出使用backref时，实例化c1时会自动在c1对象上添加parent属性此后再检查:hasattr(Child, &#x27;parent&#x27;) // Truehasattr(c1, &#x27;parent&#x27;) // Truehasattr(Parent, &#x27;children&#x27;) // Truehasattr(p1, &#x27;children&#x27;) // TrueChild 下添加 `parent = relationship(&quot;Parent&quot;, backref=&quot;children&quot;)` 情况和 3 相同Parent下添加 `children = relationship(&quot;Child&quot;, backref=&quot;parent&quot;)`Child下添加 `parent = relationship(&quot;Parent&quot;, backref=&quot;children&quot;)`创建p1 = Parent()和c1 = Child()失败，原因是One or more mappers failed to initialize因此两者只能使用其中之一lazy 指定如何加载相关记录，默认值是&quot;select&quot; select 首次访问时按需加载 immediate 源对象加载后就加载 joined 加载记录,但使用联结 subquery 立即加载,但使用子查询 noload 永不加载 dynamic 不加载记录,但提供加载记录的查询lazy = &quot;dynamic&quot;只能用于collections，不立即查询出结果集，而是提供一系列结果集的方法，可以基于结果集再次进行更精确的查找 default 和 server_default default 是在 ORM 层设置默认值，server_default 是在表结构上设置默认值 onupdate 在 ORM 层生效，server_onupdate 在数据库生效，在 MySQL 上 ON UPDATE 是MySQL在背后创建了 trigger，而在 PostgreSQL 上你必须手动创建 trigger 1234567891011121314from datetime import datetimefrom sqlalchemy import func, sql, textclass Record(Base): __tablename__ = &#x27;records id = Column(Integer, primary_key=True) name = Column(String(64), server_default=text(&#x27;name&#x27;)) created = Column(DateTime(timezone=True), default=datetime.utcnow) # created = Column(DateTime(timezone=True), server_default=func.now()) # created = Column(DateTime(timezone=True), server_default=func.current_timestamp()) updated = Column(DateTime(timezone=True), server_default=func.current_timestamp(), onupdate=func.current_timestamp()) deleted = Column(Boolean, default=False) # deleted = Column(Boolean, server_default=sql.expression.false()) 为flask_sqlalchemy扩展BaseQuery方法12345678910from flask_sqlalchemy import SQLAlchemy, BaseQueryfrom sqlalchemy import funcclass CustomQuery(BaseQuery): def count_all(self): return self.with_entities(func.count()).scalar()db = SQLAlchemy(query_class=CustomQuery)","categories":[{"name":"笔记","slug":"笔记","permalink":"https://fuyunliu.github.io/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Sqlalchemy","slug":"Sqlalchemy","permalink":"https://fuyunliu.github.io/tags/Sqlalchemy/"}]},{"title":"二叉树","slug":"treenode","date":"2019-01-15T05:52:53.000Z","updated":"2019-08-06T14:05:27.569Z","comments":true,"path":"2019/01/15/treenode/","link":"","permalink":"https://fuyunliu.github.io/2019/01/15/treenode/","excerpt":"LeetCode 二叉树题解汇总","text":"LeetCode 二叉树题解汇总 二叉树定义12345class TreeNode: def __init__(self, x): self.val = x self.left = None self.right = None 相同的树1234567def is_same_tree(p, q): if p is None: return not q if q is None: return not p return p.val == q.val and is_same_tree(p.left, q.left) and is_same_tree(p.right, q.right) 对称的树12345678910111213def is_symmetric(root): if not root: return True return symmetric(root.left, root.right)def symmetric(l1, l2): if l1 is None: return not l2 if l2 is None: return not l1 return l1.val == l2.val and symmetric(l1.left, l2.right) and symmetric(l1.right, l2.left) 层次遍历给定一个二叉树，返回其按层次遍历的节点值。 1234567891011121314def add(node, level, res): if node is None: return if len(res) &lt; level: res.append([]) res[level - 1].append(node.val) add(node.left, level + 1, res) add(node.right, level + 1, res)def level_order(root): res = [] add(root, 1, res) return res 最大深度给定一个二叉树，找出其最大深度。 二叉树的深度为根节点到最远叶子节点的最长路径上的节点数。 123def max_depth(root): return 1 + max(map(max_depth, (root.left, root.right))) if root else 0 最小深度给定一个二叉树，找出其最小深度。 最小深度是从根节点到最近叶子节点的最短路径上的节点数量。 12345678910111213141516def min_depth(root): if root is None: return 0 if root.left is None: return 1 + min_depth(root.right) if root.right is None: return 1 + min_depth(root.left) return 1 + min(map(min_depth, (root.left, root.right)))# 更简洁的写法def min_depth(root): if root is None: return 0 depth_under_root = map(min_depth, (root.left, root.right)) return 1 + (min(depth_under_root) or max(depth_under_root)) 将有序数组转化为二叉树将一个按照升序排列的有序数组，转换为一棵高度平衡二叉搜索树。 高度平衡二叉树是指一个二叉树每个节点的左右两个子树的高度差的绝对值不超过1。 12345678def sorted_array_to_balanced_tree(nums): if not nums: return None mid = len(nums) // 2 root = TreeNode(nums[mid]) root.left = sorted_array_to_balanced_tree(nums[:mid]) root.right = sorted_array_to_balanced_tree(nums[mid + 1:]) 平衡二叉树一个二叉树每个节点的左右两个子树的高度差的绝对值不超过1。 12345678910def hight(node): if node is None: return 0 return 1 + max(map(hight, (node.left, node.right)))def is_balanced(root): if root is None: return True return abs(hight(root.left) - hight(root.right)) &lt;= 1 and is_balanced(root.left) and is_balanced(root.right) 路径总和给定一个二叉树和一个目标和，判断该树中是否存在根节点到叶子节点的路径，这条路径上所有节点值相加等于目标和。 1234567def has_path_sum(root, sums): if root is None: return False if root.left or root.right: return has_path_sum(root.left, sums - root.val) or has_path_sum(root.right, sums - root.val) return sums == root.val","categories":[{"name":"笔记","slug":"笔记","permalink":"https://fuyunliu.github.io/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Python3","slug":"Python3","permalink":"https://fuyunliu.github.io/tags/Python3/"}]},{"title":"Python 处理 Csv 文件常见错误","slug":"csv-error","date":"2018-12-03T02:53:31.000Z","updated":"2020-05-29T09:08:21.774Z","comments":true,"path":"2018/12/03/csv-error/","link":"","permalink":"https://fuyunliu.github.io/2018/12/03/csv-error/","excerpt":"在用 Python 处理 csv 文件时遇到2个错误，记录下处理方法。","text":"在用 Python 处理 csv 文件时遇到2个错误，记录下处理方法。 字段包含 NULL 值csv 文件中字段包含 NULL 值会出错，解决方法是读取文件时把 NULL 值替换为空字符串。 12345import csvwith open(&#x27;test.csv&#x27;, &#x27;rt&#x27;, encoding=&#x27;utf-8&#x27;) as f: fc = csv.DictReader((line.replace(&#x27;\\0&#x27;, &#x27;&#x27;) for line in f)) # do something with fc OverflowError and maxInt123456789101112131415161718192021import csvimport sysmaxInt = sys.maxsizedecrement = Truewhile decrement: # decrease the maxInt value by factor 10 # as long as the OverflowError occurs. decrement = False try: csv.field_size_limit(maxInt) except OverflowError: maxInt = int(maxInt / 10) decrement = Truewith open(&#x27;test.csv&#x27;, &#x27;rt&#x27;, encoding=&#x27;utf-8&#x27;) as f: fc = csv.DictReader(f) # do something with fc","categories":[{"name":"笔记","slug":"笔记","permalink":"https://fuyunliu.github.io/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Python3","slug":"Python3","permalink":"https://fuyunliu.github.io/tags/Python3/"}]},{"title":"Centos 安装 PhantomJS","slug":"centos-install-phantomjs","date":"2018-11-21T08:10:23.000Z","updated":"2020-05-29T09:07:54.413Z","comments":true,"path":"2018/11/21/centos-install-phantomjs/","link":"","permalink":"https://fuyunliu.github.io/2018/11/21/centos-install-phantomjs/","excerpt":"PhantomJS 已经不再开发了，Seleniumn 也警告使用 PhantomJS 是过时的，推荐使用 headless 版的 Chrome 或者 Firefox，但是有时候需要用到，够用就行，而且在 Linux 下安装也相对简单。","text":"PhantomJS 已经不再开发了，Seleniumn 也警告使用 PhantomJS 是过时的，推荐使用 headless 版的 Chrome 或者 Firefox，但是有时候需要用到，够用就行，而且在 Linux 下安装也相对简单。 安装 fontconfig 依赖1yum install -y fontconfig freetype freetype-devel fontconfig-devel libstdc++ 下载 PhantomJS 并解压1234567891011121314151617# 安装到此目录cd /usr/local# 下载wget https://bitbucket.org/ariya/phantomjs/downloads/phantomjs-2.1.1-linux-x86_64.tar.bz2# 解压tar -jxvf phantomjs-2.1.1-linux-x86_64.tar.bz2# 重命名mv phantomjs-2.1.1-linux-x86_64 phantomjs# 添加软链接ln -s /usr/local/phantomjs/bin/phantomjs /usr/bin/phantomjs# 验证phantomjs --version 用 Sselenium 驱动 PhantomJS12345678910from selenium import webdriverfrom selenium.webdriver.common.desired_capabilities import DesiredCapabilities# 更改浏览器头dcap = dict(DesiredCapabilities.PHANTOMJS)dcap[&quot;phantomjs.page.settings.userAgent&quot;] = &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.102 Safari/537.36&quot;driver = webdriver.PhantomJS(desired_capabilities=dcap)driver.set_page_load_timeout(10)driver.set_script_timeout(10)driver.get(&quot;https://www.baidu.com&quot;) 推荐使用的 Chrome 用法1234567891011121314151617181920212223242526from selenium import webdriverfrom selenium.webdriver.chrome.options import Options# 无界面浏览器options = Options()options.add_argument(&#x27;headless&#x27;)options.add_argument(&#x27;disable-gpu&#x27;)options.add_argument(&#x27;window-size=1200x600&#x27;)# 禁用 javascriptprefs = &#123;&#x27;profile.managed_default_content_settings.javascript&#x27;: 2&#125;options.add_experimental_option(&quot;prefs&quot;, prefs)# 禁止弹出式窗口prefs = &#123;&quot;profile.default_content_setting_values.notifications&quot;: 2&#125;options.add_experimental_option(&quot;prefs&quot;, prefs)# 禁用图片prefs = &#123;&#x27;profile.managed_default_content_settings.images&#x27;: 2&#125;options.add_experimental_option(&quot;prefs&quot;, prefs)driver = webdriver.Chrome(chrome_options=options)# 执行JSdriver.execute_script(&#x27;window.scrollTo(0, 0)&#x27;) # scroll to topdriver.execute_script(&#x27;window.scrollTo(0, document.body.scrollHeight)&#x27;) # end","categories":[{"name":"笔记","slug":"笔记","permalink":"https://fuyunliu.github.io/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Python3","slug":"Python3","permalink":"https://fuyunliu.github.io/tags/Python3/"},{"name":"CentOS","slug":"CentOS","permalink":"https://fuyunliu.github.io/tags/CentOS/"}]},{"title":"Python 通过 Thrift 操作 Hbase","slug":"hbase-thrift","date":"2018-11-14T09:04:20.000Z","updated":"2020-05-29T09:09:05.236Z","comments":true,"path":"2018/11/14/hbase-thrift/","link":"","permalink":"https://fuyunliu.github.io/2018/11/14/hbase-thrift/","excerpt":"记录 Python 通过 Thrift 操作 Hbase 的通用操作方法。","text":"记录 Python 通过 Thrift 操作 Hbase 的通用操作方法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160from thrift.transport import TSocketfrom thrift.protocol import TBinaryProtocolfrom thrift.transport import TTransportfrom elasticsearch import Elasticsearchfrom hbase import Hbase# Connect to HBase Thrift servertransport = TTransport.TBufferedTransport(TSocket.TSocket(&#x27;localhost&#x27;, 9090))protocol = TBinaryProtocol.TBinaryProtocolAccelerated(transport)# Create and open the client connectionclient = Hbase.Client(protocol)transport.open()# Connect to Elasticsearch serveres = Elasticsearch(&#x27;localhost&#x27;, http_auth=(&#x27;username&#x27;, &#x27;password&#x27;), port=&#x27;9200&#x27;, timeout=30, max_retries=10, retry_on_timeout=True )def fetch_one(index, doc_type, body, size=1): &quot;&quot;&quot;查询es获取第一条匹配的数据 Arguments: index &#123;str&#125; -- 索引 doc_type &#123;str&#125; -- 类型 body &#123;dict&#125; -- 查询语句 Keyword Arguments: size &#123;int&#125; -- 返回数量 (default: &#123;1&#125;) Returns: dict -- 一条数据，没有结果返回 None &quot;&quot;&quot; res = es.search(index=index, doc_type=doc_type, scroll=&#x27;2m&#x27;, body=body, size=size) hits = res[&#x27;hits&#x27;][&#x27;hits&#x27;] return hits[0] if hits else Nonedef fetch_all(index, doc_type, body, size=100): &quot;&quot;&quot;查询es获取所有匹配的结果 Arguments: index &#123;str&#125; -- 索引 doc_type &#123;str&#125; -- 类型 body &#123;dict&#125; -- 查询语句 Keyword Arguments: size &#123;int&#125; -- 返回数量 (default: &#123;100&#125;) Returns: list -- 结果集 &quot;&quot;&quot; res = es.search(index=index, doc_type=doc_type, scroll=&#x27;2m&#x27;, body=body, size=size) return res[&#x27;hits&#x27;][&#x27;hits&#x27;]def build_term(field, value): &quot;&quot;&quot;term Arguments: field &#123;str&#125; -- 字段 value &#123;str&#125; -- 值 Returns: dict -- 查询语句 &quot;&quot;&quot; body = &#123; &quot;query&quot;: &#123; &quot;term&quot;: &#123; field: &#123; &quot;value&quot;: value &#125; &#125; &#125; &#125; return bodydef build_terms(field, values): &quot;&quot;&quot;terms Arguments: field &#123;str&#125; -- 字段 values &#123;list&#125; -- 列表 Returns: dict -- 查询语句 &quot;&quot;&quot; body = &#123; &quot;query&quot;: &#123; &quot;terms&quot;: &#123; field: values &#125; &#125; &#125; return bodydef get_row_with_columns(table_name, rowkey, columns): &quot;&quot;&quot;根据 rowkey 从 hbase 获取一条数据 Arguments: table_name &#123;str&#125; -- 表名 rowkey &#123;str&#125; -- rowkey attributes &#123;list&#125; -- 属性列表 Returns: dict -- 一条数据，没有则返回None &quot;&quot;&quot; table_name = table_name.encode() rowkey = rowkey.encode() columns = [(&#x27;0:&#x27; + c).encode() for c in columns] res = client.getRowWithColumns(table_name, rowkey, columns, None) if not res: return None d = &#123; k.decode().split(&#x27;:&#x27;)[1]: v.value.decode() for k, v in res[0].columns.items() &#125; d[&#x27;rowkey&#x27;] = res[0].row.decode() return ddef get_rows_with_columns(table_name, rowkeys, columns): &quot;&quot;&quot;根据 rowkeys 从 hbase 获取所有匹配的数据 Arguments: table_name &#123;str&#125; -- 表名 rowkeys &#123;list&#125; -- rowkey 列表 columns &#123;list&#125; -- 指定返回字段 Returns: list -- 数据结果集 &quot;&quot;&quot; data = [] table_name = table_name.encode() rowkeys = [k.encode() for k in rowkeys] columns = [(&#x27;0:&#x27; + c).encode() for c in columns] res = client.getRowsWithColumns(table_name, rowkeys, columns, None) for r in res: d = &#123; k.decode().split(&#x27;:&#x27;)[1]: v.value.decode() for k, v in r.columns.items() &#125; d[&#x27;rowkey&#x27;] = r.row.decode() data.append(d) return data","categories":[{"name":"笔记","slug":"笔记","permalink":"https://fuyunliu.github.io/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Python3","slug":"Python3","permalink":"https://fuyunliu.github.io/tags/Python3/"}]},{"title":"Asyncio 笔记","slug":"asyncio-tutorial","date":"2018-11-11T07:02:28.000Z","updated":"2019-08-06T13:58:49.803Z","comments":true,"path":"2018/11/11/asyncio-tutorial/","link":"","permalink":"https://fuyunliu.github.io/2018/11/11/asyncio-tutorial/","excerpt":"并发是指一次处理多件事。 并行是指一次做多件事。 二者不同，但是有联系。 一个关于结构，一个关于执行。 并发用于制定方案，用来解决可能（但未必）并行的问题。 ——Rob Pike Go 语言的创造者之一","text":"并发是指一次处理多件事。 并行是指一次做多件事。 二者不同，但是有联系。 一个关于结构，一个关于执行。 并发用于制定方案，用来解决可能（但未必）并行的问题。 ——Rob Pike Go 语言的创造者之一 异步版 hello-world12345678910111213import asyncioasync def main(): print(&#x27;hello&#x27;) await asyncio.sleep(.1) print(&#x27;world&#x27;)# python3.7 提供asyncio.run(main())# main 函数是个协程，直接运行不会执行操作# main() --&gt; &lt;coroutine object main at 0x109be6d48&gt; 运行协程的三种方式 asyncio.run() 使用 await 关键字 123456789101112131415161718import asyncioimport timeasync def say_after(delay, what): await asyncio.sleep(delay) print(what)async def main(): print(f&quot;started at &#123;time.strftime(&#x27;%X&#x27;)&#125;&quot;) await say_after(1, &#x27;hello&#x27;) await say_after(2, &#x27;world&#x27;) print(f&quot;finished at &#123;time.strftime(&#x27;%X&#x27;)&#125;&quot;)asyncio.run(main()) 使用 asyncio.create_task() 创建一个 Task 对象 1234567891011# 直接对上面的 main 函数进行修改async def main(): t1 = asyncio.create_task(say_after(1, &#x27;hello&#x27;)) t2 = asyncio.create_task(say_after(2, &#x27;world&#x27;)) print(f&quot;started at &#123;time.strftime(&#x27;%X&#x27;)&#125;&quot;) await t1 await t2 print(f&quot;finished at &#123;time.strftime(&#x27;%X&#x27;)&#125;&quot;) Awaitable 对象awaitable 对象是指可以在 await 表达式中使用的对象。 coroutines, Tasks 和 Futures 是 awaitable 对象。 协程 coroutines 1234567891011121314151617import asyncioasync def nested(): return 42async def main(): # 这中方式不会执行 nested 函数 nested() # await print(await nested())asyncio.run(main()) 任务 Tasks 12345678910111213import asyncioasync def nested(): return 42async def main(): t = asyncio.create_task(nested()) await tasyncio.run(main()) 期物 Futures 并发执行 Tasks使用 asyncio.gather 并发执行 Tasks 123456789101112131415161718192021import asyncioasync def factorial(name, number): f = 1 for i in range(2, number + 1): print(f&quot;Task &#123;name&#125;: Compute factorial(&#123;i&#125;)...&quot;) await asyncio.sleep(1) f *= i print(f&quot;Task &#123;name&#125;: factorial(&#123;number&#125;) = &#123;f&#125;&quot;)async def main(): await asyncio.gather( factorial(&#x27;A&#x27;, 2), factorial(&#x27;B&#x27;, 3), factorial(&#x27;C&#x27;, 4), )asyncio.run(main()) 线程和协程的对比12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# 线程版以动画形式显示文本旋转指针import threadingimport itertoolsimport timeimport sysclass Signal: go = Truedef spin(msg, signal): write, flush = sys.stdout.write, sys.stdout.flush for char in itertools.cycle(&#x27;|/-\\\\&#x27;): status = char + &#x27; &#x27; + msg write(status) flush() write(&#x27;\\x08&#x27; * len(status)) time.sleep(.1) if not signal.go: break write(&#x27; &#x27; * len(status) + &#x27;\\x08&#x27; * len(status))def slow_funtion(): time.sleep(3) return 42def supervisor(): signal = Signal() spinner = threading.Thread( target=spin, args=(&#x27;thinking!&#x27;, signal)) print(&#x27;spinner object: &#x27;, spinner) spinner.start() result = slow_funtion() signal.go = False spinner.join() return resultdef main(): result = supervisor() print(&#x27;Answer: &#x27;, result)if __name__ == &#x27;__main__&#x27;: main() 123456789101112131415161718192021222324252627282930313233343536373839404142# 协程版以动画形式显示文本旋转指针import asyncioimport itertoolsimport sysasync def spin(msg): write, flush = sys.stdout.write, sys.stdout.flush for char in itertools.cycle(&#x27;|/-\\\\&#x27;): status = char + &#x27; &#x27; + msg write(status) flush() write(&#x27;\\x08&#x27; * len(status)) try: await asyncio.sleep(.1) except asyncio.CancelledError: break write(&#x27; &#x27; * len(status) + &#x27;\\x08&#x27; * len(status))async def slow_funtion(): await asyncio.sleep(3) return 42async def supervisor(): spinner = asyncio.create_task(spin(&#x27;thinking!&#x27;)) print(&#x27;spinner object: &#x27;, spinner) result = await slow_funtion() spinner.cancel() return result# 一般执行方式loop = asyncio.get_event_loop()result = loop.run_until_complete(supervisor())loop.close()print(&#x27;Answer: &#x27;, result)# python3.7 执行方式asyncio.run(supervisor()) Task 对象像是实现协作式多任务的库（如 gevent）中的绿色线程（green thread）。 Task 对象用于驱动协程，Thread 对象用于调用可调用对象。 Task 对象不由自己手动实例化，而是由 asyncio.create_task 方法获取。 获取的 Task 对象已经排定了运行时间，而 Thread 实例需要调用 start 方法运行。 异步版 slow_funtion 是协程，由 await （就是 yield from）驱动。 终止线程需要借助外部变量 go,终止 Task 可以调用 Task.cancel() 实例方法，在协程内部抛出 CancelledError 异常，协程内部也可以捕获这个异常，处理终止请求。","categories":[{"name":"笔记","slug":"笔记","permalink":"https://fuyunliu.github.io/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Python3","slug":"Python3","permalink":"https://fuyunliu.github.io/tags/Python3/"}]},{"title":"外国小说鉴赏辞典","slug":"foreign-novel-appreciation-dictionary","date":"2018-11-03T02:03:31.000Z","updated":"2019-08-06T14:02:44.978Z","comments":true,"path":"2018/11/03/foreign-novel-appreciation-dictionary/","link":"","permalink":"https://fuyunliu.github.io/2018/11/03/foreign-novel-appreciation-dictionary/","excerpt":"外国小说鉴赏辞典，从图书馆拍来的目录，纯手码，很累！","text":"外国小说鉴赏辞典，从图书馆拍来的目录，纯手码，很累！ 古代至19世纪中期卷 书名 国籍 作者 阿玛莉亚 阿根廷 马莫尔 魂归故里 波兰 克拉舍夫斯基 春香传 朝鲜 佚名 痴儿西木传 德国 格里美尔斯豪森 少年维特的烦恼 德国 歌德 威廉·麦斯特的学习时代 德国 歌德 亲和力 德国 歌德 金罐 德国 霍夫曼 侏儒查赫斯 德国 霍夫曼 雄猫穆尔的生活观 德国 霍夫曼 温亭娜 德国 富凯 彼得·史勒密尔的奇怪故事 德国 沙米索 茵梦湖 德国 施托姆 驿站长 俄国 普希金 黑桃皇后 俄国 普希金 上尉的女儿 俄国 普希金 狂人日记 俄国 果戈里 塔拉斯·布利巴 俄国 果戈里 外套 俄国 果戈里 死魂灵 俄国 果戈里 谁之罪 俄国 赫尔岑 偷东西的喜鹊 俄国 赫尔岑 平凡的故事 俄国 冈察洛夫 当代英雄 俄国 莱蒙托夫 木木 俄国 屠格涅夫 白夜 俄国 陀思妥耶夫斯基 巨人传 法国 拉伯雷 吉尔·布拉斯 法国 勒萨日 波斯人信札 法国 孟德斯鸠 查第格 法国 伏尔泰 老实人 法国 伏尔泰 玛农·列斯戈 法国 普莱服神甫 新爱洛伊丝 法国 卢梭 爱弥儿 法国 卢梭 拉摩的侄子 法国 狄德罗 定命论者雅克和他的主人 法国 狄德罗 阿达拉 法国 夏多布里昂 阿尔芒丝 法国 司汤达 红与黑 法国 司汤达 巴马修道院 法国 司汤达 驴皮记 法国 巴尔扎克 欧也妮·葛朗台 法国 巴尔扎克 高老头 法国 巴尔扎克 幻灭 法国 巴尔扎克 邦斯舅舅 法国 巴尔扎克 三个火枪手 法国 大仲马 基督山恩仇记 法国 大仲马 巴黎圣母院 法国 雨果 高龙巴 法国 梅里美 嘉尔曼 法国 梅里美 巴黎的秘密 法国 欧仁·苏 安吉堡的磨工 法国 乔治·桑 一个世纪的忏悔 法国 缪塞 外祖母 捷克 涅姆佐娃 癞皮鹦鹉 墨西哥 利萨尔迪 瑞普·凡·温克尔 美国 欧文 睡谷的传说 美国 欧文 最后的莫西干人 美国 库柏 杀鹿人 美国 库柏 拉帕其尼医生的女儿 美国 霍桑 红字 美国 霍桑 七个尖角顶的宅第 美国 霍桑 黑猫 美国 爱伦·坡 厄舍府的倒塌 美国 爱伦·坡 毛格街血案 美国 爱伦·坡 汤姆叔叔的小屋 美国 斯托夫人 白鲸 美国 麦尔维尔 竹取物语 日本 佚名 源氏物语 日本 紫式部 平家物语 日本 佚名 浮世澡堂 日本 式亭三马 绿衣亨利 瑞士 凯勒 小癞子 西班牙 佚名 堂吉诃德 西班牙 塞万提斯 金驴记 古罗马 阿普列乌斯 十日谈 意大利 卜伽丘 太阳城 意大利 康帕内拉 约婚夫妇 意大利 孟佐尼 坎特伯雷故事集 英国 乔叟 天路历程 英国 班扬 鲁宾逊漂流记 英国 笛福 格列佛游记 英国 斯威夫特 帕梅拉 英国 理查森 大伟人江奈生·魏尔德传 英国 菲尔丁 汤姆·琼斯 英国 菲尔丁 感伤的旅程 英国 斯特恩 蓝登传 英国 斯摩莱特 威克菲牧师传 英国 哥尔斯密 爱丁堡监狱 英国 司各特 艾凡赫 英国 司各特 理智与情感 英国 奥斯丁 傲慢与偏见 英国 奥斯丁 爱玛 英国 奥斯丁 玛丽·巴顿 英国 盖斯凯尔夫人 名利场 英国 萨克雷 钮可谟一家 英国 李敦 庞贝城的末日 英国 狄更斯 匹克维克外传 英国 狄更斯 雾都孤儿 英国 狄更斯 老古玩店 英国 狄更斯 大卫·考坡菲 英国 狄更斯 简·爱 英国 夏洛蒂·勃朗特 呼啸山庄 英国 艾米莉·勃朗特 19世纪下半期卷 书名 国籍 作者 为了面包 波兰 显克微支 火与剑 波兰 显克微支 洪流 波兰 显克微支 十字军骑士 波兰 显克微支 傀儡 波兰 普鲁斯 福地 波兰 莱蒙特 三色紫罗兰 德国 史托姆 白马骑士 德国 史托姆 艾菲·布里斯特 德国 冯塔纳 奥勃洛摩夫 俄国 冈察洛夫 悬崖 俄国 冈察洛夫 罗亭 俄国 屠格涅夫 贵族之家 俄国 屠格涅夫 前夜 俄国 屠格涅夫 初恋 俄国 屠格涅夫 父与子 俄国 屠格涅夫 罪与罚 俄国 陀思妥耶夫斯基 白痴 俄国 陀思妥耶夫斯基 群魔 俄国 陀思妥耶夫斯基 卡拉马佐夫兄弟 俄国 陀思妥耶夫斯基 怎么办？ 俄国 车尔尼雪夫斯基 琉森 俄国 列夫·托尔斯泰 哥萨克 俄国 列夫·托尔斯泰 战争与和平 俄国 列夫·托尔斯泰 安娜·卡列尼娜 俄国 列夫·托尔斯泰 伊万·伊利奇之死 俄国 列夫·托尔斯泰 复活 俄国 列夫·托尔斯泰 大堂神父 俄国 列斯科夫 左撇子 俄国 列斯科夫 盲音乐家 俄国 柯罗连科 棕榈 俄国 迦尔洵 变色龙 俄国 契诃夫 苦恼 俄国 契诃夫 草原 俄国 契诃夫 第六病室 俄国 契诃夫 装在套子里的人 俄国 契诃夫 悲惨世界 法国 雨果 海上劳工 法国 雨果 笑面人 法国 雨果 九三年 法国 雨果 包法利夫人 法国 福楼拜 萨朗波 法国 福楼拜 情感教育 法国 福楼拜 格兰特船长的儿女 法国 凡尔纳 起义者 法国 瓦莱斯 小酒店 法国 左拉 萌芽 法国 左拉 金钱 法国 左拉 小东西 法国 都德 最后一课 法国 都德 苔依丝 法国 法郎士 羊脂球 法国 莫泊桑 一生 法国 莫泊桑 我的叔叔于勒 法国 莫泊桑 项链 法国 莫泊桑 漂亮朋友 法国 莫泊桑 起义者 菲律宾 黎萨尔 玛丽亚 哥伦比亚 伊萨克斯 马格斯·哈弗拉尔 荷兰 穆尔塔图里 野姑娘芭拉 捷克 聂姆佐娃 庄园内外 捷克 聂姆佐娃 竞选州长 美国 马克·吐温 汤姆·索亚历险记 美国 马克·吐温 王子与贫儿 美国 马克·吐温 哈克贝里·芬历险记 美国 马克·吐温 塞拉斯·拉帕姆的发迹 美国 豪威尔斯 黛西·米勒 美国 詹姆斯 一位女士的画像 美国 詹姆斯 嘉莉妹妹 美国 德莱塞 饥饿 挪威 汉姆生 阿马罗神父的罪恶 葡萄牙 克罗兹 舞姬 日本 森鸥外 浮云 日本 二叶亭四迷 慈悲心肠 西班牙 佩雷斯·加尔多斯 庭长夫人 西班牙 克拉林 金人 匈牙利 约卡伊·莫尔 圣彼得的伞 匈牙利 米克沙特·卡尔曼 奇婚记 匈牙利 米克沙特·卡尔曼 斯巴达克思 意大利 乔万尼奥里 女乞丐 印度 泰戈尔 饥饿的石头 印度 泰戈尔 妻子和女儿 英国 盖斯凯尔夫人 艰难时世 英国 狄更斯 双城记 英国 狄更斯 远大前程 英国 狄更斯 教师 英国 夏洛蒂·勃朗特 亚当·贝德 英国 乔治·艾略特 佛洛斯河磨坊 英国 乔治·艾略特 织工马南转 英国 乔治·艾略特 米德尔马契 英国 乔治·艾略特 远离尘嚣 英国 哈代 还乡 英国 哈代 卡斯特桥市长 英国 哈代 德伯家的苔丝 英国 哈代 无名的裘德 英国 哈代 化身博士 英国 斯蒂文森 诱拐 英国 斯蒂文森 金银岛 英国 斯蒂文森 道林·格雷的画像 英国 王尔德 黑暗的心 英国 康拉德 吉姆爷 英国 康拉德 牛虻 英国 伏尼契 丛林故事 英国 吉卜林 时间机器 英国 威尔斯 马丁·里瓦斯 智利 布莱斯特·加纳 20世纪前期卷 书名 国籍 作者 都柏林人 爱尔兰 乔伊斯 一个青年艺术家的画像 爱尔兰 乔伊斯 尤利西斯 爱尔兰 乔伊斯 一个陌生女人的来信 奥地利 茨威格 变形记 奥地利 卡夫卡 饥饿艺术家 奥地利 卡夫卡 城堡 奥地利 卡夫卡 地洞 奥地利 卡夫卡 农民 波兰 莱蒙特 征服者贝莱 丹麦 尼克索 垃圾教授 德国 亨利希·曼 臣仆 德国 亨利希·曼 布登勃洛克一家 德国 托马斯·曼 死于威尼斯 德国 托马斯·曼 魔山 德国 托马斯·曼 荒原狼 德国 黑塞 纳尔齐斯与歌尔德蒙 德国 黑塞 柏林，亚历山大广场 德国 德布林 西线无战事 德国 雷马克 《基督与反基督》三部曲 俄国 梅列日科夫斯基 决斗 俄国 库普林 石榴石手镯 俄国 库普林 乡村 俄国 布宁 阿尔谢尼耶夫的一生 俄国 布宁 红笑 俄国 安德烈耶夫 七个被绞死者的故事 俄国 安德烈耶夫 企鹅岛 法国 法郎士 诸神渴了 法国 法郎士 约翰·克里斯朵夫 法国 罗曼·罗兰 母与子 法国 罗曼·罗兰 伪币制造者 法国 纪德 追寻逝去的时光 法国 普鲁斯特 火线-一个步兵班的日记 法国 巴比塞 苔蕾丝·德斯盖鲁 法国 莫里亚克 旋涡 哥伦比亚 里维拉 好兵帅克 捷克 哈谢克 折断的翅膀 黎巴嫩 纪伯伦 麦琪的礼物 美国 欧·亨利 最后一片叶子 美国 欧·亨利 章鱼 美国 诺里斯 珍尼姑娘 美国 德莱塞 美国悲剧 美国 德莱塞 啊，拓荒者！ 美国 凯瑟 荒野的呼唤 美国 杰克·伦敦 小城畸人 美国 杰克·伦敦 了不起的盖茨比 美国 菲茨杰拉德 喧哗与骚动 美国 福克纳 我弥留之际 美国 福克纳 太阳照常升起 美国 海明威 永别了，武器 美国 海明威 情侣 缅甸 詹姆斯拉觉 劳伦斯之女克里斯丁 挪威 温塞特 我是猫 日本 夏目漱石 棉被 日本 田山花袋 破戒 日本 岛崎藤村 新珠 日本 菊池宽 罗生门 日本 芥川龙之介 橘子 日本 芥川龙之介 竹林中 日本 芥川龙之介 太阳 日本 横光利一 没有太阳的街 日本 德永直 蟹工船 日本 小林多喜二 雅考伯·冯·贡腾 瑞士 罗伯特·瓦尔泽 母亲 苏联 高尔基 奥库罗夫镇 苏联 高尔基 阿尔塔莫诺夫家的事业 苏联 高尔基 彼得堡 苏联 别雷 我们 苏联 扎米亚京 孽卵 苏联 布尔加科夫 狗心 苏联 布尔加科夫 第四十一 苏联 拉夫列尼约夫 基坑 苏联 普拉东诺夫 伊斯坦布尔的姑娘 土耳其 君泰金 堂娜芭芭拉 委内瑞拉 加列戈斯 迷雾 西班牙 乌纳穆诺 碧血黄沙 西班牙 布拉斯科·伊巴涅斯 孤独者 意大利 皮兰德娄 坛子 意大利 皮兰德娄 已故的帕斯卡尔 意大利 皮兰德娄 沉船 印度 泰戈尔 戈拉 印度 泰戈尔 斯里甘特 印度 查特吉 仁爱道院 印度 普列姆昌德 半斤小麦 印度 普列姆昌德 有产业的人 英国 高尔斯华绥 穿破裤子的慈善家 英国 特莱赛尔 人生的枷锁 英国 毛姆 看得见风景房间 英国 福斯特 印度之行 英国 福斯特 密林中的村庄 英国 伦纳德·伍尔夫 达洛卫夫人 英国 弗吉尼亚·伍尔夫 到灯塔去 英国 弗吉尼亚·伍尔夫 儿子与情人 英国 劳伦斯 虹 英国 劳伦斯 查泰莱夫人的情人 英国 劳伦斯 20世纪中期卷 书名 国籍 作者 小径分岔的花园 阿根廷 博尔赫斯 环形废墟 阿根廷 博尔赫斯 人树 澳大利亚 怀特 一杯茶 澳大利亚 怀特 象棋的故事 奥地利 茨威格 无边的土地 巴西 亚马多 绿蒂在魏玛 德国 托马斯·曼 玻璃球游戏 德国 黑塞 戈雅 德国 福伊希特万格 凯旋门 德国 雷马克 第七个十字架 德国 西格斯 迷惘 德国 卡内蒂 小丑之见 德国 伯尔 淡漠的人 德国 伦茨 铁皮鼓 德国 格拉斯 猫与鼠 德国 格拉斯 分裂的天空 德国 沃尔夫 俄罗斯森林 俄罗斯 列昂诺夫 伊万·杰尼索维奇的一天 俄罗斯 索尔仁尼琴 癌病房 俄罗斯 索尔仁尼琴 蒂博一家 法国 马丁·杜·加尔 蛇结 法国 莫里亚克 小王子 法国 圣埃克絮佩里 人的命运 法国 马尔罗 法兰西组曲 法国 内米洛夫斯基 恶心 法国 萨特 墙 法国 萨特 局外人 法国 加缪 鼠疫 法国 加缪 弗兰德公路 法国 西蒙 琴声如诉 法国 杜拉斯 橡皮 法国 罗伯-格里耶 窥视者 法国 罗伯-格里耶 变 法国 布托尔 你好，忧愁 法国 萨冈 伊萨贝尔在马孔多观雨时的独白 哥伦比亚 马尔克斯 百年孤独 哥伦比亚 马尔克斯 消失了的足迹 古巴 卡彭铁尔 查密莉雅 吉尔吉斯斯坦 艾特玛托夫 愚人船 美国 波特 北回归线 美国 米勒 夜色温柔 美国 菲茨杰拉德 八月之光 美国 福克纳 押沙龙，押沙龙！ 美国 福克纳 熊 美国 福克纳 乞力马扎罗的雪 美国 海明威 老人与海 美国 海明威 洛丽塔 美国 博纳科夫 市场街的斯宾诺莎 美国 辛格 店员 美国 马拉默德 魔桶 美国 马拉默德 赫索格 美国 贝娄 伤心咖啡馆之歌 美国 麦卡勒斯 麦田里的守望者 美国 塞林格 在路上 美国 凯鲁亚克 五号屠场 美国 冯内古特 第二十二条军规 美国 海勒 裸者与死者 美国 梅勒 好人难寻 美国 奥康纳 他们 美国 奥茨 城市与狗 秘鲁 略萨 最明净的地区 墨西哥 富恩特斯 诺言 瑞士 迪伦马特 细雪 日本 谷崎润一郎 上海 日本 横光利一 来到农村的文工队 日本 德永直 雪国 日本 川端康成 睡美人 日本 川端康成 “帝国银行事件”之谜 日本 松本清账 西阵之蝶 日本 水上勉 骏河夫人 日本 司马辽太郎 潮骚 日本 三岛由纪夫 金阁寺 日本 三岛由纪夫 黑衣 日本 有吉佐和子 饲育 日本 大江健三郎 万延元年的足球 日本 大江健三郎 苦难的历程 苏联 阿列克赛·托尔斯泰 日瓦戈医生 苏联 帕斯捷尔纳克 大师和玛格丽特 苏联 布尔加科夫 静静的顿河 苏联 肖洛霍夫 一个人的遭遇 苏联 肖洛霍夫 基督的最后诱惑 希腊 卡赞扎基斯 房间与街道 意大利 摩拉维亚 分成两半的子爵 意大利 卡尔维诺 刀锋 英国 毛姆 海浪 英国 伍尔夫 美妙的新世界 英国 赫胥黎 城堡 英国 克罗宁 一九八四 英国 奥威尔 问题的核心 英国 格林 蝇王 英国 戈尔丁 发条橙 英国 伯吉斯 沙堡 英国 默多克 金色笔记 英国 莱辛 幸运的吉姆 英国 艾米斯 法国中尉的女人 英国 福尔斯 戈丹 印度 普列姆昌德 黑水洋彼岸 印度 安纳德 20世纪后期卷 书名 国籍 作者 蜘蛛女之吻 阿根廷 普伊格 平民史诗 埃及 马哈福兹 风暴眼 澳大利亚 怀特 美好的美好的时光 奥地利 耶利内克 钢琴教师 奥地利 耶利内克 情欲 奥地利 耶利内克 浪女回归 巴西 亚马多 我坐在彼得拉河畔哭泣 巴西 科埃略 韦罗妮卡决定去死 巴西 科埃略 方尖碑 白俄罗斯 贝科夫 战争中没有女性 白俄罗斯 阿列克茜叶维契 惊马奔逃 德国 瓦尔泽 我的世纪 德国 格拉斯 献词 德国 施特劳斯 香水-一个谋杀犯的故事 德国 聚斯金德 白比姆黑耳朵 俄罗斯 特罗耶波尔斯基 一幅画 俄罗斯 格拉宁 永远十九岁 俄罗斯 巴拉克诺夫 百慕大三角 俄罗斯 邦达列夫 鱼王 俄罗斯 阿斯塔菲耶夫 被取消的演出 俄罗斯 奥库扎瓦 活下去，并且要记住 俄罗斯 拉斯普京 告别马焦拉 俄罗斯 拉斯普京 命运线 俄罗斯 哈里托诺夫 书市上的斯薇特兰娜 俄罗斯 马卡宁 美狄娅和她的孩子们 俄罗斯 乌利茨卡娅 夏伯阳与虚空 俄罗斯 佩列文 乡间的房子 俄罗斯 瓦尔拉莫夫 暗店街 法国 莫迪亚诺 我走了 法国 艾什诺兹 流浪的星星 法国 克莱齐奥 霍乱时期的爱情 哥伦比亚 马尔克斯 乙火 韩国 金东里 一日长于百年 吉尔吉斯斯坦 艾特玛托夫 断头台 吉尔吉斯斯坦 艾特玛托夫 斯通家史札记 加拿大 希尔兹 笑忘录 捷克 昆拉德 不能承受的生命之轻 捷克 昆拉德 冤家，一个爱情故事 美国 辛格 童爱 美国 辛格 杜宾的传记 美国 马拉默德 洪堡的礼物 美国 贝娄 更多的人死于心碎 美国 贝娄 时震 美国 冯内古特 刽子手之歌 美国 梅勒 苏菲的抉择 美国 斯泰伦 情欲艺术家 美国 霍克斯 铁草 美国 肯尼迪 最蓝的眼睛 美国 莫里森 所罗门之歌 美国 莫里森 白雪公主后传 美国 巴塞尔姆 拉格泰姆时代 美国 多克特罗 兔子回家 美国 厄普代克 变形记 美国 厄普代克 反生活 美国 罗斯 人性的污点 美国 罗斯 遗产-一个真实的故事 美国 罗斯 骏马长嘶 美国 麦卡锡 孤独鸽 美国 麦克默特里 葡萄园 美国 品钦 幽灵之家 美国 阿连德 不规则飞行 美国 纳尔逊 紫色 美国 沃克 纽约女人未眠夜 美国 提尔曼 一千英亩 美国 斯迈利 时时刻刻 美国 坎宁安 达·芬奇密码 美国 布朗 神圣的夜晚 摩洛哥 杰伦 帝国轶闻 墨西哥 帕索 七月的人民 南非 戈迪默 耻 南非 库切 修道院纪事 葡萄牙 萨拉马戈 失明症漫记 葡萄牙 萨拉马戈 失乐园 日本 渡边淳一 挪威的森林 日本 村上春树 无限近似于透明的蓝 日本 村上龙 厨房 日本 吉本芭娜娜 印第安的最后夏天 瑞士 谢赛克斯 哈扎尔辞典 塞尔维亚 帕维奇 老人 苏联 特里丰诺夫 红莓 苏联 舒克申 我的名字叫红 土耳其 帕慕克 独裁者的葬礼 委内瑞拉 彼特里 请听清风倾诉 乌拉圭 奥内蒂 为亡灵弹奏 西班牙 塞拉 无命运的人生 匈牙利 凯尔泰斯 蓝山 以色列 沙莱夫 玫瑰的名字 意大利 埃科 阿纳泰的贝壳 意大利 斯戈隆 人性的因素 英国 格林 河湾 英国 奈保尔 抵达之谜 英国 奈保尔 来自无人地带的明信片 英国 钱伯斯 隐之书 英国 拜厄特 时间中的孩子 英国 麦克尤恩 化学 英国 斯威夫特 长日留痕 英国 石黑一雄 卑微的神灵 印度 罗易 夜阑更深 印度尼西亚 维查雅 人世间 印度尼西亚 普拉姆迪亚 旁边的花园 智利 多诺索","categories":[{"name":"笔记","slug":"笔记","permalink":"https://fuyunliu.github.io/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"小说","slug":"小说","permalink":"https://fuyunliu.github.io/tags/%E5%B0%8F%E8%AF%B4/"}]},{"title":"Flask v0.1 源码阅读","slug":"understand-flask-v01","date":"2018-09-27T09:17:36.000Z","updated":"2019-08-06T14:07:55.599Z","comments":true,"path":"2018/09/27/understand-flask-v01/","link":"","permalink":"https://fuyunliu.github.io/2018/09/27/understand-flask-v01/","excerpt":"flask v0.1 是第一个发布的版本，单文件版，v0.4 是 flask 的最后一个单文件版本，文章中 flask 的源码有修改，因为依赖包有更新。","text":"flask v0.1 是第一个发布的版本，单文件版，v0.4 是 flask 的最后一个单文件版本，文章中 flask 的源码有修改，因为依赖包有更新。 导包部分123456789101112131415161718192021222324252627282930313233343536373839404142434445# python2.5 版本加入 with 语句，低于 2.5 需要引入，高于则忽略。from __future__ import with_statementimport osimport sys# 没有用到from threading import local# jinja2 模板引擎from jinja2 import Environment, PackageLoader, FileSystemLoader# Flask 的 Request 和 Response 继承自 werkzeug 的 Request 和 Responsefrom werkzeug.wrappers import Request as RequestBase, Response as ResponseBase# 最后几行 _request_ctx_stack, current_app, request, session, g 用到。from werkzeug.local import LocalStack, LocalProxy# 用于测试请求上下文，在 Flask 类的方法 test_request_context 中调用，已失效。# 最新版 test_request_context 方法调用 flask.testing 的 make_test_environ_builder，最终调用 werkzeug.test 的 EnvironBuilder。from werkzeug import create_environfrom werkzeug.utils import cached_propertyfrom werkzeug.wsgi import SharedDataMiddleware# 路由from werkzeug.routing import Map, Rule# 错误处理from werkzeug.exceptions import HTTPException, InternalServerError# flask 自带的 session 用到from werkzeug.contrib.securecookie import SecureCookie# 没有用到，作为对外接口from werkzeug import abort, redirectfrom jinja2 import Markup, escape# 用于获取应用程序根目录try: import pkg_resources pkg_resources.resource_streamexcept (ImportError, AttributeError): pkg_resources = None Request 和 Responseflask 的 Request 和 Response 继承自 werkzeug 的 Request 和 Response。 如果你想要自定义 Request 和 Response，你可以继承这两个类，然后指定 Flask 的 request_class 和 response_class。 123456789101112131415161718192021222324252627282930313233343536class Request(RequestBase): &quot;&quot;&quot;请求类&quot;&quot;&quot; def __init__(self, environ): RequestBase.__init__(self, environ) # WSGI 环境 self.endpoint = None # 视图函数的键名 self.view_args = None # 视图函数的参数class Response(ResponseBase): &quot;&quot;&quot;响应类&quot;&quot;&quot; default_mimetype = &#x27;text/html&#x27;class _RequestGlobals(object): passclass _RequestContext(object): &quot;&quot;&quot;请求上下文&quot;&quot;&quot; def __init__(self, app, environ): self.app = app self.url_adapter = app.url_map.bind_to_environ(environ) self.request = app.request_class(environ) self.session = app.open_session(self.request) # 带上下文的 session self.g = _RequestGlobals() # 带上下文的 g self.flashes = None def __enter__(self): _request_ctx_stack.push(self) def __exit__(self, exc_type, exc_value, tb): if tb is None or not self.app.debug: _request_ctx_stack.pop() 几个有用的函数12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061def url_for(endpoint, **values): &quot;&quot;&quot;函数跳转 endpoint: Flask 类有个 view_functions 字典，存储的就是 endpoint 和 视图函数的映射关系，默认 endpoint 是视图函数的名字 values: 路由传过来的参数 &quot;&quot;&quot; return _request_ctx_stack.top.url_adapter.build(endpoint, values)def flash(message): &quot;&quot;&quot; 消息闪现，存储在 session 中，是个列表 &quot;&quot;&quot; session[&#x27;_flashes&#x27;] = (session.get(&#x27;_flashes&#x27;, [])) + [message]def get_flashed_messages(): &quot;&quot;&quot; 把 session 中存储的消息全部 pop 出来并返回 &quot;&quot;&quot; flashes = _request_ctx_stack.top.flashes if flashes is None: _request_ctx_stack.top.flashes = flashes = \\ session.pop(&#x27;_flashes&#x27;, []) return flashesdef render_template(template_name, **context): &quot;&quot;&quot; 从文件渲染模板 &quot;&quot;&quot; current_app.update_template_context(context) return current_app.jinja_env.get_template(template_name).render(context)def render_template_string(source, **context): &quot;&quot;&quot; 从字符串渲染模板 &quot;&quot;&quot; current_app.update_template_context(context) return current_app.jinja_env.from_string(source).render(context)def _default_template_ctx_processor(): &quot;&quot;&quot; 模板处理，使得在所有模板中可以使用 request, session 和 g 三个全局变量 &quot;&quot;&quot; reqctx = _request_ctx_stack.top return dict( request=reqctx.request, session=reqctx.session, g=reqctx.g )def _get_package_path(name): &quot;&quot;&quot;根据名字获取模块的路径&quot;&quot;&quot; try: return os.path.abspath(os.path.dirname(sys.modules[name].__file__)) except (KeyError, AttributeError): return os.getcwd() Flask 类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355class Flask(object): &quot;&quot;&quot; Flask 类实现了一个 WSGI 应用，只要将包或者模块的名字传递给它 一旦创建的时候，它将首先注册视图函数、路由映射、模板配置等等几个重要的对象 传入包的名字是用于解决应用内部资源的引用，具体请查看 open_resource 函数 一般情况下，你只需要这样创建： from flask import Flask app = Flask(__name__) &quot;&quot;&quot; # 请求类 request_class = Request # 响应类 response_class = Response # 静态文件路径，设置为 None 可以禁用 static_path = &#x27;/static&#x27; # 密钥，用于 cookies 签名验证 secret_key = None # 基于 cookie 的 session 的名字 session_cookie_name = &#x27;session&#x27; # 默认会直接传给 jinja2 的 options 参数值 jinja_options = dict( autoescape=True, extensions=[&#x27;jinja2.ext.autoescape&#x27;, &#x27;jinja2.ext.with_&#x27;] ) def __init__(self, package_name): # 调试模式开关，设置 True 以打开调试模式 # 在调试模式下，应用程序出错会有特殊的错误页面以供调试 # 并且服务会监控文件的变化，文件发生变化会重载服务 self.debug = False # 包或者模块的名字，一旦设置好了就不要改动 self.package_name = package_name # 应用程序顶级目录 self.root_path = _get_package_path(self.package_name) # 包含所有注册好的视图函数字典，键是函数的名字，也用于生成 URL # 值就是函数本身，可以用 route 装饰器注册一个函数 self.view_functions = &#123;&#125; # 所有注册好的错误处理函数，键是错误代码，值是处理函数 # 可以用 errorhandler 注册一个错误处理函数 self.error_handlers = &#123;&#125; # 预处理函数，每次请求之前会执行，用 before_request 装饰器注册 self.before_request_funcs = [] # 后处理函数，每次请求完成以后执行，函数会截获响应并且改变它 # 用 after_request 装饰器注册 self.after_request_funcs = [] # 模板上下文处理器，默认有一个处理函数 _default_template_ctx_processor # 默认的函数功能是向模板上下文添加三个对象 request, session, g # 每个函数执行不需要参数，返回值为字典，用于填充模板上下文 self.template_context_processors = [_default_template_ctx_processor] # 路由映射，在 werkzeug.routing.Map self.url_map = Map() # 架起一个静态资源服务，一般用于开发环境，生产环境用 nginx if self.static_path is not None: self.url_map.add(Rule(self.static_path + &#x27;/&lt;filename&gt;&#x27;, build_only=True, endpoint=&#x27;static&#x27;)) if pkg_resources is not None: target = (self.package_name, &#x27;static&#x27;) else: target = os.path.join(self.root_path, &#x27;static&#x27;) self.wsgi_app = SharedDataMiddleware(self.wsgi_app, &#123; self.static_path: target &#125;) # jinja2 模板配置，包括模板目录和默认开启的功能 self.jinja_env = Environment(loader=self.create_jinja_loader(), **self.jinja_options) # 这是两个模板能用到的函数 # url_for 用于根据 endpoint 获取 URL # get_flashed_messages 用于获取消息闪现 self.jinja_env.globals.update( url_for=url_for, get_flashed_messages=get_flashed_messages ) def create_jinja_loader(self): &quot;&quot;&quot; 加载模板目录，默认目录为 templates &quot;&quot;&quot; if pkg_resources is None: return FileSystemLoader(os.path.join(self.root_path, &#x27;templates&#x27;)) return PackageLoader(self.package_name) def update_template_context(self, context): &quot;&quot;&quot; 为模板上下文注入几个常用的变量，比如 request, session, g context 为填充模板上下文的字典 &quot;&quot;&quot; reqctx = _request_ctx_stack.top for func in self.template_context_processors: context.update(func()) def run(self, host=&#x27;localhost&#x27;, port=5000, **options): &quot;&quot;&quot; 运行开发服务器 &quot;&quot;&quot; from werkzeug import run_simple if &#x27;debug&#x27; in options: self.debug = options.pop(&#x27;debug&#x27;) options.setdefault(&#x27;use_reloader&#x27;, self.debug) options.setdefault(&#x27;use_debugger&#x27;, self.debug) return run_simple(host, port, self, **options) def test_client(self): &quot;&quot;&quot; 为应用程序创建一个测试客户端 &quot;&quot;&quot; from werkzeug import Client return Client(self, self.response_class, use_cookies=True) def open_resource(self, resource): &quot;&quot;&quot; 动态加载模块 &quot;&quot;&quot; if pkg_resources is None: return open(os.path.join(self.root_path, resource), &#x27;rb&#x27;) return pkg_resources.resource_stream(self.package_name, resource) def open_session(self, request): &quot;&quot;&quot; 创建一个 session，secret_key 必须设置 基于 werkzeug.contrib.securecookie.SecureCookie &quot;&quot;&quot; key = self.secret_key if key is not None: return SecureCookie.load_cookie(request, self.session_cookie_name, secret_key=key) def save_session(self, session, response): &quot;&quot;&quot; 保存 session &quot;&quot;&quot; if session is not None: session.save_cookie(response, self.session_cookie_name) def add_url_rule(self, rule, endpoint, **options): &quot;&quot;&quot; 创建 URL 和视图函数的映射规则，等同于 route 装饰器 只是 add_url_rule 并没有为视图函数注册一个 endpoint 这一步也就是向 view_functions 字典添加 endpoint: view_func 键值对 以下： @app.route(&#x27;/&#x27;) def index(): pass 等同于： def index(): pass app.add_url_rule(&#x27;index&#x27;, &#x27;/&#x27;) app.view_functions[&#x27;index&#x27;] = index options: 参数选项详见 werkzeug.routing.Rule &quot;&quot;&quot; options[&#x27;endpoint&#x27;] = endpoint options.setdefault(&#x27;methods&#x27;, (&#x27;GET&#x27;,)) self.url_map.add(Rule(rule, **options)) def route(self, rule, **options): &quot;&quot;&quot; 为给定的 URL 注册一个视图函数 用法： @app.route(&#x27;/&#x27;) def index(): return &#x27;Hello World&#x27; 变量部分可以用尖括号(``/user/&lt;username&gt;``)指定，默认接受任何不带斜杆的字符串 变量也可以指定一个转换器，以指定类型的参数： =========== =========================================== int 整数 float 浮点数 path 路径 =========== =========================================== 值得注意的是 Flask 如何处理结尾的斜杆，核心思路是保证每个 URL 唯一： 1、如果配置了一个带结尾斜杆的 URL，用户请求不带结尾斜杆的这个 URL，则跳转到带结尾斜杆的页面。 2、如果配置了一个不带结尾斜杆的 URL，用户请求带结尾斜杆的这个 URL，则触发404错误。 这和 web 服务器处理静态资源 static 的逻辑是一样的 参数： rule: URL 字符串 methods: 允许的请求方法，是个列表，默认只接受 GET 请求和隐式的 HEAD subdomain: 指定子域名 strict_slashes: 上述对结尾斜杆处理的开关 options: 参数选项详见 `werkzeug.routing.Rule` &quot;&quot;&quot; def decorator(f): self.add_url_rule(rule, f.__name__, **options) self.view_functions[f.__name__] = f return f return decorator def errorhandler(self, code): &quot;&quot;&quot; 注册一个错误码处理函数 用法： @app.errorhandler(404) def page_not_found(): return &#x27;This page does not exist&#x27;, 404 等同于： def page_not_found(): return &#x27;This page does not exist&#x27;, 404 app.error_handlers[404] = page_not_found 参数： code: 错误码 &quot;&quot;&quot; def decorator(f): self.error_handlers[code] = f return f return decorator def before_request(self, f): &quot;&quot;&quot;注册一个预处理函数&quot;&quot;&quot; self.before_request_funcs.append(f) return f def after_request(self, f): &quot;&quot;&quot;注册一个后处理函数&quot;&quot;&quot; self.after_request_funcs.append(f) return f def context_processor(self, f): &quot;&quot;&quot;注册一个模板上下文处理函数&quot;&quot;&quot; self.template_context_processors.append(f) return f def match_request(self): &quot;&quot;&quot; 根据当前请求的路由去和url_map匹配，拿到 enpoint 和 view_args endpoint: 端点，是 view_functions 中对应视图函数的key view_args: 视图函数的参数 &quot;&quot;&quot; rv = _request_ctx_stack.top.url_adapter.match() request.endpoint, request.view_args = rv return rv def dispatch_request(self): &quot;&quot;&quot; 首先调用上面的 match_request 方法拿到 endpoint 和 view_args 根据 endpoint 可以从 view_functions 找到对应的视图函数 再传入视图函数的参数 view_args，并返回结果，这个结果只是函数的返回值 并没有包装成响应类 response_class，可以调用 make_response 方法生成响应 如果函数执行失败，则根据错误码调用对应的错误处理函数 &quot;&quot;&quot; try: endpoint, values = self.match_request() return self.view_functions[endpoint](**values) except HTTPException, e: handler = self.error_handlers.get(e.code) if handler is None: return e return handler(e) except Exception, e: handler = self.error_handlers.get(500) if self.debug or handler is None: raise return handler(e) def make_response(self, rv): &quot;&quot;&quot; 将视图函数的返回值包装成一个真实的响应类 response_class 函数的返回值支持以下几种类型： ======================= =========================================== response_class: 响应类本身，原样返回 str: 字符串，创建相应类并返回 unicode: unicode 编码，utf-8编码后创建相应类并返回 tuple: 元组，解包元组传入参数创建响应类并返回 a WSGI function: WSGI 函数 ======================= =========================================== 参数： rv: 视图函数的返回值 &quot;&quot;&quot; if isinstance(rv, self.response_class): return rv # basestring 是 str 和 unicode 的超类，只支持 python2 if isinstance(rv, basestring): return self.response_class(rv) if isinstance(rv, tuple): return self.response_class(*rv) return self.response_class.force_type(rv, request.environ) def preprocess_request(self): &quot;&quot;&quot; 在分发请求之前执行所有的预处理函数，如果预处理函数有返回值不为 None 则返回结果并中断其余的预处理 &quot;&quot;&quot; for func in self.before_request_funcs: rv = func() if rv is not None: return rv def process_response(self, response): &quot;&quot;&quot; 依次传入响应并执行所有的后处理函数，返回新的响应 &quot;&quot;&quot; session = _request_ctx_stack.top.session if session is not None: # 保存 `session` self.save_session(session, response) for handler in self.after_request_funcs: response = handler(response) return response def wsgi_app(self, environ, start_response): &quot;&quot;&quot; WSGI 应用，可以用中间件包装： app.wsgi_app = MyMiddleware(app.wsgi_app) 参数： environ: WSGI 环境，是一个字典，包含了所有请求的信息 start_response: 回调函数 &quot;&quot;&quot; with self.request_context(environ): rv = self.preprocess_request() if rv is None: rv = self.dispatch_request() response = self.make_response(rv) response = self.process_response(response) return response(environ, start_response) def request_context(self, environ): &quot;&quot;&quot; 通过给定的 WSGI 环境创建一个请求上下文，并把它绑定到当前上下文中 必须通过 with 语句使用，因为 request 对象只在请求上下文 也就是 with 语句块中起作用 用法如下： with app.request_context(environ): do_something_with(request) 参数： environ: WSGI 环境 &quot;&quot;&quot; return _RequestContext(self, environ) def test_request_context(self, *args, **kwargs): &quot;&quot;&quot; 测试请求上下文，参数详见 werkzeug.create_environ &quot;&quot;&quot; return self.request_context(create_environ(*args, **kwargs)) def __call__(self, environ, start_response): &quot;&quot;&quot;调用 wsgi_app 方法&quot;&quot;&quot; return self.wsgi_app(environ, start_response) 全局变量12345_request_ctx_stack = LocalStack()current_app = LocalProxy(lambda: _request_ctx_stack.top.app)request = LocalProxy(lambda: _request_ctx_stack.top.request)session = LocalProxy(lambda: _request_ctx_stack.top.session)g = LocalProxy(lambda: _request_ctx_stack.top.g) werkzeug 的 Local，LocalStack 和 LocalProxyFlask 中有两个上下文（Context）： 应用上下文（App Context） 请求上下文（Request Context） 上下文就是函数运行时所需要的外部变量，当我们运行一个简单的求和函数 sum 是不需要外部变量的，而像 Flask 中的视图函数运行需要知道当前的请求的路由、表单和请求方法等等一些信息。 Django 和 Tornado 把视图函数所需要的外部信息封装成一个对象 Request，并把这个对象当作参数传给视图函数，无论视图函数有没有用到，所以编写 Django 的视图函数会到处都见到一个 request 参数。 而 Flask 则使用了类似 Thread Local 的对象，它可以隔离多线程/协程之间的状态，使得多线程/协程像操作一个全局变量一样操作各自的状态而互不影响，原理就是使用当前的线程ID作为命名空间，保存多份字典，每个线程只获取各自线程ID对应的字典。 Flask 并没有使用 Python 标准库的 Thread Local，而是用了 werkzeug 实现的 Local。 Local 和 threading.local 相似，但是 Local 在 Greenlet 可用的情况下优先使用 getcurrent 获取当前线程ID，用以支持 Gevent 调度。 Local 还有一个 __release_local__ 方法，用以释放当前线程存储的状态信息。 LocalStack 是基于 Local 实现的栈结构，可以入栈（push）、出栈（pop）和获取栈顶对象（top）。 LocalProxy 是作为 Local 的一个代理模式，它接受一个 callable 对象，注意参数不是 Local 实例，这个 callable 对象返回的结果才是 Local 实例，所有对于 LocalProxy 对象的操作都会转发到对应的 Local。 上 当 app = Flask(__name__) 实例化一个 Flask App 时，App Context 并没有立即被入栈，LocalStack 栈顶元素是空的，返回 None 值，current_app，request，session 和 g 也是 unbound 状态，此时使用这些对象会引发 RuntimeError，解决方法是手动将 app.app_context() 入栈。 当 Flask 应用被 werkzeug 自带的开发服务器或者 gunicorn 用于生产的这类 WSGI 服务器架起的时候，每一个请求进来之前会自动将请求上下文（Request Context）入栈。 应用上下文（App Context）在 flask v0.1 版本的源码中没有，后面版本引入，应用上下文也会自动入栈，后面待看。 threading.local 使用： Flask 的 App Context 使用： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190# 优先使用 Greenlet 的线程IDtry: from greenlet import getcurrent as get_identexcept ImportError: try: from thread import get_ident except ImportError: from _thread import get_identclass Local(object): # 固定属性 __slots__ = (&#x27;__storage__&#x27;, &#x27;__ident_func__&#x27;) def __init__(self): # 数据存储，是一个字典 object.__setattr__(self, &#x27;__storage__&#x27;, &#123;&#125;) # 获取当前线程ID的方法 object.__setattr__(self, &#x27;__ident_func__&#x27;, get_ident) def __iter__(self): &quot;&quot;&quot;以生成器的方式返回字典的所有元素&quot;&quot;&quot; return iter(self.__storage__.items()) def __call__(self, proxy): &quot;&quot;&quot;创建一个 LocalProxy&quot;&quot;&quot; return LocalProxy(self, proxy) def __release_local__(self): &quot;&quot;&quot;清空当前线程/协程所保存的数据&quot;&quot;&quot; self.__storage__.pop(self.__ident_func__(), None) def __getattr__(self, name): &quot;&quot;&quot;属性访问&quot;&quot;&quot; try: return self.__storage__[self.__ident_func__()][name] except KeyError: raise AttributeError(name) def __setattr__(self, name, value): &quot;&quot;&quot;属性设置&quot;&quot;&quot; ident = self.__ident_func__() storage = self.__storage__ try: storage[ident][name] = value except KeyError: storage[ident] = &#123;name: value&#125; def __delattr__(self, name): &quot;&quot;&quot;属性删除&quot;&quot;&quot; try: del self.__storage__[self.__ident_func__()][name] except KeyError: raise AttributeError(name)class LocalStack(object): &quot;&quot;&quot; Local 的栈结构实现 &quot;&quot;&quot; def __init__(self): # Local 实例 self._local = Local() def __release_local__(self): # 释放当前线程的数据 self._local.__release_local__() def _get__ident_func__(self): # 返回获取当前线程ID的函数 return self._local.__ident_func__ def _set__ident_func__(self, value): # 设置获取当前线程ID的函数 object.__setattr__(self._local, &#x27;__ident_func__&#x27;, value) __ident_func__ = property(_get__ident_func__, _set__ident_func__) del _get__ident_func__, _set__ident_func__ def __call__(self): &quot;&quot;&quot;返回一个 LocalProxy 对象，该对象始终指向 LocalStack 实例的栈顶元素&quot;&quot;&quot; def _lookup(): rv = self.top if rv is None: raise RuntimeError(&#x27;object unbound&#x27;) return rv return LocalProxy(_lookup) def push(self, obj): &quot;&quot;&quot;入栈&quot;&quot;&quot; rv = getattr(self._local, &#x27;stack&#x27;, None) if rv is None: self._local.stack = rv = [] rv.append(obj) return rv def pop(self): &quot;&quot;&quot;出栈&quot;&quot;&quot; stack = getattr(self._local, &#x27;stack&#x27;, None) if stack is None: return None elif len(stack) == 1: release_local(self._local) return stack[-1] else: return stack.pop() @property def top(self): &quot;&quot;&quot;获取栈顶元素&quot;&quot;&quot; try: return self._local.stack[-1] except (AttributeError, IndexError): return None@implements_boolclass LocalProxy(object): &quot;&quot;&quot; Local 的代理模式实现，所有对 LocalProxy 对象的操作，包括属性访问、方法调用和二元操作 都会转发到那个 callable 参数返回的 Local 对象上 &quot;&quot;&quot; __slots__ = (&#x27;__local&#x27;, &#x27;__dict__&#x27;, &#x27;__name__&#x27;, &#x27;__wrapped__&#x27;) def __init__(self, local, name=None): # 把 callable 参数绑定到 __local 属性上 object.__setattr__(self, &#x27;_LocalProxy__local&#x27;, local) # 代理名字 object.__setattr__(self, &#x27;__name__&#x27;, name) if callable(local) and not hasattr(local, &#x27;__release_local__&#x27;): # 注意这里的参数 local 仅仅是一个 callable 对象 # 该对象执行返回的结果才是 Local 实例 object.__setattr__(self, &#x27;__wrapped__&#x27;, local) def _get_current_object(self): &quot;&quot;&quot;获取当前 Local 实例&quot;&quot;&quot; if not hasattr(self.__local, &#x27;__release_local__&#x27;): return self.__local() try: return getattr(self.__local, self.__name__) except AttributeError: raise RuntimeError(&#x27;no object bound to %s&#x27; % self.__name__) @property def __dict__(self): try: return self._get_current_object().__dict__ except RuntimeError: raise AttributeError(&#x27;__dict__&#x27;) def __repr__(self): try: obj = self._get_current_object() except RuntimeError: return &#x27;&lt;%s unbound&gt;&#x27; % self.__class__.__name__ return repr(obj) def __bool__(self): try: return bool(self._get_current_object()) except RuntimeError: return False def __unicode__(self): try: return unicode(self._get_current_object()) # noqa except RuntimeError: return repr(self) def __dir__(self): try: return dir(self._get_current_object()) except RuntimeError: return [] def __getattr__(self, name): if name == &#x27;__members__&#x27;: return dir(self._get_current_object()) return getattr(self._get_current_object(), name) def __setitem__(self, key, value): self._get_current_object()[key] = value def __delitem__(self, key): del self._get_current_object()[key] # 下面的源码省略，LocalProxy 重写了所有的魔法方法","categories":[{"name":"笔记","slug":"笔记","permalink":"https://fuyunliu.github.io/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Flask","slug":"Flask","permalink":"https://fuyunliu.github.io/tags/Flask/"}]},{"title":"RDS for MySQL 备份文件恢复到自建数据库","slug":"rds-for-mysql","date":"2018-09-13T03:45:58.000Z","updated":"2020-05-29T09:09:47.960Z","comments":true,"path":"2018/09/13/rds-for-mysql/","link":"","permalink":"https://fuyunliu.github.io/2018/09/13/rds-for-mysql/","excerpt":"云数据库MySQL版使用开源软件Percona Xtrabackup对数据库进行备份，所以您可以使用该软件将云数据库MySQL的备份文件恢复到自建数据库中，本文将介绍详细的操作步骤。","text":"云数据库MySQL版使用开源软件Percona Xtrabackup对数据库进行备份，所以您可以使用该软件将云数据库MySQL的备份文件恢复到自建数据库中，本文将介绍详细的操作步骤。 软件说明 MySQL 5.6.41 Percona XtraBackup 2.2.9 rds_backup_extract.sh 解压数据库备份文件12unzip -P密码 mysql_data_backup.tar.gz.zipbash rds_backup_extract -f mysql_data_backup.tar.gz -C /data/mysql/data 修改配置文件 backup-my.cnf 如下12345678910111213141516171819# This MySQL options file was generated by innobackupex.# The MySQL server[mysqld]innodb_checksum_algorithm=innodb# innodb_log_checksum_algorithm=innodbinnodb_data_file_path=ibdata1:200M:autoextendinnodb_log_files_in_group=2innodb_log_file_size=1572864000# innodb_fast_checksum=false# innodb_page_size=16384# innodb_log_block_size=512innodb_undo_directory=.innodb_undo_tablespaces=0# rds_encrypt_data=false# innodb_encrypt_algorithm=aes_128_ecb 修改文件属主1chown -R mysql:mysql /data/mysql/data 恢复数据文件12chmod 400 /data/mysql/data/backup-my.cnfinnobackupex --defaults-file=/data/mysql/data/backup-my.cnf --apply-log /data/mysql/data 启动数据库并登入验证1mysqld_safe --defaults-file=/data/mysql/data/backup-my.cnf --user=mysql --datadir=/data/mysql/data --skip-grant-tables &amp; 新建用户恢复完成后，表 mysql.user 中是不包含 RDS 中创建的用户，需要新建，新建用户前请执行如下 SQL： 12345delete from mysql.db where user&lt;&gt;&#x27;root&#x27; and char_length(user)&gt;0;delete from mysql.tables_priv where user&lt;&gt;&#x27;root&#x27; and char_length(user)&gt;0;flush privileges; 参考链接阿里云数据备份/恢复","categories":[{"name":"笔记","slug":"笔记","permalink":"https://fuyunliu.github.io/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://fuyunliu.github.io/tags/MySQL/"},{"name":"CentOS","slug":"CentOS","permalink":"https://fuyunliu.github.io/tags/CentOS/"}]},{"title":"CentOS 离线安装 MySQL","slug":"centos-install-mysql","date":"2018-09-06T03:47:57.000Z","updated":"2020-05-29T09:06:36.611Z","comments":true,"path":"2018/09/06/centos-install-mysql/","link":"","permalink":"https://fuyunliu.github.io/2018/09/06/centos-install-mysql/","excerpt":"记录一下 CentOS 离线安装 MySQL 并配置多实列主从复制的过程，如果有旧版 Mariadb，先卸载旧版 Mariadb。","text":"记录一下 CentOS 离线安装 MySQL 并配置多实列主从复制的过程，如果有旧版 Mariadb，先卸载旧版 Mariadb。 卸载系统自带的 Mariadb123rpm -qa|grep mariadb # 查询出已安装的 mariadbrpm -e --nodeps filename # 上面列出的所有文件rm -f /etc/my.cnf # 删除配置文件 创建 mysql 用户组12groupadd mysqluseradd -g mysql mysql 下载安装包1wget https://dev.mysql.com/get/Downloads/MySQL-8.0/mysql-8.0.12-linux-glibc2.12-x86_64.tar.xz 解压文件到目录 /usr/local123456789101112131415cp mysql-8.0.12-linux-glibc2.12-x86_64.tar.xz /usr/local/mysql-8.0.12-linux-glibc2.12-x86_64.tar.xzcd /usr/local# xz 结尾的是经过两层压缩的压缩包# 先解压 xzxz -d your_file_name.tar.xz# 再解压 tartar -xvf your_file_name.tar# 或者直接解压tar xvJf your_file_name.tar.xztar xvJf mysql-8.0.12-linux-glibc2.12-x86_64.tar.xzmv mysql-8.0.12-linux-glibc2.12-x86_64 mysql 配置 /etc/my.cnf1234567891011121314151617181920212223242526272829[mysqld_multi]mysqld = /usr/local/mysql/bin/mysqld_safemysqladmin = /usr/local/mysql/bin/mysqladminuser = root# The MySQL server###############################################################################[mysqld1]port =33306datadir =/data/mysqldata/data1socket =/var/lib/mysql/mysql1.sockpid-file =/var/lib/mysql/mysql1.piduser =mysqlserver_id =33306log_bin =/data/mysqldata/data1/mysql-binlog_bin_index =/data/mysqldata/data1/mysql-bin.indexexpire_logs_days =10 # 按需设置过期时间，表示保留最近10天的日志###############################################################################[mysqld2]port =33307datadir =/data/mysqldata/data2socket =/var/lib/mysql/mysql2.sockpid-file =/var/lib/mysql/mysql2.piduser =mysqlserver_id =33307log_bin =/data/mysqldata/data2/mysql-binlog_bin_index =/data/mysqldata/data2/mysql-bin.indexexpire_logs_days =10 # 按需设置过期时间，表示保留最近10天的日志############################################################################### 初始化数据目录1234567891011121314151617181920212223mkdir /var/lib/mysqlchown -R mysql:mysql /var/lib/mysqlmkdir /data/mysqldatachown -R mysql:mysql /data/mysqldatamkdir /data/mysqldata/data1chown -R mysql:mysql /data/mysqldata/data1mkdir /data/mysqldata/data2chown -R mysql:mysql /data/mysqldata/data2cd /usr/local/mysql/bin# 这种初始化数据库目录的方式过时了./mysql_install_db --basedir=/usr/local/mysql --datadir=/data/mysqldata/data1 --user=mysql./mysql_install_db --basedir=/usr/local/mysql --datadir=/data/mysqldata/data2 --user=mysql# 新的初始化数据库目录方式，会在终端打印一个临时登入密码。./mysqld --initialize --basedir=/usr/local/mysql --datadir=/data/mysqldata/data1 --user=mysql --console./mysqld --initialize --basedir=/usr/local/mysql --datadir=/data/mysqldata/data2 --user=mysql --console 启动实例1234cd /usr/local/mysql/binmysqld_multi start 1mysqld_multi start 2mysqld_multi report 主库创建同步账号1234567891011121314151617181920212223242526272829303132# 用刚才初始化数据库目录生成的临时密码登入./mysql -S /var/lib/mysql/mysql1.sock -p your-password# 如果忘记密码，可以在 my.cnf 的 mysqld 块中添加一行 skip-grant-tables = 1# 可以进行无密码登入，修改成功之后去掉这一行然后重启数据库。# 修改 root 密码USE mysql;UPDATE user SET authentication_string = PASSWORD(&#x27;new-password&#x27;), password_expired = &#x27;N&#x27;, password_last_changed = NOW() WHERE user = &#x27;root&#x27;;FLUSH PRIVILEGES;# 授权账户使得局域网内的机器可以访问数据库GRANT ALL PRIVILEGES ON *.* TO &#x27;root&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;new-password&#x27; WITH GRANT OPTION;# 创建一个同步账户CREATE USER &#x27;repl&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;repl-password&#x27;;GRANT REPLICATION SLAVE ON *.* TO &#x27;repl&#x27;@&#x27;%&#x27;;# 查看状态SHOW MASTER STATUS;SHOW BINARY LOGS;# 如果忘记设置日志过期时间，可以进入数据库进行全局设置，并手动清理过期日志# 不要在数据库目录进行删除日志，这样会使得数据库日志索引不一致，导致自动清理失效SET GLOBAL EXPIRE_LOGS_DAYS = 10;FLUSH LOGS; # 触发日志清理，一般是在有新的日志生成的时候触发检查一次。SHOW BINARY LOGS;# 也可以手动删除某个日志之前的所有日志PURGE BINARY LOGS TO &#x27;mysql-bin.000080&#x27;; # 删除 80 之前的日志SHOW BINARY LOGS; 从库配置12345678910111213141516# 修改从库的配置文件server-id =2relay-log =/dbdata/data/relay-logrelay-log-index =/dbdata/data/relay-log.index# 进入数据库执行CHANGE MASTER TOMASTER_HOST=‘master_host_name’, # 主库的主机名MASTER_PORT=port_number # 主库的端口号MASTER_USER=‘replication_user_name’, # 复制的数据库用户名MASTER_PASSWORD=‘replication_password’, # 复制的用户密码MASTER_LOG_FILE=‘recorded_log_file_name’, # 主库的日志文件名MASTER_LOG_POS=recorded_log_position; # 主库的日志文件位置start slave;","categories":[{"name":"笔记","slug":"笔记","permalink":"https://fuyunliu.github.io/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://fuyunliu.github.io/tags/MySQL/"},{"name":"CentOS","slug":"CentOS","permalink":"https://fuyunliu.github.io/tags/CentOS/"}]},{"title":"Selenium 在 Ubuntu 服务器上的使用","slug":"selenium-linux","date":"2018-08-13T02:31:07.000Z","updated":"2020-05-29T09:10:51.218Z","comments":true,"path":"2018/08/13/selenium-linux/","link":"","permalink":"https://fuyunliu.github.io/2018/08/13/selenium-linux/","excerpt":"安装 chrome1234wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | sudo apt-key add -echo &#x27;deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main&#x27; | sudo tee /etc/apt/sources.list.d/google-chrome.listsudo apt-get updatesudo apt-get install google-chrome-stable","text":"安装 chrome1234wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | sudo apt-key add -echo &#x27;deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main&#x27; | sudo tee /etc/apt/sources.list.d/google-chrome.listsudo apt-get updatesudo apt-get install google-chrome-stable 安装 chromedriver1234wget -N https://chromedriver.storage.googleapis.com/2.41/chromedriver_linux64.zipunzip chromedriver_linux64.zipchmod +x chromedrivercp chromedriver /usr/bin/ 安装 Xvfb12345sudo apt-get -y install xvfb gtk2-engines-pixbufsudo apt-get -y install xfonts-cyrillic xfonts-100dpi xfonts-75dpi xfonts-base xfonts-scalable# 截图功能，可选sudo apt-get -y install imagemagick x11-appsXvfb -ac :99 -screen 0 1280x1024x16 &amp; export DISPLAY=:99 测试脚本12345678910from selenium import webdriverchrome_options = webdriver.ChromeOptions()chrome_options.add_argument(&#x27;--headless&#x27;)chrome_options.add_argument(&#x27;--disable-gpu&#x27;)driver = webdriver.Chrome(chrome_options=chrome_options,executable_path=&#x27;/usr/bin/chromedriver&#x27;)driver.get(&quot;https://www.baidu.com&quot;)print(driver.title)driver.quit() 遇到的问题ubuntu server 18.04 虽然内置 python3 版本，但是没有 pip在 /etc/apt/sources.list 添加下列源 1234deb http://cn.archive.ubuntu.com/ubuntu bionic main multiverse restricted universedeb http://cn.archive.ubuntu.com/ubuntu bionic-updates main multiverse restricted universedeb http://cn.archive.ubuntu.com/ubuntu bionic-security main multiverse restricted universedeb http://cn.archive.ubuntu.com/ubuntu bionic-proposed main multiverse restricted universe 12sudo apt-get updatesudo apt-get install python3-pip 再用 pip 安装 selenium1pip3 install selenium","categories":[{"name":"笔记","slug":"笔记","permalink":"https://fuyunliu.github.io/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Python3","slug":"Python3","permalink":"https://fuyunliu.github.io/tags/Python3/"}]},{"title":"理解 Python 的关键字 Yield","slug":"understand-yield","date":"2018-03-14T06:17:26.000Z","updated":"2018-10-19T15:58:11.250Z","comments":true,"path":"2018/03/14/understand-yield/","link":"","permalink":"https://fuyunliu.github.io/2018/03/14/understand-yield/","excerpt":"为了理解什么是yield,你必须理解什么是生成器。 在理解生成器之前，让我们先走近迭代。 当你建立了一个列表，你可以逐项地读取这个列表，这叫做一个可迭代对象。","text":"为了理解什么是yield,你必须理解什么是生成器。 在理解生成器之前，让我们先走近迭代。 当你建立了一个列表，你可以逐项地读取这个列表，这叫做一个可迭代对象。 123mylist = [1, 2, 3, 4, 5]for i in mylist: print(i) 所有你可以使用for…in…语法的叫做一个迭代器，列表，字符串，文件等等，你经常使用它们是因为你可以如你所愿的读取其中的元素，但是你把所有的值都存储到了内存中，如果你有大量数据的话这个方式并不是你想要的。 生成器是可以迭代的，但是你只可以读取它一次，因为它并不把所有的值放在内存中，它是实时地生成数据。 123mygenerator = (x * x for x in range(5))for i in mygenerator: print(i) 你不可以再次迭代生成器 1234try: next(mygenerator)except StopIteration: print(&quot;停止迭代&quot;) yield 是一个类似 return 的关键字，只是这个函数返回的是个生成器。 123def create_generator(): for i in range(5): yield i * i 如果函数内部使用 return，则返回 0。 1234mygenerator = create_generator()for i in mygenerator: print(i) 斐波拉契数列 12345def fib(): x, y = 0, 1 while True: x, y = y, x + y yield x 获取斐波拉契数列前10个 12import itertoolslist(itertools.islice(fib(), 10)) 杨辉三角 12345def triangle(): a = [1] while True: yield a a = [sum(i) for i in zip([0] + a, a + [0])] 输出前10行杨辉三角 12import pprintlist(itertools.islice(triangle(), 10)) 控制迭代器的穷尽 12345678910111213141516171819202122232425262728293031323334class Bank(): crisis = False # crisis是危机的意思 def create_atm(self): while not self.crisis: yield &quot;$100&quot;bank = Bank() # 创建一个银行corner_street_atm = bank.create_atm() # 创建一个ATM机print([next(corner_street_atm) for _ in range(5)])bank.crisis = True # 危机来了try: print(next(corner_street_atm))except StopIteration: print(&quot;corner_street_atm: no more money!&quot;)try: wall_street_atm = bank.create_atm() print(next(wall_street_atm))except StopIteration: print(&quot;wall_street_atm: no more money!&quot;)bank.crisis = False # 问题是，即使改变crisis的值，ATM依然是空的try: print(next(corner_street_atm))except StopIteration: print(&quot;crisis is %s, and still no more money!&quot; % bank.crisis)# 重新创建一个ATM机，现在有钱了brand_new_atm = bank.create_atm()print([next(brand_new_atm) for _ in range(5)]) itertools 模块包含了许多特殊的迭代方法 比赛中4匹马可能到达终点的先后顺序的可能情况 12345import pprinthorses = [1, 2, 3, 4]races = itertools.permutations(horses)print(races)pprint.pprint(list(races)) 一个实现了 __iter__ 方法的对象是可迭代的，一个实现了 __next__ 方法的对象是迭代器。 12345678910111213141516class Fibs(): def __init__(self): self.a = 0 self.b = 1 def __next__(self): self.a, self.b = self.b, self.a + self.b return self.a def __iter__(self): return selffibs = Fibs()print([next(fibs) for _ in range(10)])","categories":[{"name":"笔记","slug":"笔记","permalink":"https://fuyunliu.github.io/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Python3","slug":"Python3","permalink":"https://fuyunliu.github.io/tags/Python3/"}]},{"title":"八大排序算法的 Python 实现","slug":"8-sort-algorithm","date":"2018-03-14T05:48:20.000Z","updated":"2020-11-26T09:31:27.557Z","comments":true,"path":"2018/03/14/8-sort-algorithm/","link":"","permalink":"https://fuyunliu.github.io/2018/03/14/8-sort-algorithm/","excerpt":"插入排序1234567891011def insert_sort(lists): count = len(lists) for i in range(1, count): key = lists[i] j = i - 1 while j &gt;= 0: if lists[j] &gt; key: lists[j + 1] = lists[j] lists[j] = key j -= 1 return lists","text":"插入排序1234567891011def insert_sort(lists): count = len(lists) for i in range(1, count): key = lists[i] j = i - 1 while j &gt;= 0: if lists[j] &gt; key: lists[j + 1] = lists[j] lists[j] = key j -= 1 return lists 希尔排序123456789101112131415161718def shell_sort(lists): count = len(lists) step = 2 group = count // step while group &gt; 0: for i in range(0, group): j = i + group while j &lt; count: k = j - group key = lists[j] while k &gt;= 0: if lists[k] &gt; key: lists[k + group] = lists[k] lists[k] = key k -= group j += group group //= step return lists 冒泡排序1234567def bubble_sort(lists): count = len(lists) for i in range(0, count): for j in range(i + 1, count): if lists[i] &gt; lists[j]: lists[i], lists[j] = lists[j], lists[i] return lists 快速排序123456789101112131415161718192021qs = lambda xs: ((len(xs) &lt;= 1 and [xs]) or [qs([x for x in xs[1:] if x &lt; xs[ 0]]) + [xs[0]] + qs([x for x in xs[1:] if x &gt;= xs[0]])])[0]def quick_sort(lists, left=0, right=9): if left &gt;= right: return lists key = lists[left] low = left high = right while left &lt; right: while left &lt; right and lists[right] &gt;= key: right -= 1 lists[left] = lists[right] while left &lt; right and lists[left] &lt;= key: left += 1 lists[right] = lists[left] lists[right] = key quick_sort(lists, low, left - 1) quick_sort(lists, left + 1, high) return lists 选择排序123456789def select_sort(lists): count = len(lists) for i in range(0, count): min = i for j in range(i + 1, count): if lists[min] &gt; lists[j]: min = j lists[min], lists[i] = lists[i], lists[min] return lists 堆排序1234567891011121314151617181920212223242526def adjust_heap(lists, i, size): lchild = 2 * i + 1 rchild = 2 * i + 2 max = i if i &lt; size // 2: if lchild &lt; size and lists[lchild] &gt; lists[max]: max = lchild if rchild &lt; size and lists[rchild] &gt; lists[max]: max = rchild if max != i: lists[max], lists[i] = lists[i], lists[max] adjust_heap(lists, max, size)def build_heap(lists, size): for i in range(0, (size // 2))[::-1]: adjust_heap(lists, i, size)def heap_sort(lists): size = len(lists) build_heap(lists, size) for i in range(0, size)[::-1]: lists[0], lists[i] = lists[i], lists[0] adjust_heap(lists, 0, i) return lists 归并排序12345678910111213141516171819202122def merge(left, right): i, j = 0, 0 result = [] while i &lt; len(left) and j &lt; len(right): if left[i] &lt;= right[j]: result.append(left[i]) i += 1 else: result.append(right[j]) j += 1 result += left[i:] result += right[j:] return resultdef merge_sort(lists): if len(lists) &lt;= 1: return lists num = len(lists) // 2 left = merge_sort(lists[:num]) right = merge_sort(lists[num:]) return merge(left, right) 基数排序1234567891011121314import mathdef radix_sort(lists, radix=10): k = int(math.ceil(math.log(max(lists), radix))) bucket = [[] for _ in range(radix)] for i in range(1, k + 1): for j in lists: bucket[j // (radix**(i - 1)) % radix].append(j) del lists[:] for z in bucket: lists += z del z[:] return lists 测试12345678910111213141516171819202122232425262728293031323334353637import randomoriginal_test = list(random.randint(1, 100) for _ in range(10))print(&quot;原始列表： %s&quot; % original_test)# 插入排序insert_test = insert_sort(original_test)# 希尔排序shell_test = shell_sort(original_test)# 冒泡排序bubble_test = bubble_sort(original_test)快速排序quick_test = quick_sort(original_test)# 直接选择排序select_test = select_sort(original_test)# 堆排序heap_test = heap_sort(original_test)# 归并排序merge_test = merge_sort(original_test)# 基数排序radix_test = radix_sort(original_test)print(&quot;插入排序： %s&quot; % insert_test)print(&quot;希尔排序： %s&quot; % shell_test)print(&quot;冒泡排序： %s&quot; % bubble_test)print(&quot;快速排序： %s&quot; % quick_test)print(&quot;直接选择排序：%s&quot; % select_test)print(&quot;堆排序： %s&quot; % heap_test)print(&quot;归并排序： %s&quot; % merge_test)print(&quot;基数排序： %s&quot; % radix_test)print(&quot;快速排序： %s&quot; % qs(original_test)) 本文来自：八大排序算法的 Python 实现","categories":[{"name":"笔记","slug":"笔记","permalink":"https://fuyunliu.github.io/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Python3","slug":"Python3","permalink":"https://fuyunliu.github.io/tags/Python3/"}]},{"title":"Screen 使用教程","slug":"screen-usage","date":"2018-03-13T09:36:52.000Z","updated":"2020-05-29T09:10:27.167Z","comments":true,"path":"2018/03/13/screen-usage/","link":"","permalink":"https://fuyunliu.github.io/2018/03/13/screen-usage/","excerpt":"GNU Screen是一款由GNU计划开发的用于命令行终端切换的自由软件。用户可以通过该软件同时连接多个本地或远程的命令行会话，并在其间自由切换。","text":"GNU Screen是一款由GNU计划开发的用于命令行终端切换的自由软件。用户可以通过该软件同时连接多个本地或远程的命令行会话，并在其间自由切换。 安装 screen1yum install -y screen screen 常用命令新建一个Screen Session 1screen -S session_name 将当前Screen Session放到后台 1CTRL + A + D 唤起一个Screen Session 1screen -r session_name 分享一个Screen Session 1screen -x session_name 终止一个Screen Session 123exitorCTRL + D 默认显示一屏的内容，要查看之前内容，如下操作： 1Ctrl + A ESC 列表所有的会话 1screen -ls 进入某个会话 1screen -r session_name 如果进不去，则 1screen -d session_name 再 1screen -r session_name ctrl + A + N 切换窗口","categories":[{"name":"笔记","slug":"笔记","permalink":"https://fuyunliu.github.io/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"CentOS","slug":"CentOS","permalink":"https://fuyunliu.github.io/tags/CentOS/"}]},{"title":"几种启动 Flask 应用的方式","slug":"flask-start-up","date":"2018-03-12T02:15:58.000Z","updated":"2019-08-06T14:02:19.167Z","comments":true,"path":"2018/03/12/flask-start-up/","link":"","permalink":"https://fuyunliu.github.io/2018/03/12/flask-start-up/","excerpt":"记录几种启动 Flask 应用的方式","text":"记录几种启动 Flask 应用的方式 首先写一个简单的 index.py 1234567891011# -*- coding: utf-8 -*-from flask import Flaskapp = Flask(__name__)@app.route(&#x27;/&#x27;, methods=[&#x27;GET&#x27;])def hello(): return &#x27;hello, world!&#x27; 最简单的启动方式12if __name__ == &#x27;__main__&#x27;: app.run() 这只能用于开发模式，可以设置debug=True开启调试模式，并且这是单线程同步的。 用 tornado 驱动 flask写一个server.py，并将上面index.py中的启动代码去掉，终端运行python server.py。 12345678910# -*- coding: utf-8 -*-from tornado.wsgi import WSGIContainerfrom tornado.httpserver import HTTPServerfrom tornado.ioloop import IOLoopfrom index import apphttp_server = HTTPServer(WSGIContainer(app))http_server.listen(5000) # flask默认的端口IOLoop.instance().start() 这也是同步的，同一时间只能处理一个请求，可以写个简单的接口测试一下。 12345678910111213141516171819202122# -*- coding: utf-8 -*-import timefrom flask import Flaskapp = Flask(__name__)@app.route(&#x27;/&#x27;, methods=[&#x27;GET&#x27;])def hello(): return &#x27;hello, world!&#x27;@app.route(&#x27;/test&#x27;, methods=[&#x27;GET&#x27;])def test(): for n in range(10): print(n) time.sleep(2) return &#x27;hello&#x27; 用postman同时发起5个请求，后台按顺序打印0-9，5个请求是一个一个执行的。 用 twisted 驱动 flask这个可以同时处理多个请求。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# -*- coding: utf-8 -*-import timefrom flask import Flaskapp = Flask(__name__)@app.route(&#x27;/&#x27;, methods=[&#x27;GET&#x27;])def hello(): return &#x27;hello, world!&#x27;@app.route(&#x27;/test&#x27;, methods=[&#x27;GET&#x27;])def test(): for n in range(10): print(n) time.sleep(2) return &#x27;hello&#x27;if __name__ == &quot;__main__&quot;: reactor_args = &#123;&#125; def run_twisted_wsgi(): from twisted.internet import reactor from twisted.web.server import Site from twisted.web.wsgi import WSGIResource resource = WSGIResource(reactor, reactor.getThreadPool(), app) site = Site(resource) reactor.listenTCP(5000, site) reactor.run(**reactor_args) if app.debug: # Disable twisted signal handlers in development only. reactor_args[&#x27;installSignalHandlers&#x27;] = 0 # Turn on auto reload. import werkzeug.serving run_twisted_wsgi = werkzeug.serving.run_with_reloader(run_twisted_wsgi) run_twisted_wsgi()if __name__ == &#x27;__main__&#x27;: app.run()","categories":[{"name":"笔记","slug":"笔记","permalink":"https://fuyunliu.github.io/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Flask","slug":"Flask","permalink":"https://fuyunliu.github.io/tags/Flask/"}]},{"title":"CentOS 编译安装 Python3","slug":"centos-install-python3","date":"2018-03-12T00:33:42.000Z","updated":"2021-07-22T11:45:54.651Z","comments":true,"path":"2018/03/12/centos-install-python3/","link":"","permalink":"https://fuyunliu.github.io/2018/03/12/centos-install-python3/","excerpt":"记录一下 CentOS 编译安装 Python3 的过程。","text":"记录一下 CentOS 编译安装 Python3 的过程。 安装系统相关依赖1yum install -y zlib-devel bzip2 bzip2-devel readline-devel sqlite sqlite-devel openssl-static openssl-devel xz xz-devel libffi-devel findutils gcc wget 下载 python3 包1wget https://www.python.org/ftp/python/3.9.6/Python-3.9.6.tgz 解压到当前目录1tar -zxvf Python-3.9.6.tgz 进入生成的目录进行配置1./configure --prefix=/usr/local/python3 --enable-loadable-sqlite-extensions --enable-optimizations 编译安装1make &amp;&amp; make install 添加软连接1ln -s /usr/local/python3/bin/python3 /usr/bin/python3 其他yum 搜索可用包 1yum search python3 | grep devel 一键更新 python 包 1python3 -m pip list --outdated --format=freeze | grep -v &#x27;^\\-e&#x27; | cut -d = -f 1 | xargs -n1 pip install -U 切换豆瓣源 12345678# 编辑 .pip/pip.conf 添加如下内容[global]index-url = https://pypi.douban.com/simpletrusted-host = pypi.douban.com[list]format = columns 离线安装python包 123456789101112131415# 首先离线下载依赖包，比如 `tensorflow-cpu`，同时会下载所有的依赖项python3 -m pip download -d packages tensorflow-cpu# 下载和目标机器对应架构的依赖包# https://pip.pypa.io/en/stable/cli/pip_download/python3 -m pip download \\ --only-binary=:all: \\ --platform manylinux1_x86_64 --platform linux_x86_64 --platform any \\ --python-version 36 \\ --implementation cp \\ --abi cp36m --abi cp36 --abi abi3 --abi none \\ tensorflow-cpu# 离线安装，指定寻找包的目录为 packagespython3 -m pip install --no-index --find-links=packages -r requirements.txt","categories":[{"name":"笔记","slug":"笔记","permalink":"https://fuyunliu.github.io/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Python3","slug":"Python3","permalink":"https://fuyunliu.github.io/tags/Python3/"},{"name":"CentOS","slug":"CentOS","permalink":"https://fuyunliu.github.io/tags/CentOS/"}]},{"title":"Python 脚本自动重载","slug":"python-reloader","date":"2018-03-09T09:51:08.000Z","updated":"2020-05-29T09:09:37.895Z","comments":true,"path":"2018/03/09/python-reloader/","link":"","permalink":"https://fuyunliu.github.io/2018/03/09/python-reloader/","excerpt":"Django 和 Flask 应用开启 debug 模式之后都能检测代码的变化然后自动重载，于是去找实现代码，发现 Flask 是用的 werkzeug 库里面的功能，而 Django 的不好用于自己写的脚本，因为和 Django 应用结合了。","text":"Django 和 Flask 应用开启 debug 模式之后都能检测代码的变化然后自动重载，于是去找实现代码，发现 Flask 是用的 werkzeug 库里面的功能，而 Django 的不好用于自己写的脚本，因为和 Django 应用结合了。 下面是 werkzeug 中的 _reloader 模块中的 run_with_reloader 函数。 1234567891011121314151617def run_with_reloader(main_func, extra_files=None, interval=1, reloader_type=&#x27;auto&#x27;): &quot;&quot;&quot;Run the given function in an independent python interpreter.&quot;&quot;&quot; import signal reloader = reloader_loops[reloader_type](extra_files, interval) signal.signal(signal.SIGTERM, lambda *args: sys.exit(0)) try: if os.environ.get(&#x27;WERKZEUG_RUN_MAIN&#x27;) == &#x27;true&#x27;: t = threading.Thread(target=main_func, args=()) t.setDaemon(True) t.start() reloader.run() else: sys.exit(reloader.restart_with_reloader()) except KeyboardInterrupt: pass 用法如下 123456789101112import timedef main(): while True: print(&quot;hello, world!&quot;) time.sleep(2)if __name__ == &#x27;__main__&#x27;: run_with_reloader(main) 但是执行函数不能传参，修改 run_with_reloader 如下 12345678910111213141516171819202122def run_with_reloader(main_func, args=(), kwargs=None, extra_files=None, interval=1, reloader_type=&#x27;auto&#x27;): &quot;&quot;&quot;Run the given function in an independent python interpreter.&quot;&quot;&quot; import os import sys import signal import threading from werkzeug._reloader import reloader_loops reloader = reloader_loops[reloader_type](extra_files, interval) signal.signal(signal.SIGTERM, lambda *args: sys.exit(0)) try: if os.environ.get(&#x27;WERKZEUG_RUN_MAIN&#x27;) == &#x27;true&#x27;: t = threading.Thread(target=main_func, args=args, kwargs=kwargs) t.setDaemon(True) t.start() reloader.run() else: sys.exit(reloader.restart_with_reloader()) except KeyboardInterrupt: pass 然后就能传参了 12345678910111213import timedef main(name, age): while True: print(&quot;hello, &quot;, name, &#x27;!&#x27;) time.sleep(2) print(age)if __name__ == &#x27;__main__&#x27;: run_with_reloader(main, args=(&#x27;foo&#x27;, 20))","categories":[{"name":"笔记","slug":"笔记","permalink":"https://fuyunliu.github.io/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Python3","slug":"Python3","permalink":"https://fuyunliu.github.io/tags/Python3/"}]}],"categories":[{"name":"笔记","slug":"笔记","permalink":"https://fuyunliu.github.io/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Python3","slug":"Python3","permalink":"https://fuyunliu.github.io/tags/Python3/"},{"name":"LSTM","slug":"LSTM","permalink":"https://fuyunliu.github.io/tags/LSTM/"},{"name":"Drain3","slug":"Drain3","permalink":"https://fuyunliu.github.io/tags/Drain3/"},{"name":"FastText","slug":"FastText","permalink":"https://fuyunliu.github.io/tags/FastText/"},{"name":"HanLP","slug":"HanLP","permalink":"https://fuyunliu.github.io/tags/HanLP/"},{"name":"JWT","slug":"JWT","permalink":"https://fuyunliu.github.io/tags/JWT/"},{"name":"Session","slug":"Session","permalink":"https://fuyunliu.github.io/tags/Session/"},{"name":"Cookie","slug":"Cookie","permalink":"https://fuyunliu.github.io/tags/Cookie/"},{"name":"PostgreSQL","slug":"PostgreSQL","permalink":"https://fuyunliu.github.io/tags/PostgreSQL/"},{"name":"Algorithm","slug":"Algorithm","permalink":"https://fuyunliu.github.io/tags/Algorithm/"},{"name":"CentOS","slug":"CentOS","permalink":"https://fuyunliu.github.io/tags/CentOS/"},{"name":"Sqlalchemy","slug":"Sqlalchemy","permalink":"https://fuyunliu.github.io/tags/Sqlalchemy/"},{"name":"小说","slug":"小说","permalink":"https://fuyunliu.github.io/tags/%E5%B0%8F%E8%AF%B4/"},{"name":"Flask","slug":"Flask","permalink":"https://fuyunliu.github.io/tags/Flask/"},{"name":"MySQL","slug":"MySQL","permalink":"https://fuyunliu.github.io/tags/MySQL/"}]}